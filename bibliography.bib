@article{oviatt1999,
 author = {Oviatt, Sharon},
 title = {Ten Myths of Multimodal Interaction},
 journal = {Commun. ACM},
 issue_date = {Nov. 1999},
 volume = {42},
 number = {11},
 month = nov,
 year = {1999},
 issn = {0001-0782},
 pages = {74--81},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/319382.319398},
 doi = {10.1145/319382.319398},
 acmid = {319398},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{jaimes2007,
title = "Multimodal humancomputer interaction: A survey",
journal = "Computer Vision and Image Understanding",
volume = "108",
number = "1",
pages = "116 - 134",
year = "2007",
note = "Special Issue on Vision for Human-Computer Interaction",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2006.10.019",
url = "http://www.sciencedirect.com/science/article/pii/S1077314206002335",
author = "Alejandro Jaimes and Nicu Sebe",
keywords = "Multimodal human-computer interaction, Gesture recognition, Affective computing, Human-centered computing",
abstract = "In this paper, we review the major approaches to multimodal humancomputer interaction, giving an overview of the field from a computer vision perspective. In particular, we focus on body, gesture, gaze, and affective interaction (facial expression recognition and emotion in audio). We discuss user and task modeling, and multimodal fusion, highlighting challenges, open issues, and emerging applications for multimodal humancomputer interaction (MMHCI) research."
}

@article{white2007,
	title = {Multimodal {Mixed} {Reality} {Interfaces} for {Visualizing} {Digital} {Heritage}},
	volume = {5},
	issn = {1478-0771, 2048-3988},
	url = {http://journals.sagepub.com/doi/10.1260/1478-0771.5.2.322},
	doi = {10.1260/1478-0771.5.2.322},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {International Journal of Architectural Computing},
	author = {White, Martin and Petridis, Panagiotis and Liarokapis, Fotis and Plecinckx, Daniel},
	month = jun,
	year = {2007},
	pages = {321--337}
}



@inproceedings{abbasi-asl_brain-computer_2019,
	address = {San Francisco, CA, USA},
	title = {Brain-{Computer} {Interface} in {Virtual} {Reality}},
	isbn = {9781538679210},
	url = {https://ieeexplore.ieee.org/document/8717158/},
	doi = {10.1109/NER.2019.8717158},
	urldate = {2019-09-14},
	booktitle = {2019 9th {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering} ({NER})},
	publisher = {IEEE},
	author = {Abbasi-Asl, Reza and Keshavarzi, Mohammad and Chan, Dorian Yao},
	month = mar,
	year = {2019},
	pages = {1220--1224}
}

@article{ai_edge_2018,
	title = {Edge computing technologies for {Internet} of {Things}: a primer},
	volume = {4},
	issn = {23528648},
	shorttitle = {Edge computing technologies for {Internet} of {Things}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352864817301335},
	doi = {10.1016/j.dcan.2017.07.001},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {Digital Communications and Networks},
	author = {Ai, Yuan and Peng, Mugen and Zhang, Kecheng},
	month = apr,
	year = {2018},
	pages = {77--86}
}

@article{adatia_proprioceptive_1971,
	title = {Proprioceptive innervation of the tongue},
	volume = {110},
	number = {2},
	journal = {J. Anat},
	author = {ADATIA, A. K. and GEHRING, E. N.},
	month = nov,
	year = {1971},
	pages = {215--220}
}

@inproceedings{albouys-perrois_towards_2018,
	address = {Montreal QC, Canada},
	title = {Towards a {Multisensory} {Augmented} {Reality} {Map} for {Blind} and {Low} {Vision} {People}: a {Participatory} {Design} {Approach}},
	isbn = {9781450356206},
	shorttitle = {Towards a {Multisensory} {Augmented} {Reality} {Map} for {Blind} and {Low} {Vision} {People}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174203},
	doi = {10.1145/3173574.3174203},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Albouys-Perrois, JÃ©rÃ©my and Laviole, JÃ©rÃ©my and Briant, Carine and Brock, Anke M.},
	year = {2018},
	pages = {1--14}
}

@inproceedings{al-kalbani_freehand_2017,
	address = {Glasgow, UK},
	title = {Freehand grasping in mixed reality: analysing variation during transition phase of interaction},
	isbn = {9781450355438},
	shorttitle = {Freehand grasping in mixed reality},
	url = {http://dl.acm.org/citation.cfm?doid=3136755.3136776},
	doi = {10.1145/3136755.3136776},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Multimodal} {Interaction}  - {ICMI} 2017},
	publisher = {ACM Press},
	author = {Al-Kalbani, Maadh and Frutos-Pascual, Maite and Williams, Ian},
	year = {2017},
	pages = {110--114}
}

@inproceedings{zhiyun_li_recording_2004,
	address = {Arlington, VA, USA},
	title = {Recording and {Reproducing} {High} {Order} {Surround} {Auditory} {Scenes} for {Mixed} and {Augmented} {Reality}},
	isbn = {9780769521916},
	url = {http://ieeexplore.ieee.org/document/1383061/},
	doi = {10.1109/ISMAR.2004.51},
	urldate = {2019-09-14},
	booktitle = {Third {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE},
	author = {{Zhiyun Li} and Duraiswami, R. and Davis, L.S.},
	year = {2004},
	pages = {240--249}
}

@article{xavier_audio--text_2014,
	title = {Audio-to-text {Alignment} for speech recognition with very limited resources},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	author = {Xavier, Anguera  and Luque, Jordi and  Ciro, Gracia},
	year = {2014}
}

@article{sagaya_aurelia_survey_nodate,
	title = {A {Survey} on {Mobile} {Augmented} {Reality} {Based} {Interactive} {Storytelling}},
	volume = {2},
	journal = {Advances in Information Science and Applications},
	author = {{Sagaya Aurelia} and { M. Durai Raj} and {Omer Saleh}}
}

@article{azuma_survey_1997,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {6},
	issn = {1054-7460, 1531-3263},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.355},
	doi = {10.1162/pres.1997.6.4.355},
	language = {en},
	number = {4},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Azuma, Ronald T.},
	month = aug,
	year = {1997},
	pages = {355--385}
}

@article{bablani_survey_2019,
	title = {Survey on {Brain}-{Computer} {Interface}: {An} {Emerging} {Computational} {Intelligence} {Paradigm}},
	volume = {52},
	issn = {03600300},
	shorttitle = {Survey on {Brain}-{Computer} {Interface}},
	url = {http://dl.acm.org/citation.cfm?doid=3309872.3297713},
	doi = {10.1145/3297713},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {ACM Computing Surveys},
	author = {Bablani, Annushree and Edla, Damodar Reddy and Tripathi, Diwakar and Cheruku, Ramalingaswamy},
	month = feb,
	year = {2019},
	pages = {1--32}
}

@inproceedings{bace_ubigaze:_2016,
	address = {Macau},
	title = {{ubiGaze}: ubiquitous augmented reality messaging using gaze gestures},
	isbn = {9781450345514},
	shorttitle = {{ubiGaze}},
	url = {http://dl.acm.org/citation.cfm?doid=2999508.2999530},
	doi = {10.1145/2999508.2999530},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {{SIGGRAPH} {ASIA} 2016 {Mobile} {Graphics} and {Interactive} {Applications} on - {SA} '16},
	publisher = {ACM Press},
	author = {BÃ¢ce, Mihai and LeppÃ€nen, Teemu and de Gomez, David Gil and Gomez, Argenis Ramirez},
	year = {2016},
	pages = {1--5}
}

@inproceedings{bai_markerless_2013,
	address = {Hong Kong, Hong Kong},
	title = {Markerless 3D gesture-based interaction for handheld augmented reality interfaces},
	isbn = {9781450326339},
	url = {http://dl.acm.org/citation.cfm?doid=2543651.2543678},
	doi = {10.1145/2543651.2543678},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {{SIGGRAPH} {Asia} 2013 {Symposium} on {Mobile} {Graphics} and {Interactive} {Applications} on - {SA} '13},
	publisher = {ACM Press},
	author = {Bai, Huidong and Gao, Lei and El-Sana, Jihad and Billinghurst, Mark},
	year = {2013},
	pages = {1--1}
}

@article{barfield_comments_1996,
	title = {Comments on the {Use} of {Olfactory} {Displays} for {Virtual} {Environments}},
	volume = {5},
	issn = {1054-7460, 1531-3263},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.1996.5.1.109},
	doi = {10.1162/pres.1996.5.1.109},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Barfield, Woodrow and Danas, Eric},
	month = jan,
	year = {1996},
	pages = {109--121}
}

@article{bau_revel:_2012,
	title = {{REVEL}: tactile feedback technology for augmented reality},
	volume = {31},
	issn = {07300301},
	shorttitle = {{REVEL}},
	url = {http://dl.acm.org/citation.cfm?doid=2185520.2185585},
	doi = {10.1145/2185520.2185585},
	language = {en},
	number = {4},
	urldate = {2019-09-14},
	journal = {ACM Transactions on Graphics},
	author = {Bau, Olivier and Poupyrev, Ivan},
	month = jul,
	year = {2012},
	pages = {1--11}
}

@inproceedings{baudisch_back--device_2009,
	address = {Boston, MA, USA},
	title = {Back-of-device interaction allows creating very small touch devices},
	isbn = {9781605582467},
	url = {http://dl.acm.org/citation.cfm?doid=1518701.1518995},
	doi = {10.1145/1518701.1518995},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 27th international conference on {Human} factors in computing systems - {CHI} 09},
	publisher = {ACM Press},
	author = {Baudisch, Patrick and Chu, Gerry},
	year = {2009},
	pages = {1923}
}

@inproceedings{beaudouin-lafon_instrumental_2000,
	address = {The Hague, The Netherlands},
	title = {Instrumental interaction: an interaction model for designing post-{WIMP} user interfaces},
	isbn = {9781581132168},
	shorttitle = {Instrumental interaction},
	url = {http://portal.acm.org/citation.cfm?doid=332040.332473},
	doi = {10.1145/332040.332473},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '00},
	publisher = {ACM Press},
	author = {Beaudouin-Lafon, Michel},
	year = {2000},
	pages = {446--453}
}

@article{bermejo_survey_2017,
	title = {A survey on haptic technologies for mobile augmented reality},
	url = {http://arxiv.org/abs/1709.00698},
	abstract = {Augmented Reality (AR) and Mobile Augmented Reality (MAR) applications have gained much research and industry attention these days. The mobile nature of MAR applications limits users' interaction capabilities such as inputs, and haptic feedbacks. This survey reviews current research issues in the area of human computer interaction for MAR and haptic devices. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile: touch, active surfaces, and mid-air, kinesthetic: manipulandum, grasp, and exoskeleton. Due to the mobile capabilities of MAR applications, we mainly focus our study on wearable haptic devices for each category and their AR possibilities. To conclude, we discuss the future paths that haptic feedbacks should follow for MAR applications and their challenges.},
	urldate = {2019-09-14},
	journal = {arXiv:1709.00698 [cs]},
	author = {Bermejo, Carlos and Hui, Pan},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.00698},
	keywords = {Computer Science - Human-Computer Interaction}
}

@inproceedings{billinghurst_hands_2013,
	address = {Sydney, Australia},
	title = {Hands and speech in space: multimodal interaction with augmented reality interfaces},
	isbn = {9781450321297},
	shorttitle = {Hands and speech in space},
	url = {http://dl.acm.org/citation.cfm?doid=2522848.2532202},
	doi = {10.1145/2522848.2532202},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 15th {ACM} on {International} conference on multimodal interaction - {ICMI} '13},
	publisher = {ACM Press},
	author = {Billinghurst, Mark},
	year = {2013},
	pages = {379--380}
}

@article{billinghurst_survey_2015,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {8},
	issn = {1551-3955, 1551-3963},
	url = {http://www.nowpublishers.com/article/Details/HCI-049},
	doi = {10.1561/1100000049},
	language = {en},
	number = {2-3},
	urldate = {2019-09-14},
	journal = {Foundations and TrendsÂ® in HumanâComputer Interaction},
	author = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
	year = {2015},
	pages = {73--272}
}

@inproceedings{t._blum_augmented_nodate,
	title = {An augmented reality magic mirror system for anatomy education},
	author = {{T. Blum} and {V. Kleeberger} and {C. Bichlmeier} and {N. Navab}}
}

@article{t._blum_augmented_nodate-1,
	title = {An augmented reality magic mirror system for anatomy education.},
	doi = {http://dx.doi.org/10.1109/VR.2012.6180909},
	journal = {2012 IEEE Virtual Reality Workshops (VRW)},
	author = {{T. Blum} and {V. Kleeberger} and {C. Bichlmeier} and {N. Navab}},
	pages = {115--116}
}

@inproceedings{tobias_blum_superman-like_2012,
	address = {Atlanta, GA, USA},
	title = {Superman-like {X}-ray vision: {Towards} brain-computer interfaces for medical augmented reality},
	isbn = {978-1-4673-4661-0},
	doi = {10.1109/ISMAR.2012.6402569},
	publisher = {IEEE},
	author = {{Tobias Blum} and {Ralf Stauder} and {Ekkehard Euler} and {Nassir Navab}},
	month = nov,
	year = {2012}
}

@inproceedings{boldu_insight:_2017,
	address = {Silicon Valley, California},
	title = {{InSight}: a systematic approach to create dynamic human-controller-interactions},
	isbn = {9781450348355},
	shorttitle = {{InSight}},
	url = {http://dl.acm.org/citation.cfm?doid=3041164.3041195},
	doi = {10.1145/3041164.3041195},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 8th {Augmented} {Human} {International} {Conference} on - {AH} '17},
	publisher = {ACM Press},
	author = {Boldu, Roger and Zhang, Haimo and CortÃ©s, Juan Pablo Forero and Muthukumarana, Sachith and Nanayakkara, Suranga},
	year = {2017},
	pages = {1--5}
}

@article{bolopion_review_2013,
	title = {A {Review} of {Haptic} {Feedback} {Teleoperation} {Systems} for {Micromanipulation} and {Microassembly}},
	volume = {10},
	issn = {1545-5955, 1558-3783},
	url = {http://ieeexplore.ieee.org/document/6476754/},
	doi = {10.1109/TASE.2013.2245122},
	number = {3},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Bolopion, A. and Regnier, S.},
	month = jul,
	year = {2013},
	pages = {496--502}
}

@article{borst_evaluation_2005,
	title = {Evaluation of a {Haptic} {Mixed} {Reality} {System} for {Interactions} with a {Virtual} {Control} {Panel}},
	volume = {14},
	issn = {1054-7460, 1531-3263},
	url = {http://www.mitpressjournals.org/doi/10.1162/105474605775196562},
	doi = {10.1162/105474605775196562},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Borst, Christoph W. and Volz, Richard A.},
	month = dec,
	year = {2005},
	pages = {677--696}
}

@inproceedings{jorge_brandao_augmented_2015,
	address = {New York, NY, USA},
	title = {An {Augmented} {Reality} {GameBook} for {Children} with {Autism} {Spectrum} {Disorders}},
	author = {{Jorge BrandÃ£o} and {Pedro Cunha} and {JosÃ© Vasconcelos} and {VÃ­tor Carvalho} and {Filomena Soares}},
	month = jun,
	year = {2015}
}

@inproceedings{buchmann_fingartips:_2004,
	address = {Singapore},
	title = {{FingARtips}: gesture based direct manipulation in {Augmented} {Reality}},
	isbn = {9781581138832},
	shorttitle = {{FingARtips}},
	url = {http://portal.acm.org/citation.cfm?doid=988834.988871},
	doi = {10.1145/988834.988871},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2nd international conference on {Computer} graphics and interactive techniques in {Austalasia} and {Southe} {East} {Asia}  - {GRAPHITE} '04},
	publisher = {ACM Press},
	author = {Buchmann, Volkert and Violich, Stephen and Billinghurst, Mark and Cockburn, Andy},
	year = {2004},
	pages = {212}
}

@article{cavazza_multimodal_2004,
	title = {Multimodal acting in mixed reality interactive storytelling},
	volume = {11},
	issn = {1070-986X},
	url = {http://ieeexplore.ieee.org/document/1316795/},
	doi = {10.1109/MMUL.2004.11},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {IEEE Multimedia},
	author = {Cavazza, M. and Charles, F. and Mead, S.J. and Martin, O. and Marichal, X. and Nandi, A.},
	month = jul,
	year = {2004},
	pages = {30--39}
}

@article{chatzopoulos_mobile_2017,
	title = {Mobile {Augmented} {Reality} {Survey}: {From} {Where} {We} {Are} to {Where} {We} {Go}},
	volume = {5},
	issn = {2169-3536},
	shorttitle = {Mobile {Augmented} {Reality} {Survey}},
	url = {http://ieeexplore.ieee.org/document/7912316/},
	doi = {10.1109/ACCESS.2017.2698164},
	urldate = {2019-09-14},
	journal = {IEEE Access},
	author = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Hui, Pan},
	year = {2017},
	pages = {6917--6950}
}

@inproceedings{cheok_initial_2015,
	address = {Iskandar, Malaysia},
	title = {Initial basic concept of thermal sweet taste interface},
	isbn = {9781450338523},
	url = {http://dl.acm.org/citation.cfm?doid=2832932.2856225},
	doi = {10.1145/2832932.2856225},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Advances} in {Computer} {Entertainment} {Technology} - {ACE} '15},
	publisher = {ACM Press},
	author = {Cheok, Adrian David and Karunanayaka, Kasun and Samshir, Nur Amira and Johari, Nurafiqah},
	year = {2015},
	pages = {1--3}
}

@inproceedings{chung_stress_2009,
	address = {Boston, MA, USA},
	title = {Stress outsourced: a haptic social network via crowdsourcing},
	isbn = {9781605582474},
	shorttitle = {Stress outsourced},
	url = {http://portal.acm.org/citation.cfm?doid=1520340.1520346},
	doi = {10.1145/1520340.1520346},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 27th international conference extended abstracts on {Human} factors in computing systems - {CHI} {EA} '09},
	publisher = {ACM Press},
	author = {Chung, Keywon and Chiu, Carnaven and Xiao, Xiao and Chi, Pei-Yu (Peggy)},
	year = {2009},
	pages = {2439}
}

@incollection{lalanne_mixed_2009,
	address = {Berlin, Heidelberg},
	title = {Mixed {Reality}: {A} {Survey}},
	volume = {5440},
	isbn = {9783642004360 9783642004377},
	shorttitle = {Mixed {Reality}},
	url = {http://link.springer.com/10.1007/978-3-642-00437-7_3},
	urldate = {2019-09-14},
	booktitle = {Human {Machine} {Interaction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Costanza, Enrico and Kunz, Andreas and Fjeld, Morten},
	editor = {Lalanne, Denis and Kohlas, JÃŒrg},
	year = {2009},
	doi = {10.1007/978-3-642-00437-7_3},
	pages = {47--68}
}



@inproceedings{coutrix_mixed_2006,
	address = {Venezia, Italy},
	title = {Mixed reality: a model of mixed interaction},
	isbn = {9781595933539},
	shorttitle = {Mixed reality},
	url = {http://portal.acm.org/citation.cfm?doid=1133265.1133274},
	doi = {10.1145/1133265.1133274},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the working conference on {Advanced} visual interfaces  - {AVI} '06},
	publisher = {ACM Press},
	author = {Coutrix, CÃ©line and Nigay, Laurence},
	year = {2006},
	pages = {43}
}

@article{culbertson_haptics:_2018,
	title = {Haptics: {The} {Present} and {Future} of {Artificial} {Touch} {Sensation}},
	volume = {1},
	issn = {2573-5144},
	shorttitle = {Haptics},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-control-060117-105043},
	doi = {10.1146/annurev-control-060117-105043},
	abstract = {This article reviews the technology behind creating artificial touch sensations and the relevant aspects of human touch. We focus on the design and control of haptic devices and discuss the best practices for generating distinct and effective touch sensations. Artificial haptic sensations can present information to users, help them complete a task, augment or replace the other senses, and add immersiveness and realism to virtual interactions. We examine these applications in the context of different haptic feedback modalities and the forms that haptic devices can take. We discuss the prior work, limitations, and design considerations of each feedback modality and individual haptic technology. We also address the need to consider the neuroscience and perception behind the human sense of touch in the design and control of haptic devices.},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Culbertson, Heather and Schorr, Samuel B. and Okamura, Allison M.},
	month = may,
	year = {2018},
	pages = {385--409}
}

@inproceedings{dinh_evaluating_1999,
	address = {Houston, TX, USA},
	title = {Evaluating the importance of multi-sensory input on memory and the sense of presence in virtual environments},
	isbn = {9780769500935},
	url = {http://ieeexplore.ieee.org/document/756955/},
	doi = {10.1109/VR.1999.756955},
	urldate = {2019-09-14},
	booktitle = {Proceedings {IEEE} {Virtual} {Reality} ({Cat}. {No}. 99CB36316)},
	publisher = {IEEE Comput. Soc},
	author = {Dinh, H.Q. and Walker, N. and Hodges, L.F. and {Chang Song} and Kobayashi, A.},
	year = {1999},
	pages = {222--228}
}

@book{dix_human-computer_2004,
	address = {Harlow, England ; New York},
	edition = {3rd ed},
	title = {Human-computer interaction},
	isbn = {9780130461094},
	publisher = {Pearson/Prentice-Hall},
	editor = {Dix, Alan},
	year = {2004},
	keywords = {Human-computer interaction}
}

@incollection{lalanne_multimodal_2009,
	address = {Berlin, Heidelberg},
	title = {Multimodal {Interfaces}: {A} {Survey} of {Principles}, {Models} and {Frameworks}},
	volume = {5440},
	isbn = {9783642004360 9783642004377},
	shorttitle = {Multimodal {Interfaces}},
	url = {http://link.springer.com/10.1007/978-3-642-00437-7_1},
	urldate = {2019-09-14},
	booktitle = {Human {Machine} {Interaction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dumas, Bruno and Lalanne, Denis and Oviatt, Sharon},
	editor = {Lalanne, Denis and Kohlas, JÃŒrg},
	year = {2009},
	doi = {10.1007/978-3-642-00437-7_1},
	pages = {3--26}
}

@inproceedings{elkoubaiti_survey_2018,
	address = {Marrakech},
	title = {A {Survey} of {Pedagogical} {Affordances} of {Augmented} and {Virtual} {Realities} {Technologies} in {loT} - {Based} {Classroom}},
	isbn = {9781538643853},
	url = {https://ieeexplore.ieee.org/document/8596654/},
	doi = {10.1109/CIST.2018.8596654},
	urldate = {2019-09-14},
	booktitle = {2018 {IEEE} 5th {International} {Congress} on {Information} {Science} and {Technology} ({CiSt})},
	publisher = {IEEE},
	author = {Elkoubaiti, Houda and Mrabet, Radouane},
	month = oct,
	year = {2018},
	pages = {334--341}
}

@article{escobedo_using_2014,
	title = {Using {Augmented} {Reality} to {Help} {Children} with {Autism} {Stay} {Focused}},
	volume = {13},
	issn = {1536-1268},
	url = {http://ieeexplore.ieee.org/document/6750495/},
	doi = {10.1109/MPRV.2014.19},
	number = {1},
	urldate = {2019-09-14},
	journal = {IEEE Pervasive Computing},
	author = {Escobedo, Lizbeth and Tentori, Monica and Quintana, Eduardo and Favela, Jesus and Garcia-Rosas, Daniel},
	year = {2014},
	pages = {38--46}
}

@article{bladin_w._2006,
	title = {W. {Grey} {Walter}, pioneer in the electroencephalogram, robotics, cybernetics, artificial intelligence},
	volume = {13},
	issn = {09675868},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S096758680500398X},
	doi = {10.1016/j.jocn.2005.04.010},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {Journal of Clinical Neuroscience},
	author = {Bladin, Peter F.},
	month = feb,
	year = {2006},
	pages = {170--177}
}

@article{farwell_talking_1988,
	title = {Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials},
	volume = {70},
	issn = {00134694},
	shorttitle = {Talking off the top of your head},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0013469488901496},
	doi = {10.1016/0013-4694(88)90149-6},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Farwell, L.A. and Donchin, E.},
	month = dec,
	year = {1988},
	pages = {510--523}
}

@article{fazel-rezai_region-based_2009,
	title = {A region-based {P}300 speller for brain-computer interface},
	volume = {34},
	issn = {0840-8688},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5443854},
	doi = {10.1109/CJECE.2009.5443854},
	number = {3},
	urldate = {2019-09-14},
	journal = {Canadian Journal of Electrical and Computer Engineering},
	author = {Fazel-Rezai, Reza and Abhari, Kamyar},
	year = {2009},
	pages = {81--85}
}

@article{fazel-rezai_p300_2012,
	title = {P300 brain computer interface: current challenges and emerging trends},
	volume = {5},
	issn = {1662-6443},
	shorttitle = {P300 brain computer interface},
	url = {http://journal.frontiersin.org/article/10.3389/fneng.2012.00014/abstract},
	doi = {10.3389/fneng.2012.00014},
	urldate = {2019-09-14},
	journal = {Frontiers in Neuroengineering},
	author = {Fazel-Rezai, Reza and Allison, Brendan Z. and Guger, Christoph and Sellers, Eric W. and Kleih, Sonja C. and KÃŒbler, Andrea},
	year = {2012}
}

@article{fernandez-carames_fog_2018,
	title = {A {Fog} {Computing} and {Cloudlet} {Based} {Augmented} {Reality} {System} for the {Industry} 4.0 {Shipyard}},
	volume = {18},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/18/6/1798},
	doi = {10.3390/s18061798},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {Sensors},
	author = {FernÃ¡ndez-CaramÃ©s, Tiago and Fraga-Lamas, Paula and SuÃ¡rez-Albela, Manuel and Vilar-Montesinos, Miguel},
	month = jun,
	year = {2018},
	pages = {1798}
}

@article{furdea_auditory_2009,
	title = {An auditory oddball ({P}300) spelling system for brain-computer interfaces},
	volume = {46},
	issn = {00485772, 14698986},
	url = {http://doi.wiley.com/10.1111/j.1469-8986.2008.00783.x},
	doi = {10.1111/j.1469-8986.2008.00783.x},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {Psychophysiology},
	author = {Furdea, A. and Halder, S. and Krusienski, D.J. and Bross, D. and Nijboer, F. and Birbaumer, N. and KÃŒbler, A.},
	month = may,
	year = {2009},
	pages = {617--625}
}

@article{gaillard_invasive_2017,
	title = {â{Invasive}â and â{Non}-invasiveâ {Technologies} in {Neuroscience} {Communication}},
	volume = {6},
	issn = {1923-2799},
	url = {http://id.erudit.org/iderudit/1044618ar},
	doi = {10.7202/1044618ar},
	language = {fr},
	urldate = {2019-09-14},
	journal = {BioÃ©thiqueOnline},
	author = {Gaillard, Maxence},
	year = {2017},
	pages = {1044618ar}
}

@inproceedings{gallego_cascon_chewit._2019,
	address = {Glasgow, Scotland Uk},
	title = {{ChewIt}. {An} {Intraoral} {Interface} for {Discreet} {Interactions}},
	isbn = {9781450359702},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300556},
	doi = {10.1145/3290605.3300556},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Gallego CascÃ³n, Pablo and Matthies, Denys J.C. and Muthukumarana, Sachith and Nanayakkara, Suranga},
	year = {2019},
	pages = {1--13}
}

@article{gandy_universal_2003,
	title = {Universal design: {Lessons} for wearable computing},
	volume = {2},
	issn = {1536-1268},
	shorttitle = {Universal design},
	url = {http://ieeexplore.ieee.org/document/1228523/},
	doi = {10.1109/MPRV.2003.1228523},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {IEEE Pervasive Computing},
	author = {Gandy, M. and Ross, D. and Starner, T.E.},
	month = jul,
	year = {2003},
	pages = {19--23}
}

@article{ginns_meta-analysis_2005,
	title = {Meta-analysis of the modality effect},
	volume = {15},
	issn = {09594752},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959475205000459},
	doi = {10.1016/j.learninstruc.2005.07.001},
	language = {en},
	number = {4},
	urldate = {2019-09-14},
	journal = {Learning and Instruction},
	author = {Ginns, Paul},
	month = aug,
	year = {2005},
	pages = {313--331}
}

@article{guenther_neural_2012,
	title = {A neural theory of speech acquisition and production},
	volume = {25},
	issn = {09116044},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0911604409000682},
	doi = {10.1016/j.jneuroling.2009.08.006},
	language = {en},
	number = {5},
	urldate = {2019-09-14},
	journal = {Journal of Neurolinguistics},
	author = {Guenther, Frank H. and Vladusich, Tony},
	month = sep,
	year = {2012},
	pages = {408--422}
}

@article{guger_how_2009,
	title = {How many people are able to control a {P}300-based brainâcomputer interface ({BCI})?},
	volume = {462},
	issn = {03043940},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304394009008192},
	doi = {10.1016/j.neulet.2009.06.045},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Neuroscience Letters},
	author = {Guger, Christoph and Daban, Shahab and Sellers, Eric and Holzner, Clemens and Krausz, Gunther and Carabalona, Roberta and Gramatica, Furio and Edlinger, Guenter},
	month = sep,
	year = {2009},
	pages = {94--98}
}

@article{guo_braincomputer_2008,
	title = {A brainâcomputer interface using motion-onset visual evoked potential},
	volume = {5},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/5/i=4/a=011?key=crossref.bcc667d28df0d88901563c3d560b024f},
	doi = {10.1088/1741-2560/5/4/011},
	number = {4},
	urldate = {2019-09-14},
	journal = {Journal of Neural Engineering},
	author = {Guo, Fei and Hong, Bo and Gao, Xiaorong and Gao, Shangkai},
	month = dec,
	year = {2008},
	pages = {477--485}
}

@inproceedings{massie_phantom_1994,
	title = {The {PHANTOM} haptic interface: a device for probing virtual objects},
	author = {Massie, T.H. and Salisbury., J.K.},
	year = {1994}
}

@article{haas_hans_2003,
	title = {Hans {Berger} (1873-1941), {Richard} {Caton} (1842-1926), and electroencephalography},
	volume = {74},
	issn = {00223050},
	url = {http://jnnp.bmj.com/cgi/doi/10.1136/jnnp.74.1.9},
	doi = {10.1136/jnnp.74.1.9},
	number = {1},
	urldate = {2019-09-14},
	journal = {Journal of Neurology, Neurosurgery \& Psychiatry},
	author = {Haas, L F},
	month = jan,
	year = {2003},
	pages = {9--9}
}

@inproceedings{han_hydroring:_2018,
	address = {Berlin, Germany},
	title = {{HydroRing}: {Supporting} {Mixed} {Reality} {Haptics} {Using} {Liquid} {Flow}},
	isbn = {9781450359481},
	shorttitle = {{HydroRing}},
	url = {http://dl.acm.org/citation.cfm?doid=3242587.3242667},
	doi = {10.1145/3242587.3242667},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}  - {UIST} '18},
	publisher = {ACM Press},
	author = {Han, Teng and Anderson, Fraser and Irani, Pourang and Grossman, Tovi},
	year = {2018},
	pages = {913--925}
}

@inproceedings{han_hydroring:_2018-1,
	address = {Berlin, Germany},
	title = {{HydroRing}: {Supporting} {Mixed} {Reality} {Haptics} {Using} {Liquid} {Flow}},
	isbn = {9781450359481},
	shorttitle = {{HydroRing}},
	url = {http://dl.acm.org/citation.cfm?doid=3242587.3242667},
	doi = {10.1145/3242587.3242667},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}  - {UIST} '18},
	publisher = {ACM Press},
	author = {Han, Teng and Anderson, Fraser and Irani, Pourang and Grossman, Tovi},
	year = {2018},
	pages = {913--925}
}

@article{hannun_deep_2014,
	title = {Deep {Speech}: {Scaling} up end-to-end speech recognition},
	shorttitle = {Deep {Speech}},
	url = {http://arxiv.org/abs/1412.5567},
	abstract = {We present a state-of-the-art speech recognition system developed using end-to-end deep learning. Our architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast, our system does not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learns a function that is robust to such effects. We do not need a phoneme dictionary, nor even the concept of a "phoneme." Key to our approach is a well-optimized RNN training system that uses multiple GPUs, as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training. Our system, called Deep Speech, outperforms previously published results on the widely studied Switchboard Hub5'00, achieving 16.0\% error on the full test set. Deep Speech also handles challenging noisy environments better than widely used, state-of-the-art commercial speech systems.},
	urldate = {2019-09-14},
	journal = {arXiv:1412.5567 [cs]},
	author = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew Y.},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.5567},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@inproceedings{haitham_hasan_human_nodate,
	title = {Human {Computer} {Interaction} for {Vision} {Based} {Hand} {Gesture} {Recognition} : {A} {Survey}},
	doi = {10.1109/ACSAT.2012.37},
	author = {{Haitham Hasan} and {S.Abdul Kareem}}
}

@article{hasegawa_midair_2018,
	title = {Midair {Ultrasound} {Fragrance} {Rendering}},
	volume = {24},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/8260917/},
	doi = {10.1109/TVCG.2018.2794118},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hasegawa, Keisuke and Qiu, Liwei and Shinoda, Hiroyuki},
	month = apr,
	year = {2018},
	pages = {1477--1485}
}

@incollection{hayward_haptics:_2001,
	title = {Haptics: {A} {Key} to {Fast} {Paced} {Interactivity}},
	isbn = {9780444506498},
	shorttitle = {Haptics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444506498500048},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Human {Friendly} {Mechatronics}},
	publisher = {Elsevier},
	author = {Hayward, Vincent},
	year = {2001},
	doi = {10.1016/B978-044450649-8/50004-8},
	pages = {11--16}
}

@inproceedings{herbst_timewarp:_2008,
	address = {Amsterdam, The Netherlands},
	title = {{TimeWarp}: interactive time travel with a mobile mixed reality game},
	isbn = {9781595939524},
	shorttitle = {{TimeWarp}},
	url = {http://portal.acm.org/citation.cfm?doid=1409240.1409266},
	doi = {10.1145/1409240.1409266},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 10th international conference on {Human} computer interaction with mobile devices and services - {MobileHCI} '08},
	publisher = {ACM Press},
	author = {Herbst, Iris and Braun, Anne-Kathrin and McCall, Rod and Broll, Wolfgang},
	year = {2008},
	pages = {235}
}



@inproceedings{higa_two-by-two_2007,
	address = {Nara, Japan},
	title = {A {Two}-by-{Two} {Mixed} {Reality} {System} {That} {Merges} {Real} and {Virtual} {Worlds} in {Both} {Audio} and {Visual} {Senses}},
	doi = {10.1109/ISMAR.2007.4538847},
	publisher = {IEEE},
	author = {Higa, K. and Nishiura, T. and Kimura, A. and Shibata, F. and Tamura, H.},
	month = nov,
	year = {2007},
	pages = {203--206}
}

@article{hirche_human-oriented_2012,
	title = {Human-{Oriented} {Control} for {Haptic} {Teleoperation}},
	volume = {100},
	issn = {0018-9219, 1558-2256},
	url = {http://ieeexplore.ieee.org/document/6127891/},
	doi = {10.1109/JPROC.2011.2175150},
	number = {3},
	urldate = {2019-09-14},
	journal = {Proceedings of the IEEE},
	author = {Hirche, S. and Buss, M.},
	month = mar,
	year = {2012},
	pages = {623--647}
}

@article{masaaki_honda_human_2003,
	title = {Human {Speech} {Production} {Mechanisms}},
	volume = {1},
	issn = {1348-3447},
	language = {English},
	number = {2},
	journal = {NTT Technical Review},
	author = {{Masaaki Honda}},
	month = may,
	year = {2003},
	pages = {24--29}
}

@inproceedings{hornbaek_what_2017,
	address = {Denver, Colorado, USA},
	title = {What {Is} {Interaction}?},
	isbn = {9781450346559},
	url = {http://dl.acm.org/citation.cfm?doid=3025453.3025765},
	doi = {10.1145/3025453.3025765},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '17},
	publisher = {ACM Press},
	author = {HornbÃŠk, Kasper and Oulasvirta, Antti},
	year = {2017},
	pages = {5040--5052}
}

@article{charles_e._hughes._augmenting_2004,
	title = {Augmenting {Museum} {Experiences} with {Mixed} {Reality}},
	journal = {Proceedings of Knowledge Sharing and Collaborative Engineering 2004},
	author = {{Charles E. Hughes.}},
	year = {2004},
	pages = {22--24}
}

@article{hughes_mixed_2005,
	title = {Mixed {Reality} in {Education}, {Entertainment}, and {Training}},
	volume = {25},
	issn = {0272-1716},
	url = {http://ieeexplore.ieee.org/document/1528429/},
	doi = {10.1109/MCG.2005.139},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {IEEE Computer Graphics and Applications},
	author = {Hughes, C.E. and Stapleton, C.B. and Hughes, D.E. and Smith, E.M.},
	month = nov,
	year = {2005},
	pages = {24--30}
}

@inproceedings{hurst_multimodal_2016,
	address = {Tokyo, Japan},
	title = {Multimodal feedback for finger-based interaction in mobile augmented reality},
	isbn = {9781450345569},
	url = {http://dl.acm.org/citation.cfm?doid=2993148.2993163},
	doi = {10.1145/2993148.2993163},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {Multimodal} {Interaction} - {ICMI} 2016},
	publisher = {ACM Press},
	author = {HÃŒrst, Wolfgang and Vriens, Kevin},
	year = {2016},
	pages = {302--306}
}

@incollection{pan_evaluation_2006,
	address = {Berlin, Heidelberg},
	title = {An {Evaluation} of an {Augmented} {Reality} {Multimodal} {Interface} {Using} {Speech} and {Paddle} {Gestures}},
	volume = {4282},
	isbn = {9783540497769 9783540497790},
	url = {http://link.springer.com/10.1007/11941354_28},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Advances in {Artificial} {Reality} and {Tele}-{Existence}},
	publisher = {Springer Berlin Heidelberg},
	author = {Irawati, Sylvia and Green, Scott and Billinghurst, Mark and Duenser, Andreas and Ko, Heedong},
	editor = {Pan, Zhigeng and Cheok, Adrian and Haller, Michael and Lau, Rynson W. H. and Saito, Hideo and Liang, Ronghua},
	year = {2006},
	doi = {10.1007/11941354_28},
	pages = {272--283}
}

@article{jain_artificial_1996,
	title = {Artificial neural networks: a tutorial},
	volume = {29},
	issn = {00189162},
	shorttitle = {Artificial neural networks},
	url = {http://ieeexplore.ieee.org/document/485891/},
	doi = {10.1109/2.485891},
	number = {3},
	urldate = {2019-09-14},
	journal = {Computer},
	author = {Jain, A.K. and {Jianchang Mao} and Mohiuddin, K.M.},
	month = mar,
	year = {1996},
	pages = {31--44}
}

@article{jakobsson_pain_2014,
	title = {Pain {Management} in {Ambulatory} {Surgery}â{A} {Review}},
	volume = {7},
	issn = {1424-8247},
	url = {http://www.mdpi.com/1424-8247/7/8/850},
	doi = {10.3390/ph7080850},
	language = {en},
	number = {8},
	urldate = {2019-09-14},
	journal = {Pharmaceuticals},
	author = {Jakobsson, Jan},
	month = jul,
	year = {2014},
	pages = {850--865}
}

@inproceedings{jantz_brain-computer_2017,
	address = {Los Angeles, California},
	title = {A brain-computer interface for extended reality interfaces},
	isbn = {9781450350136},
	url = {http://dl.acm.org/citation.cfm?doid=3089269.3089290},
	doi = {10.1145/3089269.3089290},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {{ACM} {SIGGRAPH} 2017 {VR} {Village} on   - {SIGGRAPH} '17},
	publisher = {ACM Press},
	author = {Jantz, Jay and Molnar, Adam and Alcaide, Ramses},
	year = {2017},
	pages = {1--2}
}

@article{kansaku_my_2010,
	title = {My thoughts through a robot's eyes: {An} augmented reality-brainâmachine interface},
	volume = {66},
	issn = {01680102},
	shorttitle = {My thoughts through a robot's eyes},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168010209020094},
	doi = {10.1016/j.neures.2009.10.006},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {Neuroscience Research},
	author = {Kansaku, Kenji and Hata, Naoki and Takano, Kouji},
	month = feb,
	year = {2010},
	pages = {219--222}
}

@inproceedings{kapur_alterego:_2018,
	address = {Tokyo, Japan},
	title = {{AlterEgo}: {A} {Personalized} {Wearable} {Silent} {Speech} {Interface}},
	isbn = {9781450349451},
	shorttitle = {{AlterEgo}},
	url = {http://dl.acm.org/citation.cfm?doid=3172944.3172977},
	doi = {10.1145/3172944.3172977},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 {Conference} on {Human} {Information} {Interaction}\&{Retrieval}  - {IUI} '18},
	publisher = {ACM Press},
	author = {Kapur, Arnav and Kapur, Shreyas and Maes, Pattie},
	year = {2018},
	pages = {43--53}
}

@article{fakhri_karray_human-computer_2008,
	title = {Human-computer interaction: {Overview} on state of the art},
	journal = {International journal on smart sensing and intelligent systems},
	author = {{Fakhri Karray}},
	month = mar,
	year = {2008}
}

@inproceedings{kato_virtual_2000,
	address = {Munich, Germany},
	title = {Virtual object manipulation on a table-top {AR} environment},
	isbn = {9780769508467},
	url = {http://ieeexplore.ieee.org/document/880934/},
	doi = {10.1109/ISAR.2000.880934},
	urldate = {2019-09-14},
	booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality} ({ISAR} 2000)},
	publisher = {IEEE},
	author = {Kato, H. and Billinghurst, M. and Poupyrev, I. and Imamoto, K. and Tachibana, K.},
	year = {2000},
	pages = {111--119}
}

@inproceedings{kyto_pinpointing:_2018,
	address = {Montreal QC, Canada},
	title = {Pinpointing: {Precise} {Head}- and {Eye}-{Based} {Target} {Selection} for {Augmented} {Reality}},
	isbn = {9781450356206},
	shorttitle = {Pinpointing},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3173655},
	doi = {10.1145/3173574.3173655},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {KytÃ¶, Mikko and Ens, Barrett and Piumsomboon, Thammathip and Lee, Gun A. and Billinghurst, Mark},
	year = {2018},
	pages = {1--14}
}

@article{lahat_multimodal_2015,
	title = {Multimodal {Data} {Fusion}: {An} {Overview} of {Methods}, {Challenges}, and {Prospects}},
	volume = {103},
	issn = {0018-9219, 1558-2256},
	shorttitle = {Multimodal {Data} {Fusion}},
	url = {http://ieeexplore.ieee.org/document/7214350/},
	doi = {10.1109/JPROC.2015.2460697},
	number = {9},
	urldate = {2019-09-14},
	journal = {Proceedings of the IEEE},
	author = {Lahat, Dana and Adali, Tulay and Jutten, Christian},
	month = sep,
	year = {2015},
	pages = {1449--1477}
}

@article{lee_semiautonomous_2013,
	title = {Semiautonomous {Haptic} {Teleoperation} {Control} {Architecture} of {Multiple} {Unmanned} {Aerial} {Vehicles}},
	volume = {18},
	issn = {1083-4435, 1941-014X},
	url = {http://ieeexplore.ieee.org/document/6522198/},
	doi = {10.1109/TMECH.2013.2263963},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Lee, Dongjun and Franchi, Antonio and Son, Hyoung Il and Ha, ChangSu and Bulthoff, Heinrich H. and Giordano, Paolo Robuffo},
	month = aug,
	year = {2013},
	pages = {1334--1345}
}

@article{lenhardt_adaptive_2008,
	title = {An {Adaptive} {P}300-{Based} {Online} {Brain}â{Computer} {Interface}},
	volume = {16},
	issn = {1534-4320, 1558-0210},
	url = {http://ieeexplore.ieee.org/document/4389810/},
	doi = {10.1109/TNSRE.2007.912816},
	number = {2},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Lenhardt, A. and Kaper, M. and Ritter, H.J.},
	month = apr,
	year = {2008},
	pages = {121--130}
}

@incollection{wong_augmented-reality_2010,
	address = {Berlin, Heidelberg},
	title = {An {Augmented}-{Reality} {Based} {Brain}-{Computer} {Interface} for {Robot} {Control}},
	volume = {6444},
	isbn = {9783642175336 9783642175343},
	url = {http://link.springer.com/10.1007/978-3-642-17534-3_8},
	urldate = {2019-09-14},
	booktitle = {Neural {Information} {Processing}. {Models} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lenhardt, Alexander and Ritter, Helge},
	editor = {Wong, Kok Wai and Mendis, B. Sumudu U. and Bouzerdoum, Abdesselam},
	year = {2010},
	doi = {10.1007/978-3-642-17534-3_8},
	pages = {58--65}
}

@inproceedings{li_brain-based_2017,
	address = {New York, NY, USA},
	title = {Brain-{Based} {Computer} {Interfaces} in {Virtual} {Reality}},
	isbn = {9781509066445},
	url = {http://ieeexplore.ieee.org/document/7987213/},
	doi = {10.1109/CSCloud.2017.51},
	urldate = {2019-09-14},
	booktitle = {2017 {IEEE} 4th {International} {Conference} on {Cyber} {Security} and {Cloud} {Computing} ({CSCloud})},
	publisher = {IEEE},
	author = {Li, Sukun and Leider, Avery and Qiu, Meikang and Gai, Keke and Liu, Meiqin},
	month = jun,
	year = {2017},
	pages = {300--305}
}

@article{licklider_man-computer_1960,
	title = {Man-{Computer} {Symbiosis}},
	volume = {HFE-1},
	issn = {0099-4561, 2168-2836},
	url = {http://ieeexplore.ieee.org/document/4503259/},
	doi = {10.1109/THFE2.1960.4503259},
	number = {1},
	urldate = {2019-09-14},
	journal = {IRE Transactions on Human Factors in Electronics},
	author = {Licklider, J. C. R.},
	month = mar,
	year = {1960},
	pages = {4--11}
}

@inproceedings{lindeman_hear-through_2007,
	address = {Nara, Japan},
	title = {Hear-{Through} and {Mic}-{Through} {Augmented} {Reality}: {Using} {Bone} {Conduction} to {Display} {Spatialized} {Audio}},
	doi = {10.1109/ISMAR.2007.4538843},
	publisher = {IEEE},
	author = {Lindeman, R.W. and Noma, H. and de Barros, P.G.},
	month = nov,
	year = {2007}
}

@article{lotte_exploring_2010,
	title = {Exploring {Large} {Virtual} {Environments} by {Thoughts} {Using} a {Brain}â{Computer} {Interface} {Based} on {Motor} {Imagery} and {High}-{Level} {Commands}},
	volume = {19},
	issn = {1054-7460, 1531-3263},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.19.1.54},
	doi = {10.1162/pres.19.1.54},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Lotte, Fabien and van Langhenhove, AurÃ©lien and Lamarche, Fabrice and Ernest, Thomas and Renard, Yann and Arnaldi, Bruno and LÃ©cuyer, Anatole},
	month = feb,
	year = {2010},
	pages = {54--70}
}

@article{jose_luis_mosso_vazquez_brain_2018,
	title = {Brain {Computer} {Interface} : {A} {Future} {Solution} for {Virtual} {Reality} {Navigation} in {Surgery} {Hands} to {Mind} {Control} , {Just} {Thinking}.},
	issn = {2640-9399},
	doi = {http://dx.doi.org/10.31031/DAPM.2018.01.000522},
	journal = {Developments in C Anaesthetics \& Pain Management},
	author = {{Jose Luis Mosso Vazquez} and {Angelica Torres Morales} and {Melissa Garcia}},
	year = {2018},
	pages = {5--8}
}

@article{macdonald_visual_1978,
	title = {Visual influences on speech perception processes},
	volume = {24},
	issn = {0031-5117, 1532-5962},
	url = {http://www.springerlink.com/index/10.3758/BF03206096},
	doi = {10.3758/BF03206096},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {Perception \& Psychophysics},
	author = {Macdonald, John and McGurk, Harry},
	month = may,
	year = {1978},
	pages = {253--257}
}

@inproceedings{machesney_gerontechnology_2014,
	address = {Farmingdale, NY, USA},
	title = {Gerontechnology {Companion}: {Virutal} pets for dementia patients},
	isbn = {9781479938506},
	shorttitle = {Gerontechnology {Companion}},
	url = {http://ieeexplore.ieee.org/document/6845226/},
	doi = {10.1109/LISAT.2014.6845226},
	urldate = {2019-09-14},
	booktitle = {{IEEE} {Long} {Island} {Systems}, {Applications} and {Technology} ({LISAT}) {Conference} 2014},
	publisher = {IEEE},
	author = {Machesney, Dawn and Wexler, Sharon Stahl and Chen, Tony and Coppola, Jean F.},
	month = may,
	year = {2014},
	pages = {1--3}
}

@inproceedings{marin_very_2002,
	address = {Washington, DC, USA},
	title = {A very high level interface to teleoperate a robot via {Web} including augmented reality},
	volume = {3},
	isbn = {9780780372726},
	url = {http://ieeexplore.ieee.org/document/1013644/},
	doi = {10.1109/ROBOT.2002.1013644},
	urldate = {2019-09-14},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.02CH37292)},
	publisher = {IEEE},
	author = {Marin, R. and Sanz, P.J. and Sanchez, J.S.},
	year = {2002},
	pages = {2725--2730}
}

@inproceedings{matthies_earfieldsensing:_2017,
	address = {Denver, Colorado, USA},
	title = {\textit{{EarFieldSensing}}: {A} {Novel} {In}-{Ear} {Electric} {Field} {Sensing} to {Enrich} {Wearable} {Gesture} {Input} through {Facial} {Expressions}},
	isbn = {9781450346559},
	shorttitle = {\textit{{EarFieldSensing}}},
	url = {http://dl.acm.org/citation.cfm?doid=3025453.3025692},
	doi = {10.1145/3025453.3025692},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '17},
	publisher = {ACM Press},
	author = {Matthies, Denys J. C. and Strecker, Bernhard A. and Urban, Bodo},
	year = {2017},
	pages = {1911--1922}
}



@article{paul_milgram_taxonomy_1994,
	title = {A {TAXONOMY} {OF} {MIXED} {REALITY} {VISUAL} {DISPLAYS}},
	volume = { E77-D},
	number = {12},
	journal = {IEICE Transactions on Information Systems},
	author = {{Paul Milgram} and {Fumio Kishino }},
	month = dec,
	year = {1994},
	pages = {1321--1329}
}

@inproceedings{milgram_applications_1993,
	address = {Yokohama, Japan},
	title = {Applications of augmented reality for human-robot communication},
	volume = {3},
	isbn = {9780780308237},
	url = {http://ieeexplore.ieee.org/document/583833/},
	doi = {10.1109/IROS.1993.583833},
	urldate = {2019-09-14},
	booktitle = {Proceedings of 1993 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS} '93)},
	publisher = {IEEE},
	author = {Milgram, P. and Zhai, S. and Drascic, D. and Grodski, J.},
	year = {1993},
	pages = {1467--1472}
}

@article{motti_human_2014,
	title = {Human {Factors} {Considerations} in the {Design} of {Wearable} {Devices}},
	volume = {58},
	issn = {1541-9312},
	url = {http://journals.sagepub.com/doi/10.1177/1541931214581381},
	doi = {10.1177/1541931214581381},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Motti, Vivian Genaro and Caine, Kelly},
	month = sep,
	year = {2014},
	pages = {1820--1824}
}

@book{michael_nelkon_advanced_1998,
	title = {Advanced level physics},
	publisher = {Heinemann Educational},
	author = {{Michael Nelkon} and {P. Parker}},
	year = {1998}
}

@article{nordahl_sound_2011,
	title = {Sound {Synthesis} and {Evaluation} of {Interactive} {Footsteps} and {Environmental} {Sounds} {Rendering} for {Virtual} {Reality} {Applications}},
	volume = {17},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/5708144/},
	doi = {10.1109/TVCG.2011.30},
	number = {9},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Nordahl, Rolf and Turchet, Luca and Serafin, Stefania},
	month = sep,
	year = {2011},
	pages = {1234--1244}
}

@book{norman_design_1990,
	address = {New York},
	edition = {1st Doubleday/Currency ed},
	title = {The design of everyday things},
	isbn = {9780385267748},
	publisher = {Doubleday},
	author = {Norman, Donald A.},
	year = {1990},
	keywords = {Industrial design, Psychological aspects, Human engineering}
}

@article{okamura_haptic_2009,
	title = {Haptic feedback in robot-assisted minimally invasive surgery:},
	volume = {19},
	issn = {0963-0643},
	shorttitle = {Haptic feedback in robot-assisted minimally invasive surgery},
	url = {https://insights.ovid.com/crossref?an=00042307-200901000-00020},
	doi = {10.1097/MOU.0b013e32831a478c},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Current Opinion in Urology},
	author = {Okamura, Allison M},
	month = jan,
	year = {2009},
	pages = {102--107}
}

@article{ott_haptic_2007,
	title = {Haptic feedback in mixed-reality environment},
	volume = {23},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/10.1007/s00371-007-0159-y},
	doi = {10.1007/s00371-007-0159-y},
	language = {en},
	number = {9-11},
	urldate = {2019-09-14},
	journal = {The Visual Computer},
	author = {Ott, Renaud and Thalmann, Daniel and Vexo, FrÃ©dÃ©ric},
	month = aug,
	year = {2007},
	pages = {843--849}
}

@inproceedings{outram_synesthesia_2016,
	address = {Greenville, SC, USA},
	title = {Synesthesia audio-visual interactive-sound and music visualization in virtual reality with orbital observation and navigation},
	isbn = {9781509013753},
	url = {http://ieeexplore.ieee.org/document/7858997/},
	doi = {10.1109/MIXRA.2016.7858997},
	urldate = {2019-09-14},
	booktitle = {2016 {IEEE} {International} {Workshop} on {Mixed} {Reality} {Art} ({MRA})},
	publisher = {IEEE},
	author = {Outram, Benjamin I.},
	month = mar,
	year = {2016},
	pages = {7--8}
}

@inproceedings{pacchierotti_hring:_2016,
	address = {Philadelphia, PA, USA},
	title = {The {hRing}: {A} wearable haptic device to avoid occlusions in hand tracking},
	isbn = {9781509009039},
	shorttitle = {The {hRing}},
	url = {http://ieeexplore.ieee.org/document/7463167/},
	doi = {10.1109/HAPTICS.2016.7463167},
	urldate = {2019-09-14},
	booktitle = {2016 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	publisher = {IEEE},
	author = {Pacchierotti, Claudio and Salvietti, Gionata and Hussain, Irfan and Meli, Leonardo and Prattichizzo, Domenico},
	month = apr,
	year = {2016},
	pages = {134--139}
}

@article{hangue_park_wireless_2012,
	title = {A {Wireless} {Magnetoresistive} {Sensing} {System} for an {Intraoral} {Tongue}-{Computer} {Interface}},
	volume = {6},
	issn = {1932-4545, 1940-9990},
	url = {http://ieeexplore.ieee.org/document/6392916/},
	doi = {10.1109/TBCAS.2012.2227962},
	number = {6},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Biomedical Circuits and Systems},
	author = {{Hangue Park} and Kiani, M. and {Hyung-Min Lee} and {Jeonghee Kim} and Block, J. and Gosselin, B. and Ghovanloo, M.},
	month = dec,
	year = {2012},
	pages = {571--585}
}

@article{parra_is_2007,
	title = {Is colour modulation an independent factor in human visual photosensitivity?},
	volume = {130},
	issn = {1460-2156, 0006-8950},
	url = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awm103},
	doi = {10.1093/brain/awm103},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {Brain},
	author = {Parra, Jaime and Lopes da Silva, Fernando H. and Stroink, Hans and Kalitzin, Stiliyan},
	month = jun,
	year = {2007},
	pages = {1679--1689}
}

@inproceedings{patil_e-learning_2016,
	address = {Pune, India},
	title = {E-learning system using {Augmented} {Reality}},
	isbn = {9781509032914},
	url = {http://ieeexplore.ieee.org/document/7860038/},
	doi = {10.1109/ICCUBEA.2016.7860038},
	urldate = {2019-09-14},
	booktitle = {2016 {International} {Conference} on {Computing} {Communication} {Control} and automation ({ICCUBEA})},
	publisher = {IEEE},
	author = {Patil, Siddhant and Prabhu, Chiquitha and Neogi, Omkar and Joshi, Abhijit R. and Katre, Neha},
	month = aug,
	year = {2016},
	pages = {1--5}
}

@article{pauly_machine_2015,
	title = {Machine learning-based augmented reality for improved surgical scene understanding},
	volume = {41},
	issn = {08956111},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611114001001},
	doi = {10.1016/j.compmedimag.2014.06.007},
	language = {en},
	urldate = {2019-09-14},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Pauly, Olivier and Diotte, Benoit and Fallavollita, Pascal and Weidert, Simon and Euler, Ekkehard and Navab, Nassir},
	month = apr,
	year = {2015},
	pages = {55--60}
}

@article{pfurtscheller_motor_2001,
	title = {Motor imagery and direct brain-computer communication},
	volume = {89},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/939829/},
	doi = {10.1109/5.939829},
	number = {7},
	urldate = {2019-09-14},
	journal = {Proceedings of the IEEE},
	author = {Pfurtscheller, G. and Neuper, C.},
	month = jul,
	year = {2001},
	pages = {1123--1134}
}

@article{prattichizzo_cutaneous_2012,
	title = {Cutaneous {Force} {Feedback} as a {Sensory} {Subtraction} {Technique} in {Haptics}},
	volume = {5},
	issn = {1939-1412},
	url = {http://ieeexplore.ieee.org/document/6175016/},
	doi = {10.1109/TOH.2012.15},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Haptics},
	author = {Prattichizzo, D. and Pacchierotti, C. and Rosati, G.},
	year = {2012},
	pages = {289--300}
}

@inproceedings{ranasinghe_virtual_2016,
	address = {Tokyo, Japan},
	title = {Virtual {Sweet}: {Simulating} {Sweet} {Sensation} {Using} {Thermal} {Stimulation} on the {Tip} of the {Tongue}},
	isbn = {9781450345316},
	shorttitle = {Virtual {Sweet}},
	url = {http://dl.acm.org/citation.cfm?doid=2984751.2985729},
	doi = {10.1145/2984751.2985729},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology} - {UIST} '16 {Adjunct}},
	publisher = {ACM Press},
	author = {Ranasinghe, Nimesha and Do, Ellen Yi-Luen},
	year = {2016},
	pages = {127--128}
}

@inproceedings{ranasinghe_season_2018,
	address = {Montreal QC, Canada},
	title = {Season {Traveller}: {Multisensory} {Narration} for {Enhancing} the {Virtual} {Reality} {Experience}},
	isbn = {9781450356206},
	shorttitle = {Season {Traveller}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174151},
	doi = {10.1145/3173574.3174151},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Ranasinghe, Nimesha and Eason Wai Tung, Chow and Yen, Ching Chiuan and Do, Ellen Yi-Luen and Jain, Pravar and Thi Ngoc Tram, Nguyen and Koh, Koon Chuan Raymond and Tolley, David and Karwita, Shienny and Lien-Ya, Lin and Liangkun, Yan and Shamaiah, Kala},
	year = {2018},
	pages = {1--13}
}

@inproceedings{rawat_evaluating_2016,
	address = {Moradabad, India},
	title = {Evaluating and exploring the {MYO} {ARMBAND}},
	isbn = {9781509035434},
	url = {http://ieeexplore.ieee.org/document/7894501/},
	doi = {10.1109/SYSMART.2016.7894501},
	urldate = {2019-09-14},
	booktitle = {2016 {International} {Conference} {System} {Modeling} \& {Advancement} in {Research} {Trends} ({SMART})},
	publisher = {IEEE},
	author = {Rawat, Seema and Vats, Somya and Kumar, Praveen},
	year = {2016},
	pages = {115--120}
}

@article{rekimoto_navicam:magnifying_1997,
	title = {{NaviCam}:{A} {Magnifying} {Glass} {Approach} to {Augmented} {Reality}},
	volume = {6},
	issn = {1054-7460, 1531-3263},
	shorttitle = {{NaviCam}},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.399},
	doi = {10.1162/pres.1997.6.4.399},
	language = {en},
	number = {4},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Rekimoto, Jun},
	month = aug,
	year = {1997},
	pages = {399--412}
}

@inproceedings{richard_augmented_2007,
	address = {Venice, Italy},
	title = {Augmented {Reality} for {Rehabilitation} of {Cognitive} {Disabled} {Children}: {A} {Preliminary} {Study}},
	isbn = {9781424412037},
	shorttitle = {Augmented {Reality} for {Rehabilitation} of {Cognitive} {Disabled} {Children}},
	url = {http://ieeexplore.ieee.org/document/4362148/},
	doi = {10.1109/ICVR.2007.4362148},
	urldate = {2019-09-14},
	booktitle = {2007 {Virtual} {Rehabilitation}},
	publisher = {IEEE},
	author = {Richard, E. and Billaudeau, V. and Richard, P. and Gaudin, G.},
	month = sep,
	year = {2007},
	pages = {102--108}
}

@article{richards_audiovisual_2019,
	title = {Audiovisual perception in amblyopia: {A} review and synthesis},
	volume = {183},
	issn = {00144835},
	shorttitle = {Audiovisual perception in amblyopia},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0014483518301404},
	doi = {10.1016/j.exer.2018.04.017},
	language = {en},
	urldate = {2019-09-14},
	journal = {Experimental Eye Research},
	author = {Richards, Michael D. and Goltz, Herbert C. and Wong, Agnes M.F.},
	month = jun,
	year = {2019},
	pages = {68--75}
}

@article{rosenblum_virtual_2000,
	title = {Virtual and augmented reality 2020},
	volume = {20},
	issn = {02721716},
	url = {http://ieeexplore.ieee.org/document/814551/},
	doi = {10.1109/38.814551},
	number = {1},
	urldate = {2019-09-14},
	journal = {IEEE Computer Graphics and Applications},
	author = {Rosenblum, L.},
	month = feb,
	year = {2000},
	pages = {38--39}
}

@article{satyanarayanan_pervasive_2001,
	title = {Pervasive computing: vision and challenges},
	volume = {8},
	issn = {10709916},
	shorttitle = {Pervasive computing},
	url = {http://ieeexplore.ieee.org/document/943998/},
	doi = {10.1109/98.943998},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE Personal Communications},
	author = {Satyanarayanan, M.},
	month = aug,
	year = {2001},
	pages = {10--17}
}

@article{satyanarayanan_case_2009,
	title = {The {Case} for {VM}-{Based} {Cloudlets} in {Mobile} {Computing}},
	volume = {8},
	issn = {1536-1268},
	url = {http://ieeexplore.ieee.org/document/5280678/},
	doi = {10.1109/MPRV.2009.82},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE Pervasive Computing},
	author = {Satyanarayanan, M. and Bahl, P. and Caceres, R. and Davies, N.},
	month = oct,
	year = {2009},
	pages = {14--23}
}

@article{schalk_bci2000:_2004,
	title = {{BCI}2000: {A} {General}-{Purpose} {Brain}-{Computer} {Interface} ({BCI}) {System}},
	volume = {51},
	issn = {0018-9294},
	shorttitle = {{BCI}2000},
	url = {http://ieeexplore.ieee.org/document/1300799/},
	doi = {10.1109/TBME.2004.827072},
	language = {en},
	number = {6},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Schalk, G. and McFarland, D.J. and Hinterberger, T. and Birbaumer, N. and Wolpaw, J.R.},
	month = jun,
	year = {2004},
	pages = {1034--1043}
}

@inproceedings{serafin_considerations_2017,
	address = {Los Angeles, CA, USA},
	title = {Considerations on the use of virtual and augmented reality technologies in music education},
	isbn = {9781538618929},
	url = {http://ieeexplore.ieee.org/document/7961562/},
	doi = {10.1109/KELVAR.2017.7961562},
	urldate = {2019-09-14},
	booktitle = {2017 {IEEE} {Virtual} {Reality} {Workshop} on {K}-12 {Embodied} {Learning} through {Virtual} \& {Augmented} {Reality} ({KELVAR})},
	publisher = {IEEE},
	author = {Serafin, Stefania and Adjorlu, Ali and Nilsson, Niels and Thomsen, Lui and Nordahl, Rolf},
	month = mar,
	year = {2017},
	pages = {1--4}
}

@article{seufert_memory_2009,
	title = {Memory characteristics and modality in multimedia learning: {An} aptitudeâtreatmentâinteraction study},
	volume = {19},
	issn = {09594752},
	shorttitle = {Memory characteristics and modality in multimedia learning},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959475208000121},
	doi = {10.1016/j.learninstruc.2008.01.002},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Learning and Instruction},
	author = {Seufert, Tina and SchÃŒtze, Maren and BrÃŒnken, Roland},
	month = feb,
	year = {2009},
	pages = {28--42}
}

@inproceedings{h._si-mohammed_brain-computer_nodate,
	address = {England},
	title = {{BRAIN}-{COMPUTER} {INTERFACES} {AND} {AUGMENTED} {REALITY}: {A} {STATE} {OF} {THE} {ART}},
	doi = {10.3217/978-3-85125-533-1-82},
	author = {{H. Si-Mohammed} and { F. Argelaguet} and { G. Casiez} and {N. Roussel} and {A. LÃ©cuyer}}
}



@article{si-mohammed_towards_2018,
	title = {Towards {BCI}-based {Interfaces} for {Augmented} {Reality}: {Feasibility}, {Design} and {Evaluation}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Towards {BCI}-based {Interfaces} for {Augmented} {Reality}},
	url = {https://ieeexplore.ieee.org/document/8481564/},
	doi = {10.1109/TVCG.2018.2873737},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Si-Mohammed, Hakim and Petit, Jimmy and Jeunet, Camille and Argelaguet, Ferran and Spindler, Fabien and Evain, Andeol and Roussel, Nicolas and Casiez, Gery and Lecuyer, Anatole},
	year = {2018},
	pages = {1--1}
}

@article{starner_augmented_1997,
	title = {Augmented {Reality} through {Wearable} {Computing}},
	volume = {6},
	issn = {1054-7460, 1531-3263},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.386},
	doi = {10.1162/pres.1997.6.4.386},
	language = {en},
	number = {4},
	urldate = {2019-09-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Starner, Thad and Mann, Steve and Rhodes, Bradley and Levine, Jeffrey and Healey, Jennifer and Kirsch, Dana and Picard, Rosalind W. and Pentland, Alex},
	month = aug,
	year = {1997},
	pages = {386--398}
}

@inproceedings{sundareswaran_3d_2003,
	address = {Tokyo, Japan},
	title = {3D audio augmented reality: implementation and experiments},
	isbn = {9780769520063},
	shorttitle = {3D audio augmented reality},
	url = {http://ieeexplore.ieee.org/document/1240728/},
	doi = {10.1109/ISMAR.2003.1240728},
	urldate = {2019-09-14},
	booktitle = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
	publisher = {IEEE Comput. Soc},
	author = {Sundareswaran, V. and Wang, K. and Chen, S. and Behringer, R. and McGee, J. and Tam, C. and Zahorik, P.},
	year = {2003},
	pages = {296--297}
}

@inproceedings{amir_m._tahmasebi_dynamic_2005,
	address = {Toronto, Canada},
	title = {Dynamic parameter identification and analysis of a {PHANToM} haptic device},
	isbn = {9780780393547},
	url = {http://ieeexplore.ieee.org/document/1507303/},
	doi = {10.1109/CCA.2005.1507303},
	urldate = {2019-09-14},
	booktitle = {Proceedings of 2005 {IEEE} {Conference} on {Control} {Applications}, 2005. {CCA} 2005.},
	publisher = {IEEE},
	author = {Amir M. Tahmasebi, Babak Taati},
	year = {2005},
	pages = {1251--1256}
}

@article{takano_towards_2011,
	title = {Towards {Intelligent} {Environments}: {An} {Augmented} {Reality}â{Brain}â{Machine} {Interface} {Operated} with a {See}-{Through} {Head}-{Mount} {Display}},
	volume = {5},
	issn = {1662-4548},
	shorttitle = {Towards {Intelligent} {Environments}},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2011.00060/abstract},
	doi = {10.3389/fnins.2011.00060},
	urldate = {2019-09-14},
	journal = {Frontiers in Neuroscience},
	author = {Takano, Kouji and Hata, Naoki and Kansaku, Kenji},
	year = {2011}
}

@article{haar_ultrasound_2010,
	title = {Ultrasound bioeffects and safety},
	volume = {224},
	issn = {0954-4119, 2041-3033},
	url = {http://journals.sagepub.com/doi/10.1243/09544119JEIM613},
	doi = {10.1243/09544119JEIM613},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
	author = {Haar, G ter},
	month = feb,
	year = {2010},
	pages = {363--373}
}

@inproceedings{hussain_tinwala_eyes-free_2009,
	title = {Eyes-free text entry on a touchscreen phone},
	url = {http://dx.doi.org/10.1109/TIC-STH.2009.5444381},
	doi = {10.1109/TIC-STH.2009.5444381},
	author = {{Hussain Tinwala} and {I. Scott MacKenzie}},
	month = oct,
	year = {2009},
	pages = {83 -- 88}
}

@book{vanderah_noltes_2016,
	address = {Philadelphia, PA},
	edition = {Seventh edition},
	title = {Nolte's {The} human brain: an introduction to its functional anatomy},
	isbn = {9781455728596},
	shorttitle = {Nolte's {The} human brain},
	publisher = {Elsevier},
	author = {Vanderah, Todd W. and Gould, Douglas J. and Nolte, John},
	year = {2016},
	keywords = {Central Nervous System, anatomy \& histology, Brain, anatomy \& histology, Nervous System Physiological Phenomena}
}

@article{townsend_novel_2010,
	title = {A novel {P}300-based brainâcomputer interface stimulus presentation paradigm: {Moving} beyond rows and columns},
	volume = {121},
	issn = {13882457},
	shorttitle = {A novel {P}300-based brainâcomputer interface stimulus presentation paradigm},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1388245710000738},
	doi = {10.1016/j.clinph.2010.01.030},
	language = {en},
	number = {7},
	urldate = {2019-09-14},
	journal = {Clinical Neurophysiology},
	author = {Townsend, G. and LaPallo, B.K. and Boulay, C.B. and Krusienski, D.J. and Frye, G.E. and Hauser, C.K. and Schwartz, N.E. and Vaughan, T.M. and Wolpaw, J.R. and Sellers, E.W.},
	month = jul,
	year = {2010},
	pages = {1109--1120}
}

@inproceedings{uchiyama_mr_2002,
	address = {Darmstadt, Germany},
	title = {{MR} {Platform}: a basic body on which mixed reality applications are built},
	isbn = {9780769517810},
	shorttitle = {{MR} {Platform}},
	url = {http://ieeexplore.ieee.org/document/1115095/},
	doi = {10.1109/ISMAR.2002.1115095},
	urldate = {2019-09-14},
	booktitle = {Proceedings. {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Comput. Soc},
	author = {Uchiyama, S. and Takemoto, K. and Satoh, K. and Yamamoto, H. and Tamura, H.},
	year = {2002},
	pages = {246--320}
}

@article{vaidya_industry_2018,
	title = {Industry 4.0 â {A} {Glimpse}},
	volume = {20},
	issn = {23519789},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2351978918300672},
	doi = {10.1016/j.promfg.2018.02.034},
	language = {en},
	urldate = {2019-09-14},
	journal = {Procedia Manufacturing},
	author = {Vaidya, Saurabh and Ambad, Prashant and Bhosle, Santosh},
	year = {2018},
	pages = {233--238}
}

@inproceedings{annie_joyce_vullamparthi_assistive_2013,
	title = {Assistive {Learning} for {Children} with {Autism} using {Augmented} {Reality} },
	url = {http://dx.doi.org/10.1109/T4E.2013.18},
	doi = {10.1109/T4E.2013.18},
	author = {{Annie Joyce Vullamparthi} and { Sarat Chandra Babu Nelaturu } and {Dakshayani D Mallaya} and {Chandrasekhar S.}},
	year = {2013}
}

@article{waldert_invasive_2016,
	title = {Invasive vs. {Non}-{Invasive} {Neuronal} {Signals} for {Brain}-{Machine} {Interfaces}: {Will} {One} {Prevail}?},
	volume = {10},
	issn = {1662-453X},
	shorttitle = {Invasive vs. {Non}-{Invasive} {Neuronal} {Signals} for {Brain}-{Machine} {Interfaces}},
	url = {http://journal.frontiersin.org/Article/10.3389/fnins.2016.00295/abstract},
	doi = {10.3389/fnins.2016.00295},
	urldate = {2019-09-14},
	journal = {Frontiers in Neuroscience},
	author = {Waldert, Stephan},
	month = jun,
	year = {2016}
}

@article{wang_conceptual_2018,
	title = {A {Conceptual} {Design} for {Smell} {Based} {Augmented} {Reality}: {Case} {Study} in {Maintenance} {Diagnosis}},
	volume = {78},
	issn = {22128271},
	shorttitle = {A {Conceptual} {Design} for {Smell} {Based} {Augmented} {Reality}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2212827118312472},
	doi = {10.1016/j.procir.2018.09.067},
	language = {en},
	urldate = {2019-09-14},
	journal = {Procedia CIRP},
	author = {Wang, Jeff and Erkoyuncu, John and Roy, Rajkumar},
	year = {2018},
	pages = {109--114}
}

@article{wang_self-paced_2012,
	title = {Self-paced brainâcomputer interface control of ambulation in a virtual reality environment},
	volume = {9},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/9/i=5/a=056016?key=crossref.a886b904b0269fc0852e04b012d6ed4c},
	doi = {10.1088/1741-2560/9/5/056016},
	number = {5},
	urldate = {2019-09-14},
	journal = {Journal of Neural Engineering},
	author = {Wang, Po T and King, Christine E and Chui, Luis A and Do, An H and Nenadic, Zoran},
	month = oct,
	year = {2012},
	pages = {056016}
}

@incollection{wang_co-presence_2011,
	address = {Dordrecht},
	title = {Co-presence in {Mixed} {Reality}-{Mediated} {Collaborative} {Design} {Space}},
	isbn = {9789400706040 9789400706057},
	url = {http://www.springerlink.com/index/10.1007/978-94-007-0605-7_5},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Collaborative {Design} in {Virtual} {Environments}},
	publisher = {Springer Netherlands},
	author = {Wang, Xiangyu and Wang, Rui},
	editor = {Wang, Xiangyu and Tsai, Jerry Jen-Hung},
	year = {2011},
	doi = {10.1007/978-94-007-0605-7_5},
	pages = {51--64}
}

@article{weichert_analysis_2013,
	title = {Analysis of the {Accuracy} and {Robustness} of the {Leap} {Motion} {Controller}},
	volume = {13},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/13/5/6380},
	doi = {10.3390/s130506380},
	language = {en},
	number = {5},
	urldate = {2019-09-14},
	journal = {Sensors},
	author = {Weichert, Frank and Bachmann, Daniel and Rudak, BartholomÃ€us and Fisseler, Denis},
	month = may,
	year = {2013},
	pages = {6380--6393}
}

@inproceedings{wenig_watchthru:_2017,
	address = {Denver, Colorado, USA},
	title = {{WatchThru}: {Expanding} {Smartwatch} {Displays} with {Mid}-air {Visuals} and {Wrist}-worn {Augmented} {Reality}},
	isbn = {9781450346559},
	shorttitle = {{WatchThru}},
	url = {http://dl.acm.org/citation.cfm?doid=3025453.3025852},
	doi = {10.1145/3025453.3025852},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '17},
	publisher = {ACM Press},
	author = {Wenig, Dirk and SchÃ¶ning, Johannes and Olwal, Alex and Oben, Mathias and Malaka, Rainer},
	year = {2017},
	pages = {716--721}
}

@inproceedings{wolf_care:_2018,
	address = {Berlin, Germany},
	title = {{cARe}: {An} {Augmented} {Reality} {Support} {System} for {Dementia} {Patients}},
	isbn = {9781450359498},
	shorttitle = {{cARe}},
	url = {http://dl.acm.org/citation.cfm?doid=3266037.3266095},
	doi = {10.1145/3266037.3266095},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} {Adjunct} {Proceedings}  - {UIST} '18 {Adjunct}},
	publisher = {ACM Press},
	author = {Wolf, Dennis and Besserer, Daniel and Sejunaite, Karolina and Riepe, Matthias and Rukzio, Enrico},
	year = {2018},
	pages = {42--44}
}

@book{wolpaw_braincomputer_2012,
	title = {Brainâ{Computer} {InterfacesPrinciples} and {Practice}},
	isbn = {9780195388855},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195388855.001.0001/acprof-9780195388855},
	urldate = {2019-09-14},
	publisher = {Oxford University Press},
	author = {Wolpaw, Jonathan and Wolpaw, Elizabeth Winter},
	month = jan,
	year = {2012},
	doi = {10.1093/acprof:oso/9780195388855.001.0001}
}

@inproceedings{yamada_weighted_1992,
	address = {Tucson, AZ, USA},
	title = {Weighted conical transducer for generation of {Bessel} beam ultrasound},
	isbn = {9780780305625},
	url = {http://ieeexplore.ieee.org/document/275927/},
	doi = {10.1109/ULTSYM.1992.275927},
	urldate = {2019-09-14},
	booktitle = {{IEEE} 1992 {Ultrasonics} {Symposium} {Proceedings}},
	publisher = {IEEE},
	author = {Yamada, K. and Tasei, K. and Nakamura, K.},
	year = {1992},
	pages = {613--618}
}

@inproceedings{yamada_wearable_2006,
	address = {Alexandria, VA, USA},
	title = {Wearable {Olfactory} {Display}: {Using} {Odor} in {Outdoor} {Environment}},
	isbn = {9781424402243},
	shorttitle = {Wearable {Olfactory} {Display}},
	url = {http://ieeexplore.ieee.org/document/1667645/},
	doi = {10.1109/VR.2006.147},
	urldate = {2019-09-14},
	booktitle = {{IEEE} {Virtual} {Reality} {Conference} ({VR} 2006)},
	publisher = {IEEE},
	author = {Yamada, T. and Yokoyama, S. and Tanikawa, T. and Hirota, K. and Hirose, M.},
	year = {2006},
	pages = {199--206}
}

@inproceedings{yanagida_projection_2004,
	address = {Chicago, IL, USA},
	title = {Projection based olfactory display with nose tracking},
	isbn = {9780780384156},
	url = {http://ieeexplore.ieee.org/document/1310054/},
	doi = {10.1109/VR.2004.1310054},
	urldate = {2019-09-14},
	booktitle = {{IEEE} {Virtual} {Reality} 2004},
	publisher = {IEEE},
	author = {Yanagida, Y. and Kawato, S. and Noma, H. and Tomono, A. and Tesutani, N.},
	year = {2004},
	pages = {43--50}
}

@article{yao_headphone-based_2017,
	title = {Headphone-based immersive audio for virtual reality headsets},
	volume = {63},
	issn = {0098-3063},
	url = {http://ieeexplore.ieee.org/document/8103379/},
	doi = {10.1109/TCE.2017.014951},
	number = {3},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Yao, Shu-Nung},
	month = aug,
	year = {2017},
	pages = {300--308}
}

@article{feng_zhou_trends_2008,
	title = {Trends in {Augmented} {Reality} {Tracking}, {Interaction} and {Display}: {A} {Review} of {Ten} {Years} of {ISMAR}},
	doi = {http://dx.doi.org/10.1109/ISMAR.2008.4637362},
	journal = {7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
	author = {{Feng Zhou} and {Henry Duh} and {Mark Billinghurst}},
	year = {2008},
	pages = {193--202}
}


@INPROCEEDINGS{4538847,
author={K. {Higa} and T. {Nishiura} and A. {Kimura} and F. {Shibata} and H. {Tamura}},
booktitle={2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
title={A Two-by-Two Mixed Reality System That Merges Real and Virtual Worlds in Both Audio and Visual Senses},
year={2007},
volume={},
number={},
pages={203-206},
keywords={virtual reality;two-by-two mixed reality system;virtual reality;geometric consistency;audio sense;closed-air headphones;Virtual reality;Headphones;Auditory displays;Real time systems;Optical sensors;Computer displays;Merging;Layout;Humans;Chromium;Mixed Reality;Audio and Visual Senses;Geometric Consistency;Open-Air Headphones;Closed-Air Headphones},
doi={10.1109/ISMAR.2007.4538847},
ISSN={},
month={Nov},}

@inproceedings{Flintham:2003:OMS:642611.642710,
 author = {Flintham, Martin and Benford, Steve and Anastasi, Rob and Hemmings, Terry and Crabtree, Andy and Greenhalgh, Chris and Tandavanitj, Nick and Adams, Matt and Row-Farr, Ju},
 title = {Where On-line Meets on the Streets: Experiences with Mobile Mixed Reality Games},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '03},
 year = {2003},
 isbn = {1-58113-630-7},
 location = {Ft. Lauderdale, Florida, USA},
 pages = {569--576},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/642611.642710},
 doi = {10.1145/642611.642710},
 acmid = {642710},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Brown:2003:LLC:642611.642711,
 author = {Brown, Barry and MacColl, Ian and Chalmers, Matthew and Galani, Areti and Randell, Cliff and Steed, Anthony},
 title = {Lessons from the Lighthouse: Collaboration in a Shared Mixed Reality System},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '03},
 year = {2003},
 isbn = {1-58113-630-7},
 location = {Ft. Lauderdale, Florida, USA},
 pages = {577--584},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/642611.642711},
 doi = {10.1145/642611.642711},
 acmid = {642711},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {WWW, context-awareness, location-awareness, mixed reality, museum visiting, virtual reality},
} 

@Article{Bulman2004,
author="Bulman, J.
and Crabtree, B.
and Gower, A.
and Oldroyd, A.
and Lawson, M.
and Sutton, J.",
title="Mixed Reality Applications in Urban Environments",
journal="BT Technology Journal",
year="2004",
month="Jul",
day="01",
volume="22",
number="3",
pages="84--94",
abstract="Mixed reality applications are concerned with blurring the divide between the real and virtual, where the user perception of the real world is contextually enhanced with additional information. This paper will provide an overview of three related projects that explore opportunities for how virtual reality and mixed reality technologies can be effectively used across consumer, industrial and military domains. A common theme is dealing with the amount of data that can be potentially displayed in the applications.",
issn="1573-1995",
doi="10.1023/B:BTTJ.0000047123.94280.3a",
url="https://doi.org/10.1023/B:BTTJ.0000047123.94280.3a"
}

@inproceedings{Koleva:2001:OMR:365024.365033,
 author = {Koleva, Boriana and Taylor, Ian and Benford, Steve and Fraser, Mike and Greenhalgh, Chris and Schn\"{a}delbach, Holger and vom Lehn, Dirk and Heath, Christian and Row-Farr, Ju and Adams, Matt},
 title = {Orchestrating a Mixed Reality Performance},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '01},
 year = {2001},
 isbn = {1-58113-327-8},
 location = {Seattle, Washington, USA},
 pages = {38--45},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/365024.365033},
 doi = {10.1145/365024.365033},
 acmid = {365033},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mixed reality, performance, traversable interfaces},
} 

@inproceedings{Grasset:2008:DMB:1605298.1605354,
 author = {Grasset, Raphael and Dunser, Andreas and Billinghurst, Mark},
 title = {The Design of a Mixed-reality Book: Is It Still a Real Book?},
 booktitle = {Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
 series = {ISMAR '08},
 year = {2008},
 isbn = {978-1-4244-2840-3},
 pages = {99--102},
 numpages = {4},
 url = {https://doi.org/10.1109/ISMAR.2008.4637333},
 doi = {10.1109/ISMAR.2008.4637333},
 acmid = {1605354},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@INPROCEEDINGS{7495414,
author={T. {Chatzidimitris} and D. {Gavalas} and D. {Michael}},
booktitle={2016 18th Mediterranean Electrotechnical Conference (MELECON)},
title={SoundPacman: Audio augmented reality in location-based games},
year={2016},
volume={},
number={},
pages={1-6},
keywords={audio acoustics;augmented reality;biology computing;computer games;electroencephalography;medical computing;SoundPacman;audio augmented reality;sound design;location-based games research;visual information;game information;3D sounds;EEG analysis;immersion levels;players;Games;Three-dimensional displays;Engines;Servers;Prototypes;Roads;Augmented reality;pervasive games;augmented reality;3D sound;location-based games;EEG},
doi={10.1109/MELCON.2016.7495414},
ISSN={},
month={April},}

@inproceedings{Schnadelbach:2002:AMR:503376.503379,
 author = {Schn\"{a}delbach, Holger and Koleva, Boriana and Flintham, Martin and Fraser, Mike and Izadi, Shahram and Chandler, Paul and Foster, Malcolm and Benford, Steve and Greenhalgh, Chris and Rodden, Tom and Rodden, Tom},
 title = {The Augurscope: A Mixed Reality Interface for Outdoors},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '02},
 year = {2002},
 isbn = {1-58113-453-3},
 location = {Minneapolis, Minnesota, USA},
 pages = {9--16},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/503376.503379},
 doi = {10.1145/503376.503379},
 acmid = {503379},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, mixed reality, mobile and wireless applications, outdoors applications, virtual reality},
} 

@inproceedings{Komninos:2012:UEU:2371574.2371629,
 author = {Komninos, Andreas and Barrie, Peter and Stefanis, Vassilios and Plessas, Athanasios},
 title = {Urban Exploration Using Audio Scents},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services},
 series = {MobileHCI '12},
 year = {2012},
 isbn = {978-1-4503-1105-2},
 location = {San Francisco, California, USA},
 pages = {349--358},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2371574.2371629},
 doi = {10.1145/2371574.2371629},
 acmid = {2371629},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {audio mixed reality, implicit navigation, urban environments},
} 

@inproceedings{Crabtree:2004:OMR:985692.985742,
 author = {Crabtree, Andy and Benford, Steve and Rodden, Tom and Rodden, Tom and Greenhalgh, Chris and Flintham, Martin and Anastasi, Rob and Drozd, Adam and Adams, Matt and Row-Farr, Ju and Tandavanitj, Nick and Steed, Anthony and Steed, Anthony},
 title = {Orchestrating a Mixed Reality Game 'on the Ground'},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '04},
 year = {2004},
 isbn = {1-58113-702-8},
 location = {Vienna, Austria},
 pages = {391--398},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/985692.985742},
 doi = {10.1145/985692.985742},
 acmid = {985742},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GPS, ethnography, mobile \& wireless games, orchestration},
} 

@InProceedings{10.1007/978-3-642-02771-0_37,
author="Kagimoto, Mami
and Kimura, Asako
and Shibata, Fumihisa
and Tamura, Hideyuki",
editor="Shumaker, Randall",
title="Analysis of Tactual Impression by Audio and Visual Stimulation for User Interface Design in Mixed Reality Environment",
booktitle="Virtual and Mixed Reality",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="326--335",
abstract="In a mixed-reality (MR) environment, a touchable object can be made to change its appearance when a computer-generated image (MR visual stimulation) is superimposed onto it. In this research, we conduct experiments to study the effects of MR visual and audio stimuli on the tactual impression of the ``roughness'' of an object. We show that MR visual stimulation alters a subject's tactual impression of the roughness of an object and that the addition of MR audio stimulation intensifies that effect.",
isbn="978-3-642-02771-0"
}

@Article{Birchfield2009,
author="Birchfield, David
and Megowan-Romanowicz, Colleen",
title="Earth science learning in SMALLab: A design experiment for mixed reality",
journal="International Journal of Computer-Supported Collaborative Learning",
year="2009",
month="Dec",
day="01",
volume="4",
number="4",
pages="403--421",
abstract="Conversational technologies such as email, chat rooms, and blogs have made the transition from novel communication technologies to powerful tools for learning. Currently virtual worlds are undergoing the same transition. We argue that the next wave of innovation is at the level of the computer interface, and that mixed-reality environments offer important advantages over prior technologies. Thus, mixed reality is positioned to have a broad impact on the future of K-12 collaborative learning. We propose three design imperatives that arise from our ongoing work in this area grounded in research from the learning sciences and human-computer interaction. By way of example, we present one such platform, the Situated Multimedia Arts Learning Lab [SMALLab]. SMALLab is a mixed-reality environment that affords face-to-face interaction by colocated participants within a mediated space. We present a recent design experiment that involved the development of a new SMALLab learning scenario and a collaborative student participation framework for a 3-day intervention for 72 high school earth science students. We analyzed student and teacher exchanges from classroom sessions both during the intervention and during regular classroom instruction and found significant increases in the number of student-driven exchanges within SMALLab. We also found that students made significant achievement gains. We conclude that mixed reality can have a positive impact on collaborative learning and that it is poised for broad dissemination into mainstream K-12 contexts.",
issn="1556-1615",
doi="10.1007/s11412-009-9074-8",
url="https://doi.org/10.1007/s11412-009-9074-8"
}

@inproceedings{Langlotz:2013:ASV:2541016.2541022,
 author = {Langlotz, Tobias and Regenbrecht, Holger and Zollmann, Stefanie and Schmalstieg, Dieter},
 title = {Audio Stickies: Visually-guided Spatial Audio Annotations on a Mobile Augmented Reality Platform},
 booktitle = {Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration},
 series = {OzCHI '13},
 year = {2013},
 isbn = {978-1-4503-2525-7},
 location = {Adelaide, Australia},
 pages = {545--554},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2541016.2541022},
 doi = {10.1145/2541016.2541022},
 acmid = {2541022},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, mobile phone, spatial audio},
} 

@article{ZHOU20041043,
title = "An experimental study on the role of 3D sound in augmented reality environment",
journal = "Interacting with Computers",
volume = "16",
number = "6",
pages = "1043 - 1068",
year = "2004",
issn = "0953-5438",
doi = "https://doi.org/10.1016/j.intcom.2004.06.016",
url = "http://www.sciencedirect.com/science/article/pii/S0953543804000864",
author = "Zhiying Zhou and Adrian David Cheok and Xubo Yang and Yan Qiu",
keywords = "3D sound, Augmented reality, User study",
abstract = "Investigation of augmented reality (AR) environments has become a popular research topic for engineers, computer and cognitive scientists. Although application oriented studies focused on audio AR environments have been published, little work has been done to vigorously study and evaluate the important research questions of the effectiveness of three-dimensional (3D) sound in the AR context, and to what extent the addition of 3D sound would contribute to the AR experience. Thus, we have developed two AR environments and performed vigorous experiments with human subjects to study the effects of 3D sound in the AR context. The study concerns two scenarios. In the first scenario, one participant must use vision only and vision with 3D sound to judge the relative depth of augmented virtual objects. In the second scenario, two participants must cooperate to perform a joint task in a game-based AR environment. Hence, the goals of this study are (1) to access the impact of 3D sound on depth perception in a single-camera AR environment, (2) to study the impact of 3D sound on task performance and the feeling of ‘human presence and collaboration’, (3) to better understand the role of 3D sound in human–computer and human–human interactions, (4) to investigate if gender can affect the impact of 3D sound in AR environments. The outcomes of this research can have a useful impact on the development of audio AR systems, which provide more immersive, realistic and entertaining experiences by introducing 3D sound. Our results suggest that 3D sound in AR environment significantly improves the accuracy of depth judgment and improves task performance. Our results also suggest that 3D sound contributes significantly to the feeling of human presence and collaboration and helps the subjects to ‘identify spatial objects’."
}

@Article{Rumiński2015,
author="Rumi{\'{n}}ski, Dariusz",
title="An experimental study of spatial sound usefulness in searching and navigating through AR environments",
journal="Virtual Reality",
year="2015",
month="Nov",
day="01",
volume="19",
number="3",
pages="223--233",
abstract="This paper presents an experimental study of spatial sound usefulness in searching and navigating through augmented reality environments. Participants were asked to find three objects hidden within no-sound and spatial sound AR environments. The experiment showed that the participants of the spatialized sound group performed faster and more efficiently than working in no-sound configuration. What is more, 3D sound was a valuable cue for navigation in AR environment. The collected data suggest that the use of spatial sound in AR environments can be a significant factor in searching and navigating for hidden objects within indoor AR scenes. To conduct the experiment, the CARE approach was applied, while its CARL language was extended with new elements responsible for controlling audio in 3D space.",
issn="1434-9957",
doi="10.1007/s10055-015-0274-4",
url="https://doi.org/10.1007/s10055-015-0274-4"
}

@Article{Mion2006,
author="Mion, Luca
and D'Inc{\`a}, Gianluca",
title="Analysis of expression in simple musical gestures to enhance audio in interfaces",
journal="Virtual Reality",
year="2006",
month="May",
day="03",
volume="10",
number="1",
pages="62",
abstract="Expression could play a key role in the audio rendering of virtual reality applications. Its understanding is an ambitious issue in the scientific environment, and several studies have investigated the analysis techniques to detect expression in music performances. The knowledge coming from these analyses is widely applicable: embedding expression on audio interfaces can drive to attractive solutions to emphasize interfaces in mixed-reality environments. Synthesized expressive sounds can be combined with real stimuli to experience augmented reality, and they can be used in multi-sensory stimulations to provide the sensation of first-person experience in virtual expressive environments. In this work we focus on the expression of violin and flute performances, with reference to sensorial and affective domains. By means of selected audio features, we draw a set of parameters describing performers' strategies which are suitable both for tuning expressive synthesis instruments and enhancing audio in human--computer interfaces.",
issn="1434-9957",
doi="10.1007/s10055-006-0029-3",
url="https://doi.org/10.1007/s10055-006-0029-3"
}

@article{hrm2004augmented,
		title = {Augmented Reality Audio for Mobile and Wearable Appliances},
		author = {Härmä, Aki and Jakka, Julia and Tikander, Miikka and Karjalainen, Matti and Lokki, Tapio and Hiipakka, Jarmo and Lorho, Gaëtan},
		journal = {J. Audio Eng. Soc},
		volume = {52},
		number = {6},
		pages = {618--639},
		year = {2004},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=13010}
		}

@inproceedings{Burke:2006:CEV:1180995.1181017,
 author = {Burke, Jennifer L. and Prewett, Matthew S. and Gray, Ashley A. and Yang, Liuquin and Stilson, Frederick R. B. and Coovert, Michael D. and Elliot, Linda R. and Redden, Elizabeth},
 title = {Comparing the Effects of Visual-auditory and Visual-tactile Feedback on User Performance: A Meta-analysis},
 booktitle = {Proceedings of the 8th International Conference on Multimodal Interfaces},
 series = {ICMI '06},
 year = {2006},
 isbn = {1-59593-541-X},
 location = {Banff, Alberta, Canada},
 pages = {108--117},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1180995.1181017},
 doi = {10.1145/1180995.1181017},
 acmid = {1181017},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {meta-analysis, multimodal interface, visual-auditory feedback, visual-tactile feedback},
} 

@ARTICLE{8103379,
author={S. {Yao}},
journal={IEEE Transactions on Consumer Electronics},
title={Headphone-based immersive audio for virtual reality headsets},
year={2017},
volume={63},
number={3},
pages={300-308},
keywords={acoustic signal processing;audio signal processing;handicapped aids;headphones;hearing;loudspeakers;optimisation;rendering (computer graphics);transfer functions;virtual reality;ambisonic surround sound;binaural ambisonic system;image-source model;listening-room simulation;ambisonic rotator;binaural ambisonic decoder;system optimization technique;subjective measurements;objective measurements;perceived audio quality;audio quality assessment;immersive sound;binaural system;virtual auditory space synthesis;subjective listening test;virtual reality headset;headphone-based immersive audio;audio quality enhancement;head-related transfer function customization;closest-matching HRTF dataset;front-back discrimination;up-down discrimination;multiple sound source synthesis;head motion;computational cost minimization;frequency hearing impairment;localization error;localization blur;immersive sound rendering;immersive sound mixing;virtual auditory space repoduction;Loudspeakers;Headphones;Harmonic analysis;Real-time systems;Computational modeling;Solid modeling;Virtual reality;Virtual reality;headphones;head-related transfer function;binaural},
doi={10.1109/TCE.2017.014951},
ISSN={},
month={August},}


@article{article,
author = {Moustakas, Nikos and Floros, Andreas and Grigoriou, Nikolas},
year = {2011},
month = {05},
pages = {13-16},
title = {Interactive Audio Realities: An Augmented / Mixed Reality Audio Game Prototype}
}

@article{GINNS2005313,
title = "Meta-analysis of the modality effect",
journal = "Learning and Instruction",
volume = "15",
number = "4",
pages = "313 - 331",
year = "2005",
issn = "0959-4752",
doi = "https://doi.org/10.1016/j.learninstruc.2005.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0959475205000459",
author = "Paul Ginns",
abstract = "This article reviews research on the modality effect, the educational practice of presenting to-be-learned graphical information visually, and related textual information through an auditory mode. Meta-analytic methods were applied to 43 independent effects (39 between-subjects designs, 4 within-subjects designs). Major hypotheses regarding the instructional benefits of presenting information across modalities were supported, including the effect of two hypothesised moderators, level of element interactivity and pacing of presentation, and between certain fields of study. The strong observed modality effect under system-paced conditions must be weighed against the additional cost of developing audio-visual instructional materials."
}

@article{article,
author = {Balan, Oana and Moldoveanu, Alin and Moldoveanu, Florica},
year = {2015},
month = {01},
pages = {},
title = {Navigational audio games: An effective approach toward improving spatial contextual learning for blind people},
volume = {0},
journal = {International Journal on Disability and Human Development},
doi = {10.1515/ijdhd-2014-0018}
}

@article{cooperstock2001classroom,
  title={The classroom of the future: enhancing education through augmented reality},
  author={Cooperstock, Jeremy R and others},
  journal={Usability evaluation and interface design: cognitive engineering, intelligent agents and virtual reality},
  pages={688--692},
  year={2001},
  publisher={Lawrence Erlbaum Associates}
}


@inproceedings{sayed_arsc:_2010,
	title = {{ARSC}: {Augmented} {Reality} {Student} {Card}},
	shorttitle = {{ARSC}},
	doi = {10.1109/ICENCO.2010.5720437},
	abstract = {Augmented Reality (AR) is the technology of adding virtual objects to the real scenes through enabling the addition of missing information at real life. As the lack of resources is a problem that can be solved through AR, this paper represents and explains the usage of AR technology in what can be named Augmented Reality Student Card (ARSC) for serving the education field. ARSC uses single static markers combined in one card for assigning different objects, leaving the choice to the computer application for minimizing the tracking process. ARSC is designed to be a useful low cost solution for serving the education field. ARSC represents any lesson in a 3D format that helps students to visualize the facts, interact with theories and deal with the information in a totally new effective and interactive way. ARSC can be used in offline, online and game applications with seven markers, four of them are used as a joystick game controller. One of the novelties in this paper is that full experimental tests had been made for the ARTag marker set for sorting them according to their efficiency. The results of the tests are used in this research to choose the most efficient markers for ARSC, and can be used for further researches. The experimental work that had been made in this paper also shows the constraints for marker creation for an AR application. Due to the need to work for online and offline application, merging of toolkits and libraries has been made, as presented in this paper. ARSC was examined by a number of students of both genders with average age between 10-17 years and it was found to have a great acceptance among them.},
	booktitle = {2010 {International} {Computer} {Engineering} {Conference} ({ICENCO})},
	author = {Sayed, N. A. M. El and Zayed, H. H. and Sharawy, M. I.},
	month = dec,
	year = {2010},
	keywords = {augmented reality, computer aided instruction, interactive devices, natural scenes, augmented reality student card, real scenes, virtual objects, AR technology, ARSC, joystick game controller, tracking process, Lead, Navigation, Optical imaging, Education, Cameras, Productivity, Software, Augmented Reality, Mixed Reality, Computer Assisted Learning, Optical tracking},
	pages = {113--120}
}

@inproceedings{dahne_archeoguide:_2002,
	address = {Darmstadt, Germany},
	title = {Archeoguide: system architecture of a mobile outdoor augmented reality system},
	isbn = {9780769517810},
	shorttitle = {Archeoguide},
	url = {http://ieeexplore.ieee.org/document/1115103/},
	doi = {10.1109/ISMAR.2002.1115103},
	urldate = {2019-09-14},
	booktitle = {Proceedings. {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Comput. Soc},
	author = {Dahne, P. and Karigiannis, J.N.},
	year = {2002},
	pages = {263--264}
}

@article{li_development_2004,
	title = {Development of {Augmented} {Reality} {System} for {AFM}-{Based} {Nanomanipulation}},
	volume = {9},
	issn = {1083-4435},
	url = {http://ieeexplore.ieee.org/document/1306449/},
	doi = {10.1109/TMECH.2004.828651},
	language = {en},
	number = {2},
	urldate = {2019-09-14},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Li, G. and Xi, N. and Yu, M. and Fung, W.-K.},
	month = jun,
	year = {2004},
	pages = {358--365}
}

@inproceedings{nawab_joystick_2007,
	title = {Joystick mapped {Augmented} {Reality} {Cues} for {End}-{Effector} controlled {Tele}-operated {Robots}},
	doi = {10.1109/VR.2007.352496},
	abstract = {End-effector control of robots using just remote camera views is difficult due to lack of perceived correspondence between the joysticks and the end-effector coordinate frame. This paper reports the positive effects of augmented reality visual cues on operator performance during end-effector controlled tele-operation using only camera views. Our solution is to overlay a color-coded coordinate system on the end-effector of the robot using AR techniques. This mapped and color-coded coordinate system is then directly mapped to similarly color-coded joysticks used for control of both position and orientation. The AR view along with mapped markings on the joystick give the user a clear notion of the effect of their joystick movements on the end-effector of the robot. All camera views display this registered dynamic overlay information on-demand. An insertion task was used to compare performance with and without the coordinate mapping using fifteen subjects. Preliminary results indicate a significant reduction in distance and reversal errors},
	booktitle = {2007 {IEEE} {Virtual} {Reality} {Conference}},
	author = {Nawab, A. and Chintamani, K. and Ellis, D. and Auner, G. and Pandya, A.},
	month = mar,
	year = {2007},
	keywords = {augmented reality, end effectors, manipulator kinematics, telerobotics, joystick mapped augmented reality, tele-operated robots, robot end-effector control, Augmented reality, Robot control, Cameras, Robot kinematics, Robot vision systems, Software testing, Intelligent robots, Displays, Human factors, Navigation, Robotics, Augmented Reality, Tele-operations, Kinematics, Performance Testing},
	pages = {263--266}
}

@article{fang_interactive_2012,
	title = {Interactive robot trajectory planning and simulation using {Augmented} {Reality}},
	volume = {28},
	issn = {0736-5845},
	url = {http://www.sciencedirect.com/science/article/pii/S0736584511001116},
	doi = {10.1016/j.rcim.2011.09.003},
	abstract = {Human–robot interaction in industrial robotics has largely been confined to finding better ways to reconfigure or program the robots. In this paper, an Augmented Reality based (RPAR-II) system is proposed to facilitate robot programming and trajectory planning considering the dynamic constraints of the robots. Through the various simulation capabilities provided in the proposed AR environment, the users are able to preview the simulated motion, perceive any possible overshoot, and resolve discrepancies between the planned and simulated paths prior to the execution of a task. By performing the simulation, the performance of the trajectory planning and the fitness of the selection of the robot controller model/parameters in the robot programming process can be visually evaluated. Practical issues concerning the system implementation are also discussed.},
	number = {2},
	urldate = {2019-09-14},
	journal = {Robotics and Computer-Integrated Manufacturing},
	author = {Fang, H. C. and Ong, S. K. and Nee, A. Y. C.},
	month = apr,
	year = {2012},
	keywords = {Augmented Reality, Robot programming, Human–robot interaction, Trajectory planning, Simulation},
	pages = {227--237}
}
@inproceedings{jung_[poster]_2015,
	address = {Fukuoka, Japan},
	title = {[{POSTER}] {An} {Adaptive} {Augmented} {Reality} {Interface} for {Hand} {Based} on {Probabilistic} {Approach}},
	isbn = {9781467376600},
	url = {http://ieeexplore.ieee.org/document/7328084/},
	doi = {10.1109/ISMAR.2015.44},
	urldate = {2019-09-14},
	booktitle = {2015 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE},
	author = {Jung, Jinki and Lee, Hyeopwoo and Yang, Hyun Seung},
	month = sep,
	year = {2015},
	pages = {152--155}
}

@inproceedings{lakshmiprabha_[poster]_2014,
	address = {Munich, Germany},
	title = {[{Poster}] {An} augmented and virtual reality system for training autistic children},
	isbn = {9781479961849},
	url = {http://ieeexplore.ieee.org/document/6948448/},
	doi = {10.1109/ISMAR.2014.6948448},
	urldate = {2019-09-14},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Lakshmiprabha, N. S. and Santos, Alexandre and Mladenov, Dimitar and Beltramello, Olga},
	month = sep,
	year = {2014},
	pages = {277--278}
}

@inproceedings{lee_user_2018,
	address = {Munich, Germany},
	title = {A {User} {Study} on {MR} {Remote} {Collaboration} {Using} {Live} 360 {Video}},
	isbn = {9781538674598},
	url = {https://ieeexplore.ieee.org/document/8613761/},
	doi = {10.1109/ISMAR.2018.00051},
	urldate = {2019-09-14},
	booktitle = {2018 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Lee, Gun A. and Teo, Theophilus and Kim, Seungwon and Billinghurst, Mark},
	month = oct,
	year = {2018},
	pages = {153--164}
}

@inproceedings{yamada_camtrackpoint:_2018,
	address = {Berlin, Germany},
	title = {{CamTrackPoint}: {Camera}-{Based} {Pointing} {Stick} {Using} {Transmitted} {Light} through {Finger}},
	isbn = {9781450359481},
	shorttitle = {{CamTrackPoint}},
	url = {http://dl.acm.org/citation.cfm?doid=3242587.3242641},
	doi = {10.1145/3242587.3242641},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}  - {UIST} '18},
	publisher = {ACM Press},
	author = {Yamada, Wataru and Manabe, Hiroyuki and Ikeda, Daizo},
	year = {2018},
	pages = {313--320}
}

@inproceedings{pfeuffer_gaze_2017,
	address = {Brighton, United Kingdom},
	title = {Gaze + pinch interaction in virtual reality},
	isbn = {9781450354868},
	url = {http://dl.acm.org/citation.cfm?doid=3131277.3132180},
	doi = {10.1145/3131277.3132180},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 5th {Symposium} on {Spatial} {User} {Interaction}  - {SUI} '17},
	publisher = {ACM Press},
	author = {Pfeuffer, Ken and Mayer, Benedikt and Mardanbegi, Diako and Gellersen, Hans},
	year = {2017},
	pages = {99--108}
}

@inproceedings{chang_gesture-based_2017,
	address = {Los Angeles, CA, USA},
	title = {Gesture-based augmented reality annotation},
	isbn = {9781509066476},
	url = {http://ieeexplore.ieee.org/document/7892383/},
	doi = {10.1109/VR.2017.7892383},
	urldate = {2019-09-14},
	booktitle = {2017 {IEEE} {Virtual} {Reality} ({VR})},
	publisher = {IEEE},
	author = {Chang, Yun Suk and Nuernberger, Benjamin and Luan, Bo and Hollerer, Tobias and O'Donovan, John},
	year = {2017},
	pages = {469--470}
}

@article{hurst_gesture-based_2013,
	title = {Gesture-based interaction via finger tracking for mobile augmented reality},
	volume = {62},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-011-0983-y},
	doi = {10.1007/s11042-011-0983-y},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Multimedia Tools and Applications},
	author = {Hürst, Wolfgang and van Wezel, Casper},
	month = jan,
	year = {2013},
	pages = {233--258}
}

@inproceedings{piumsomboon_grasp-shell_2014,
	address = {Munich, Germany},
	title = {Grasp-{Shell} vs gesture-speech: {A} comparison of direct and indirect natural interaction techniques in augmented reality},
	isbn = {9781479961849},
	shorttitle = {Grasp-{Shell} vs gesture-speech},
	url = {http://ieeexplore.ieee.org/document/6948411/},
	doi = {10.1109/ISMAR.2014.6948411},
	urldate = {2019-09-14},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Piumsomboon, Thammathip and Altimira, David and Kim, Hyungon and Clark, Adrian and Lee, Gun and Billinghurst, Mark},
	month = sep,
	year = {2014},
	pages = {73--82}
}

@article{jenny_interacting_2019,
	title = {Interacting with {Maps} in {Virtual} and {Augmented} {Reality}},
	volume = {1},
	issn = {2570-2106},
	url = {https://www.abstr-int-cartogr-assoc.net/1/147/2019/},
	doi = {10.5194/ica-abs-1-147-2019},
	abstract = {{\textless}p{\textgreater}{\textless}strong{\textgreater}Abstract.{\textless}/strong{\textgreater} Augmented reality (AR) and virtual reality (VR) technology are increasingly used for the analysis and visualisation of geospatial data. It has become simple to create an immersive three-dimensional AR or VR map with a combination of game engines (e.g., Unity), software development kits for streaming and rendering geospatial data (e.g., Mapbox), and affordable hardware (e.g., HTC Vive). However, it is not clear how to best interact with geospatial visualisations in AR and VR. For example, there are no established standards to efficiently zoom and pan, select map features, or place markers on AR and VR maps. In this paper, we explore interaction with AR and VR maps using gestures and handheld controllers.{\textless}/p{\textgreater}{\textless}p{\textgreater}As for gesture-controlled interaction, we present the results of recent research projects exploring how body gestures can control basic AR and VR map operations. We use motion-tracking controllers (e.g., Leap Motion) to capture and interpret gestures. We conducted a set of user studies to identify, explore and compare various gestures for controlling map-related operations. This includes, for example, mid-air hand gestures for zooming and panning (Satriadi et al. 2019), selecting points of interest, adjusting the orientation of maps, or placing markers on maps. Additionally, we present novel VR interfaces and interaction methods for controlling the content of maps with gestures.{\textless}/p{\textgreater}{\textless}p{\textgreater}As for handheld controllers, we discuss interaction with exocentric globes, egocentric globes (where the user stands inside a large virtual globe), flat maps, and curved maps in VR. We demonstrate controller-based interaction for adjusting the centre of world maps displayed on these four types of projection surfaces (Yang et al. 2018), and illustrate the utility of interactively movable VR maps by the example of three-dimensional origin-destination flow maps (Yang et al. 2019).{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-09-14},
	journal = {Abstracts of the ICA},
	author = {Jenny, Bernhard and Satriadi, Kadek Ananta and Yang, Yalong and Austin, Christopher R. and Lee, Simond and Chan, Nian and Cordeil, Maxime and Ens, Barrett},
	month = jul,
	year = {2019},
	pages = {1--1}
}

@inproceedings{brun_multimodal_2018,
	address = {Boulder, CO, USA},
	title = {Multimodal and {Context}-{Aware} {Interaction} in {Augmented} {Reality} for {Active} {Assistance}},
	isbn = {9781450356923},
	url = {http://dl.acm.org/citation.cfm?doid=3242969.3264966},
	doi = {10.1145/3242969.3264966},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 on {International} {Conference} on {Multimodal} {Interaction}  - {ICMI} '18},
	publisher = {ACM Press},
	author = {Brun, Damien},
	year = {2018},
	pages = {506--510}
}

@inproceedings{datcu_multimodal_2012,
	address = {Santa Monica, California, USA},
	title = {Multimodal collaboration for crime scene investigation in mediated reality},
	isbn = {9781450314671},
	url = {http://dl.acm.org/citation.cfm?doid=2388676.2388739},
	doi = {10.1145/2388676.2388739},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 14th {ACM} international conference on {Multimodal} interaction - {ICMI} '12},
	publisher = {ACM Press},
	author = {Datcu, Dragoş and Swart, Thomas and Lukosch, Stephan and Rusak, Zoltan},
	year = {2012},
	pages = {299}
}

@inproceedings{knierim_physical_2018,
	address = {Montreal QC, Canada},
	title = {Physical {Keyboards} in {Virtual} {Reality}: {Analysis} of {Typing} {Performance} and {Effects} of {Avatar} {Hands}},
	isbn = {9781450356206},
	shorttitle = {Physical {Keyboards} in {Virtual} {Reality}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3173919},
	doi = {10.1145/3173574.3173919},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Knierim, Pascal and Schwind, Valentin and Feit, Anna Maria and Nieuwenhuizen, Florian and Henze, Niels},
	year = {2018},
	pages = {1--9}
}

@inproceedings{lien_ppv:_2016,
	address = {Merida, Yucatan, Mexico},
	title = {{PPV}: {Pixel}-{Point}-{Volume} {Segmentation} for {Object} {Referencing} in {Collaborative} {Augmented} {Reality}},
	isbn = {9781509036417},
	shorttitle = {{PPV}},
	url = {http://ieeexplore.ieee.org/document/7781769/},
	doi = {10.1109/ISMAR.2016.21},
	urldate = {2019-09-14},
	booktitle = {2016 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Lien, Kuo-Chin and Nuernberger, Benjamin and Hollerer, Tobias and Turk, Matthew},
	month = sep,
	year = {2016},
	pages = {77--83}
}

@inproceedings{chun_real-time_2013,
	address = {Santa Monica, California, USA},
	title = {Real-time hand interaction for augmented reality on mobile phones},
	isbn = {9781450319652},
	url = {http://dl.acm.org/citation.cfm?doid=2449396.2449435},
	doi = {10.1145/2449396.2449435},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces - {IUI} '13},
	publisher = {ACM Press},
	author = {Chun, Wendy H. and Höllerer, Tobias},
	year = {2013},
	pages = {307}
}

@inproceedings{benavides_invisibilia:_2015,
	address = {Osaka, Japan},
	title = {Invisibilia: revealing invisible data using augmented reality and internet connected devices},
	isbn = {9781450335751},
	shorttitle = {Invisibilia},
	url = {http://dl.acm.org/citation.cfm?doid=2800835.2800882},
	doi = {10.1145/2800835.2800882},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2015 {ACM} {International} {Symposium} on {Wearable} {Computers} - {UbiComp} '15},
	publisher = {ACM Press},
	author = {Benavides, Xavier and Amores, Judith and Maes, Pattie},
	year = {2015},
	pages = {341--344}
}

@incollection{hutchison_static_2007,
	address = {Berlin, Heidelberg},
	title = {Static and {Dynamic} {Hand}-{Gesture} {Recognition} for {Augmented} {Reality} {Applications}},
	volume = {4552},
	isbn = {9783540731085 9783540731108},
	url = {http://link.springer.com/10.1007/978-3-540-73110-8_79},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Human-{Computer} {Interaction}. {HCI} {Intelligent} {Multimodal} {Interaction} {Environments}},
	publisher = {Springer Berlin Heidelberg},
	author = {Reifinger, Stefan and Wallhoff, Frank and Ablassmeier, Markus and Poitschke, Tony and Rigoll, Gerhard},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Jacko, Julie A.},
	year = {2007},
	doi = {10.1007/978-3-540-73110-8_79},
	pages = {728--737}
}

@article{lv_multimodal_2014,
	title = {Multimodal {Hand} and {Foot} {Gesture} {Interaction} for {Handheld} {Devices}},
	volume = {11},
	issn = {15516857},
	url = {http://dl.acm.org/citation.cfm?doid=2675060.2645860},
	doi = {10.1145/2645860},
	language = {en},
	number = {1s},
	urldate = {2019-09-14},
	journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
	author = {Lv, Zhihan and Halawani, Alaa and Feng, Shengzhong and Li, Haibo and Réhman, Shafiq Ur},
	month = oct,
	year = {2014},
	pages = {1--19}
}

@article{kim_tangible_2005,
	title = {Tangible 3D: {Hand} {Gesture} {Interaction} for {Immersive} 3D {Modeling}},
	issn = {1727-530X},
	shorttitle = {Tangible 3D},
	url = {http://diglib.eg.org/handle/10.2312/EGVE.IPT_EGVE2005.191-199},
	doi = {10.2312/egve/ipt_egve2005/191-199},
	abstract = {Most of all interaction tasks relevant for a general three-dimensional virtual environment can be supported by 6DOF control and grab/select input. Obviously a very efficient method is direct manipulation with bare hands, like in real environment. This paper shows the possibility to perform non-trivial tasks using only a few well-known hand gestures, so that almost no training is necessary to interact with 3D-softwares. Using this gesture interaction we have built an immersive 3D modeling system with 3D model representation based on a mesh library, which is optimized not only for real-time rendering but also accommodates for changes of both vertex positions and mesh connectivity in real-time. For performing the gesture interaction, the users hand is marked with just four fingertipthimbles made of inexpensive material as simple as white paper. Within our scenario, the recognized hand gestures are used to select, create, manipulate and deform the meshes in a spontaneous and intuitive way. All modeling tasks are performed wirelessly through a camera/vision tracking method for the head and hand interaction.},
	language = {eng},
	urldate = {2019-09-14},
	journal = {Eurographics Symposium on Virtual Environments},
	author = {Kim, Hyosun and Albuquerque, Georgia and Havemann, Sven and Fellner, Dieter W.},
	year = {2005},
	keywords = {Categories and Subject Descriptors (according to ACM CCS): I.3.6 [Computer Graphics]: Interaction Techniques},
	pages = {9 pages}
}

@inproceedings{barioni_human_2018,
	address = {Foz do Iguaçu, Brazil},
	title = {Human {Pose} {Tracking} from {RGB} {Inputs}},
	isbn = {9781728106045},
	url = {https://ieeexplore.ieee.org/document/8802469/},
	doi = {10.1109/SVR.2018.00035},
	urldate = {2019-09-14},
	booktitle = {2018 20th {Symposium} on {Virtual} and {Augmented} {Reality} ({SVR})},
	publisher = {IEEE},
	author = {Barioni, Ricardo R. and Figueiredo, Lucas and Cunha, Kelvin and Teichrieb, Veronica},
	month = oct,
	year = {2018},
	pages = {176--182}
}

@inproceedings{sun_magichand:_2019,
	address = {Osaka, Japan},
	title = {{MagicHand}: {Interact} with {IoT} {Devices} in {Augmented} {Reality} {Environment}},
	isbn = {9781728113777},
	shorttitle = {{MagicHand}},
	url = {https://ieeexplore.ieee.org/document/8798053/},
	doi = {10.1109/VR.2019.8798053},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Sun, Yongbin and Armengol-Urpi, Alexandre and Reddy Kantareddy, Sai Nithin and Siegel, Joshua and Sarma, Sanjay},
	month = mar,
	year = {2019},
	pages = {1738--1743}
}

@inproceedings{techasarntikul_evaluation_2019,
	address = {Osaka, Japan},
	title = {Evaluation of {Pointing} {Interfaces} with an {AR} {Agent} for {Multi}-section {Information} {Guidance}},
	isbn = {9781728113777},
	url = {https://ieeexplore.ieee.org/document/8798061/},
	doi = {10.1109/VR.2019.8798061},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Techasarntikul, Nattaon and Mashita, Tomohiro and Ratsamee, Photchara and Uranishi, Yuki and Takemura, Haruo and Orlosky, Jason and Kiyokawa, Kiyoshi},
	month = mar,
	year = {2019},
	pages = {1185--1186}
}

@incollection{hutchison_user-defined_2013,
	address = {Berlin, Heidelberg},
	title = {User-{Defined} {Gestures} for {Augmented} {Reality}},
	volume = {8118},
	isbn = {9783642404795 9783642404801},
	url = {http://link.springer.com/10.1007/978-3-642-40480-1_18},
	urldate = {2019-09-14},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2013},
	publisher = {Springer Berlin Heidelberg},
	author = {Piumsomboon, Thammathip and Clark, Adrian and Billinghurst, Mark and Cockburn, Andy},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Kotzé, Paula and Marsden, Gary and Lindgaard, Gitte and Wesson, Janet and Winckler, Marco},
	year = {2013},
	doi = {10.1007/978-3-642-40480-1_18},
	pages = {282--299}
}

@inproceedings{pomsar_using_2019,
	address = {Herlany, Slovakia},
	title = {Using surface electromyography for gesture detection},
	isbn = {9781728102504},
	url = {https://ieeexplore.ieee.org/document/8782744/},
	doi = {10.1109/SAMI.2019.8782744},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} 17th {World} {Symposium} on {Applied} {Machine} {Intelligence} and {Informatics} ({SAMI})},
	publisher = {IEEE},
	author = {Pomsar, Ladislav and Ferencik, Norbert and Jascur, Miroslav and Bundzel, Marek},
	month = jan,
	year = {2019},
	pages = {95--100}
}

@article{ro_ar_2019,
	title = {{AR} {Pointer}: {Advanced} {Ray}-{Casting} {Interface} {Using} {Laser} {Pointer} {Metaphor} for {Object} {Manipulation} in 3D {Augmented} {Reality} {Environment}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {{AR} {Pointer}},
	url = {https://www.mdpi.com/2076-3417/9/15/3078},
	doi = {10.3390/app9153078},
	abstract = {In this paper, we propose AR Pointer, a new augmented reality (AR) interface that allows users to manipulate three-dimensional (3D) virtual objects in AR environment. AR Pointer uses a built-in 6-degrees of freedom (DoF) inertial measurement unit (IMU) sensor in an off-the-shelf mobile device to cast a virtual ray that is used to accurately select objects. It is also implemented using simple touch gestures commonly used in smartphones for 3D object manipulation, so users can easily manipulate 3D virtual objects using the AR Pointer, without a long training period. To demonstrate the usefulness of AR Pointer, we introduce two use-cases, constructing an AR furniture layout and AR education. Then, we conducted two experiments, performance tests and usability tests, to represent the excellence of the designed interaction methods using AR Pointer. We found that AR Pointer is more efficient than other interfaces, achieving 39.4\% faster task completion time in the object manipulation. In addition, the participants gave an average of 8.61 points (13.4\%) on the AR Pointer in the usability test conducted through the system usability scale (SUS) questionnaires and 8.51 points (15.1\%) on the AR Pointer in the fatigue test conducted through the NASA task load index (NASA-TLX) questionnaire. Previous AR applications have been implemented in a passive AR environment where users simply check and pop up the AR objects those are prepared in advance. However, if AR Pointer is used for AR object manipulation, it is possible to provide an immersive AR environment for the user who want/wish to actively interact with the AR objects.},
	language = {en},
	number = {15},
	urldate = {2019-09-14},
	journal = {Applied Sciences},
	author = {Ro, Hyocheol and Byun, Jung-Hyun and Park, Yoon Jung and Lee, Nam Kyu and Han, Tack-Don},
	month = jan,
	year = {2019},
	keywords = {augmented reality, head-mounted display, intelligent user interface, ray-casting, mixed reality, augmented reality interface, head-mounted display interface, ray-casting interface},
	pages = {3078}
}

@article{maitlo_hand-gesture-recognition_2019,
	title = {Hand-{Gesture}-{Recognition} {Based} {Text} {Input} {Method} for {AR}/{VR} {Wearable} {Devices}},
	url = {http://arxiv.org/abs/1907.12188},
	abstract = {Static and dynamic hand movements are basic way for human-machine interactions. To recognize and classify these movements, first these movements are captured by the cameras mounted on the augmented reality (AR) or virtual reality (VR) wearable devices. The hand is segmented using segmentation method and its gestures are passed to hand gesture recognition algorithm, which depends on depth-wise separable convolutional neural network for training, testing and finally running smoothly on mobile AR/VR devices, while maintaining the accuracy and balancing the load. A number of gestures are processed for identification of right gesture and to classify the gesture and ignore the all intermittent gestures. With proposed method, a user can write letters and numbers in air by just moving his/her hand in air. Gesture based operations are performed, and trajectory of hand is recorded as handwritten text. Finally, that handwritten text is processed for the text recognition.},
	urldate = {2019-09-14},
	journal = {arXiv:1907.12188 [cs]},
	author = {Maitlo, Nizamuddin and Wang, Yanbo and Chen, Chao Ping and Mi, Lantian and Zhang, Wenbo},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.12188},
	keywords = {Computer Science - Human-Computer Interaction}
}

@article{hou_augmented_2019,
	title = {Augmented {Reality} {Museum} {Visiting} {Application} based on the {Microsoft} {HoloLens}},
	volume = {1237},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1237/5/052018},
	doi = {10.1088/1742-6596/1237/5/052018},
	urldate = {2019-09-14},
	journal = {Journal of Physics: Conference Series},
	author = {Hou, Weiting},
	month = jun,
	year = {2019},
	pages = {052018}
}

@inproceedings{barioni_human_2018,
	address = {Foz do Iguaçu, Brazil},
	title = {Human {Pose} {Tracking} from {RGB} {Inputs}},
	isbn = {9781728106045},
	url = {https://ieeexplore.ieee.org/document/8802469/},
	doi = {10.1109/SVR.2018.00035},
	urldate = {2019-09-14},
	booktitle = {2018 20th {Symposium} on {Virtual} and {Augmented} {Reality} ({SVR})},
	publisher = {IEEE},
	author = {Barioni, Ricardo R. and Figueiredo, Lucas and Cunha, Kelvin and Teichrieb, Veronica},
	month = oct,
	year = {2018},
	pages = {176--182}
}

@inproceedings{sun_magichand:_2019,
	address = {Osaka, Japan},
	title = {{MagicHand}: {Interact} with {IoT} {Devices} in {Augmented} {Reality} {Environment}},
	isbn = {9781728113777},
	shorttitle = {{MagicHand}},
	url = {https://ieeexplore.ieee.org/document/8798053/},
	doi = {10.1109/VR.2019.8798053},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Sun, Yongbin and Armengol-Urpi, Alexandre and Reddy Kantareddy, Sai Nithin and Siegel, Joshua and Sarma, Sanjay},
	month = mar,
	year = {2019},
	pages = {1738--1743}
}

@inproceedings{techasarntikul_evaluation_2019,
	address = {Osaka, Japan},
	title = {Evaluation of {Pointing} {Interfaces} with an {AR} {Agent} for {Multi}-section {Information} {Guidance}},
	isbn = {9781728113777},
	url = {https://ieeexplore.ieee.org/document/8798061/},
	doi = {10.1109/VR.2019.8798061},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Techasarntikul, Nattaon and Mashita, Tomohiro and Ratsamee, Photchara and Uranishi, Yuki and Takemura, Haruo and Orlosky, Jason and Kiyokawa, Kiyoshi},
	month = mar,
	year = {2019},
	pages = {1185--1186}
}

@incollection{hutchison_user-defined_2013,
	address = {Berlin, Heidelberg},
	title = {User-{Defined} {Gestures} for {Augmented} {Reality}},
	volume = {8118},
	isbn = {9783642404795 9783642404801},
	url = {http://link.springer.com/10.1007/978-3-642-40480-1_18},
	urldate = {2019-09-14},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2013},
	publisher = {Springer Berlin Heidelberg},
	author = {Piumsomboon, Thammathip and Clark, Adrian and Billinghurst, Mark and Cockburn, Andy},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Kotzé, Paula and Marsden, Gary and Lindgaard, Gitte and Wesson, Janet and Winckler, Marco},
	year = {2013},
	doi = {10.1007/978-3-642-40480-1_18},
	pages = {282--299}
}

@inproceedings{pomsar_using_2019,
	address = {Herlany, Slovakia},
	title = {Using surface electromyography for gesture detection},
	isbn = {9781728102504},
	url = {https://ieeexplore.ieee.org/document/8782744/},
	doi = {10.1109/SAMI.2019.8782744},
	urldate = {2019-09-14},
	booktitle = {2019 {IEEE} 17th {World} {Symposium} on {Applied} {Machine} {Intelligence} and {Informatics} ({SAMI})},
	publisher = {IEEE},
	author = {Pomsar, Ladislav and Ferencik, Norbert and Jascur, Miroslav and Bundzel, Marek},
	month = jan,
	year = {2019},
	pages = {95--100}
}

@article{ro_ar_2019,
	title = {{AR} {Pointer}: {Advanced} {Ray}-{Casting} {Interface} {Using} {Laser} {Pointer} {Metaphor} for {Object} {Manipulation} in 3D {Augmented} {Reality} {Environment}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {{AR} {Pointer}},
	url = {https://www.mdpi.com/2076-3417/9/15/3078},
	doi = {10.3390/app9153078},
	abstract = {In this paper, we propose AR Pointer, a new augmented reality (AR) interface that allows users to manipulate three-dimensional (3D) virtual objects in AR environment. AR Pointer uses a built-in 6-degrees of freedom (DoF) inertial measurement unit (IMU) sensor in an off-the-shelf mobile device to cast a virtual ray that is used to accurately select objects. It is also implemented using simple touch gestures commonly used in smartphones for 3D object manipulation, so users can easily manipulate 3D virtual objects using the AR Pointer, without a long training period. To demonstrate the usefulness of AR Pointer, we introduce two use-cases, constructing an AR furniture layout and AR education. Then, we conducted two experiments, performance tests and usability tests, to represent the excellence of the designed interaction methods using AR Pointer. We found that AR Pointer is more efficient than other interfaces, achieving 39.4\% faster task completion time in the object manipulation. In addition, the participants gave an average of 8.61 points (13.4\%) on the AR Pointer in the usability test conducted through the system usability scale (SUS) questionnaires and 8.51 points (15.1\%) on the AR Pointer in the fatigue test conducted through the NASA task load index (NASA-TLX) questionnaire. Previous AR applications have been implemented in a passive AR environment where users simply check and pop up the AR objects those are prepared in advance. However, if AR Pointer is used for AR object manipulation, it is possible to provide an immersive AR environment for the user who want/wish to actively interact with the AR objects.},
	language = {en},
	number = {15},
	urldate = {2019-09-14},
	journal = {Applied Sciences},
	author = {Ro, Hyocheol and Byun, Jung-Hyun and Park, Yoon Jung and Lee, Nam Kyu and Han, Tack-Don},
	month = jan,
	year = {2019},
	keywords = {augmented reality, head-mounted display, intelligent user interface, ray-casting, mixed reality, augmented reality interface, head-mounted display interface, ray-casting interface},
	pages = {3078}
}

@article{maitlo_hand-gesture-recognition_2019,
	title = {Hand-{Gesture}-{Recognition} {Based} {Text} {Input} {Method} for {AR}/{VR} {Wearable} {Devices}},
	url = {http://arxiv.org/abs/1907.12188},
	abstract = {Static and dynamic hand movements are basic way for human-machine interactions. To recognize and classify these movements, first these movements are captured by the cameras mounted on the augmented reality (AR) or virtual reality (VR) wearable devices. The hand is segmented using segmentation method and its gestures are passed to hand gesture recognition algorithm, which depends on depth-wise separable convolutional neural network for training, testing and finally running smoothly on mobile AR/VR devices, while maintaining the accuracy and balancing the load. A number of gestures are processed for identification of right gesture and to classify the gesture and ignore the all intermittent gestures. With proposed method, a user can write letters and numbers in air by just moving his/her hand in air. Gesture based operations are performed, and trajectory of hand is recorded as handwritten text. Finally, that handwritten text is processed for the text recognition.},
	urldate = {2019-09-14},
	journal = {arXiv:1907.12188 [cs]},
	author = {Maitlo, Nizamuddin and Wang, Yanbo and Chen, Chao Ping and Mi, Lantian and Zhang, Wenbo},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.12188},
	keywords = {Computer Science - Human-Computer Interaction}
}

@article{hou_augmented_2019,
	title = {Augmented {Reality} {Museum} {Visiting} {Application} based on the {Microsoft} {HoloLens}},
	volume = {1237},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1237/5/052018},
	doi = {10.1088/1742-6596/1237/5/052018},
	urldate = {2019-09-14},
	journal = {Journal of Physics: Conference Series},
	author = {Hou, Weiting},
	month = jun,
	year = {2019},
	pages = {052018}
}

@incollection{si_full_2011,
	address = {Berlin, Heidelberg},
	title = {Full {Body} {Gestures} {Enhancing} a {Game} {Book} for {Interactive} {Story} {Telling}},
	volume = {7069},
	isbn = {9783642252884 9783642252891},
	url = {http://link.springer.com/10.1007/978-3-642-25289-1_23},
	urldate = {2019-09-14},
	booktitle = {Interactive {Storytelling}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kistler, Felix and Sollfrank, Dominik and Bee, Nikolaus and André, Elisabeth},
	editor = {Si, Mei and Thue, David and André, Elisabeth and Lester, James C. and Tanenbaum, Joshua and Zammitto, Veronica},
	year = {2011},
	doi = {10.1007/978-3-642-25289-1_23},
	pages = {207--218}
}

@inproceedings{barakonyi_monkeybridge:_2005,
	address = {Valencia, Spain},
	title = {{MonkeyBridge}: autonomous agents in augmented reality games},
	isbn = {9781595931108},
	shorttitle = {{MonkeyBridge}},
	url = {http://portal.acm.org/citation.cfm?doid=1178477.1178500},
	doi = {10.1145/1178477.1178500},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2005 {ACM} {SIGCHI} {International} {Conference} on {Advances} in computer entertainment technology  - {ACE} '05},
	publisher = {ACM Press},
	author = {Barakonyi, István and Weilguny, Markus and Psik, Thomas and Schmalstieg, Dieter},
	year = {2005},
	pages = {172--175}
}

@article{pachoulakis_augmented_2012,
	title = {Augmented {Reality} {Platforms} for {Virtual} {Fitting} {Rooms}},
	volume = {4},
	issn = {09755934},
	url = {http://www.airccse.org/journal/jma/4412ijma04.pdf},
	doi = {10.5121/ijma.2012.4404},
	number = {4},
	urldate = {2019-09-14},
	journal = {The International journal of Multimedia \& Its Applications},
	author = {Pachoulakis, Ioannis},
	month = aug,
	year = {2012},
	pages = {35--46}
}

@inproceedings{barakonyi_remote_2004,
	address = {School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada},
	series = {{GI} '04},
	title = {Remote {Collaboration} {Using} {Augmented} {Reality} {Videoconferencing}},
	isbn = {9781568812274},
	url = {http://dl.acm.org/citation.cfm?id=1006058.1006070},
	abstract = {This paper describes an Augmented Reality (AR) Videoconferencing System, which is a novel remote collaboration tool combining a desktop-based AR system and a videoconference module. The novelty of our system is the combination of these tools with AR applications superimposed on live video background displaying the conference parties' real environment, merging the advantages of the natural face-to-face communication of videoconferencing and AR's interaction capabilities with distributed virtual objects using tangible physical artifacts. The simplicity of the system makes it affordable for everyday use. We explain our system design based on concurrent video streaming, optical tracking and 3D application sharing, and provide experimental proof that it yields superior quality compared to pure video streaming with successive optical tracking from the compressed streams. We demonstrate the system's collaborative features with a volume rendering application that allows users to display and examine volumetric data simultaneously and to highlight or explore slices of the volume by manipulating an optical marker as a cutting plane interaction device.},
	urldate = {2019-09-14},
	booktitle = {Proceedings of {Graphics} {Interface} 2004},
	publisher = {Canadian Human-Computer Communications Society},
	author = {Barakonyi, Istvan and Fahmy, Tamer and Schmalstieg, Dieter},
	year = {2004},
	note = {event-place: London, Ontario, Canada},
	keywords = {Augmented Reality, Videoconferencing, computer-supported collaborative work, volume rendering},
	pages = {89--96}
}

@inproceedings{hsiao_body_2011,
	title = {Body {Language} and {Augmented} {Reality} {Learning} {Environment}},
	doi = {10.1109/MUE.2011.51},
	abstract = {A recent national survey of Taiwanese students shows that their physical health condition has been worsening more than many other countries. In this study we examine use of a new learning system enhanced with augmented reality (AR) to address this growing global problem. In order to apply three different physical activities for the experiment the learners use their body language for interacting with the computer. In order to increase effectiveness of the AR system, we then combine students' academic achievement and their preferences for using the system. The experimental results from 419 students indicate much higher achievements in their academic work and gain significantly more those who come with their minds set for stronger challenging preferences in the seven subscales.},
	booktitle = {2011 {Fifth} {FTRA} {International} {Conference} on {Multimedia} and {Ubiquitous} {Engineering}},
	author = {Hsiao, K. and Rashvand, H. F.},
	month = jun,
	year = {2011},
	keywords = {augmented reality, computer aided instruction, body language, augmented reality learning environment, physical health condition, student academic achievement, Learning systems, Augmented reality, Educational institutions, Animation, Conferences, augmented reality, virtual reality, learning, education, preference},
	pages = {246--250}
}

@article{hsiao_integrating_2011,
	title = {Integrating body language movements in augmented reality learning environment},
	volume = {1},
	issn = {2192-1962},
	url = {http://hcis-journal.springeropen.com/articles/10.1186/2192-1962-1-1},
	doi = {10.1186/2192-1962-1-1},
	language = {en},
	number = {1},
	urldate = {2019-09-14},
	journal = {Human-centric Computing and Information Sciences},
	author = {Hsiao, Kuei-Fang and Rashvand, Habib F},
	year = {2011},
	pages = {1}
}

@inproceedings{kantonen_mixed_2010,
	title = {Mixed reality in virtual world teleconferencing},
	doi = {10.1109/VR.2010.5444792},
	abstract = {In this paper we present a Mixed Reality (MR) teleconferencing application based on Second Life (SL) and the OpenSim virtual world. Augmented Reality (AR) techniques are used for displaying virtual avatars of remote meeting participants in real physical spaces, while Augmented Virtuality (AV), in form of video based gesture detection, enables capturing of human expressions to control avatars and to manipulate virtual objects in virtual worlds. The use of Second Life for creating a shared augmented space to represent different physical locations allows us to incorporate the application into existing infrastructure. The application is implemented using open source Second Life viewer, ARToolKit and OpenCV libraries.},
	booktitle = {2010 {IEEE} {Virtual} {Reality} {Conference} ({VR})},
	author = {Kantonen, T. and Woodward, C. and Katz, N.},
	month = mar,
	year = {2010},
	keywords = {augmented reality, avatars, teleconferencing, mixed reality, virtual world teleconferencing, second life, OpenSim virtual world, augmented reality, augmented virtuality, virtual avatars, video based gesture detection, Virtual reality, Teleconferencing, Second Life, Avatars, Augmented virtuality, Augmented reality, Video sharing, Object detection, Humans, Libraries, mixed reality, virtual worlds, Second Life, teleconferencing, immersive virtual environments, collaborative augmented reality},
	pages = {179--182}
}

@inproceedings{konrad_gesture_2003,
	address = {Ft. Lauderdale, Florida, USA},
	title = {Gesture + play: full-body interaction for virtual environments},
	isbn = {9781581136371},
	shorttitle = {Gesture + play},
	url = {http://portal.acm.org/citation.cfm?doid=765891.765894},
	doi = {10.1145/765891.765894},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {{CHI} '03 extended abstracts on {Human} factors in computing systems  - {CHI} '03},
	publisher = {ACM Press},
	author = {Konrad, Tollmar and Demirdjian, David and Darrell, Trevor},
	year = {2003},
	pages = {620}
}

@inproceedings{toyama_mixed_2014,
	address = {Haifa, Israel},
	title = {A mixed reality head-mounted text translation system using eye gaze input},
	isbn = {9781450321846},
	url = {http://dl.acm.org/citation.cfm?doid=2557500.2557528},
	doi = {10.1145/2557500.2557528},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 19th international conference on {Intelligent} {User} {Interfaces} - {IUI} '14},
	publisher = {ACM Press},
	author = {Toyama, Takumi and Sonntag, Daniel and Dengel, Andreas and Matsuda, Takahiro and Iwamura, Masakazu and Kise, Koichi},
	year = {2014},
	pages = {329--334}
}

@inproceedings{rantala_glasses_2014,
	address = {Toronto, Ontario, Canada},
	title = {Glasses with haptic feedback of gaze gestures},
	isbn = {9781450324748},
	url = {http://dl.acm.org/citation.cfm?doid=2559206.2581163},
	doi = {10.1145/2559206.2581163},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the extended abstracts of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} {EA} '14},
	publisher = {ACM Press},
	author = {Rantala, Jussi and Kangas, Jari and Akkil, Deepak and Isokoski, Poika and Raisamo, Roope},
	year = {2014},
	pages = {1597--1602}
}


@inproceedings{delamare_designing_2017,
	address = {Vienna, Austria},
	title = {Designing a gaze gesture guiding system},
	isbn = {9781450350754},
	url = {http://dl.acm.org/citation.cfm?doid=3098279.3098561},
	doi = {10.1145/3098279.3098561},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}  - {MobileHCI} '17},
	publisher = {ACM Press},
	author = {Delamare, William and Han, Teng and Irani, Pourang},
	year = {2017},
	pages = {1--13}
}

@incollection{auvray_delayed_2014,
	address = {Berlin, Heidelberg},
	title = {Delayed {Haptic} {Feedback} to {Gaze} {Gestures}},
	volume = {8618},
	isbn = {9783662441923 9783662441930},
	url = {http://link.springer.com/10.1007/978-3-662-44193-0_4},
	urldate = {2019-09-14},
	booktitle = {Haptics: {Neuroscience}, {Devices}, {Modeling}, and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kangas, Jari and Rantala, Jussi and Akkil, Deepak and Isokoski, Poika and Majaranta, Päivi and Raisamo, Roope},
	editor = {Auvray, Malika and Duriez, Christian},
	year = {2014},
	doi = {10.1007/978-3-662-44193-0_4},
	pages = {25--31}
}

@inproceedings{buchmann_fingartips:_2004,
	address = {New York, NY, USA},
	series = {{GRAPHITE} '04},
	title = {{FingARtips}: {Gesture} {Based} {Direct} {Manipulation} in {Augmented} {Reality}},
	isbn = {9781581138832},
	shorttitle = {{FingARtips}},
	url = {http://doi.acm.org/10.1145/988834.988871},
	doi = {10.1145/988834.988871},
	abstract = {This paper presents a technique for natural, fingertip-based interaction with virtual objects in Augmented Reality (AR) environments. We use image processing software and finger- and hand-based fiducial markers to track gestures from the user, stencil buffering to enable the user to see their fingers at all times, and fingertip-based haptic feedback devices to enable the user to feel virtual objects. Unlike previous AR interfaces, this approach allows users to interact with virtual content using natural hand gestures. The paper describes how these techniques were applied in an urban planning interface, and also presents preliminary informal usability results.},
	urldate = {2019-09-16},
	booktitle = {Proceedings of the 2Nd {International} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques} in {Australasia} and {South} {East} {Asia}},
	publisher = {ACM},
	author = {Buchmann, Volkert and Violich, Stephen and Billinghurst, Mark and Cockburn, Andy},
	year = {2004},
	note = {event-place: Singapore},
	keywords = {Augmented Reality, gesture interaction, occlusion},
	pages = {212--221}
}


@article{anderson_augmented_2014,
	title = {Augmented reality improves myoelectric prosthesis training},
	volume = {13},
	issn = {2191-0367, 2191-1231},
	url = {https://www.degruyter.com/view/j/ijdhd.2014.13.issue-3/ijdhd-2014-0327/ijdhd-2014-0327.xml},
	doi = {10.1515/ijdhd-2014-0327},
	number = {3},
	urldate = {2019-09-14},
	journal = {International Journal on Disability and Human Development},
	author = {Anderson, Fraser and Bischof, Walter F.},
	month = jan,
	year = {2014}
}

@inproceedings{lamounier_use_2010,
	title = {On the use of {Virtual} and {Augmented} {Reality} for upper limb prostheses training and simulation},
	doi = {10.1109/IEMBS.2010.5626370},
	abstract = {Accidents happen and unfortunately people may loose part of their body members. Studies have shown that in this case, most individuals suffer physically and psychologically. For this reason, actions to restore the patient's freedom and mobility are imperative. Traditional solutions require ways to adapt the individual to prosthetic devices. This idea is also applied to patients who have congenital limitations. However, one of the major difficulties faced by those who are fitted with these devices is the great mental effort needed during first stages of training. As a result, a meaningful number of patients give up the use of theses devices very soon. Thus, this article reports on a solution designed by the authors to help patients during the learning phases, without actually having to wear the prosthesis. This solution considers Virtual (VR) and Augmented Reality (AR) techniques to mimic the prosthesis natural counterparts. Thus, it is expected that problems such as weight, heat and pain should not contribute to an already hard task.},
	booktitle = {2010 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology}},
	author = {Lamounier, E. and Lopes, K. and Cardoso, A. and Andrade, A. and Soares, A.},
	month = aug,
	year = {2010},
	keywords = {augmented reality, medical computing, patient rehabilitation, prosthetics, virtual reality, virtual reality, augmented reality, upper limb prostheses training, upper limb prostheses simulation, prosthetic devices, congenital limitations, prosthetic natural counterpart mimicking, Electromyography, Augmented reality, Solid modeling, Prosthetics, Real time systems, Training, Algorithms, Amputation, Artificial Limbs, Biomechanics, Computer Simulation, Equipment Design, Humans, Monitoring, Ambulatory, Pain, Prosthesis Design, Signal Processing, Computer-Assisted, Upper Extremity},
	pages = {2451--2454}
}

@article{ortiz-catalan_phantom_2016,
	title = {Phantom motor execution facilitated by machine learning and augmented reality as treatment for phantom limb pain: a single group, clinical trial in patients with chronic intractable phantom limb pain},
	volume = {388},
	issn = {01406736},
	shorttitle = {Phantom motor execution facilitated by machine learning and augmented reality as treatment for phantom limb pain},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673616315987},
	doi = {10.1016/S0140-6736(16)31598-7},
	language = {en},
	number = {10062},
	urldate = {2019-09-14},
	journal = {The Lancet},
	author = {Ortiz-Catalan, Max and Guðmundsdóttir, Rannveig A and Kristoffersen, Morten B and Zepeda-Echavarria, Alejandra and Caine-Winterberger, Kerstin and Kulbacka-Ortiz, Katarzyna and Widehammar, Cathrine and Eriksson, Karin and Stockselius, Anita and Ragnö, Christina and Pihlar, Zdenka and Burger, Helena and Hermansson, Liselotte},
	month = dec,
	year = {2016},
	pages = {2885--2894}
}

@article{ortiz-catalan_treatment_2014,
	title = {Treatment of phantom limb pain ({PLP}) based on augmented reality and gaming controlled by myoelectric pattern recognition: a case study of a chronic {PLP} patient},
	volume = {8},
	issn = {1662-453X},
	shorttitle = {Treatment of phantom limb pain ({PLP}) based on augmented reality and gaming controlled by myoelectric pattern recognition},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2014.00024/abstract},
	doi = {10.3389/fnins.2014.00024},
	urldate = {2019-09-14},
	journal = {Frontiers in Neuroscience},
	author = {Ortiz-Catalan, Max and Sander, Nichlas and Kristoffersen, Morten B. and Håkansson, Bo and Brånemark, Rickard},
	year = {2014}
}

@article{berlier_integration_2018,
	title = {Integration of {Augmented} {Reality} and {Neuromuscular} {Control} {Systems} for {Remote} {Vehicle} {Operations}},
	author = {Berlier, Adam J and Brown, Bradford and Christovich, Timothy and Hester, Taylor and Koury, Brandon J and Monk, Cameron T and Woolford, Chadwick A},
	year = {2018}
}

@inproceedings{woodward_virtual_2017,
	address = {Montreal, QC, Canada},
	title = {A virtual coach for upper-extremity myoelectric prosthetic rehabilitation},
	isbn = {9781509030538},
	url = {http://ieeexplore.ieee.org/document/8007495/},
	doi = {10.1109/ICVR.2017.8007495},
	urldate = {2019-09-14},
	booktitle = {2017 {International} {Conference} on {Virtual} {Rehabilitation} ({ICVR})},
	publisher = {IEEE},
	author = {Woodward, Richard B. and Cancio, Jill M. and Fisher, Robert and Hargrove, Levi J. and Rabago, Christopher A. and Siewiorek, Dan and Smailagic, Asim},
	month = jun,
	year = {2017},
	pages = {1--2}
}

@article{roche_prosthetic_2014,
	title = {Prosthetic {Myoelectric} {Control} {Strategies}: {A} {Clinical} {Perspective}},
	volume = {2},
	issn = {2167-4817},
	shorttitle = {Prosthetic {Myoelectric} {Control} {Strategies}},
	url = {http://link.springer.com/10.1007/s40137-013-0044-8},
	doi = {10.1007/s40137-013-0044-8},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {Current Surgery Reports},
	author = {Roche, Aidan D. and Rehbaum, Hubertus and Farina, Dario and Aszmann, Oskar C.},
	month = mar,
	year = {2014},
	pages = {44}
}

@article{markovic_stereovision_2014,
	title = {Stereovision and augmented reality for closed-loop control of grasping in hand prostheses},
	volume = {11},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/11/i=4/a=046001?key=crossref.920cc30034714dfe1da6df3291ab5200},
	doi = {10.1088/1741-2560/11/4/046001},
	number = {4},
	urldate = {2019-09-14},
	journal = {Journal of Neural Engineering},
	author = {Markovic, Marko and Dosen, Strahinja and Cipriani, Christian and Popovic, Dejan and Farina, Dario},
	month = aug,
	year = {2014},
	pages = {046001}
}

@article{soares_virtual_2012,
	title = {Virtual and {Augmented} {Reality}: {A} {New} {Approach} to {Aid} {Users} of {Myoelectric} {Prostheses}},
	shorttitle = {Virtual and {Augmented} {Reality}},
	url = {https://www.intechopen.com/books/computational-intelligence-in-electromyography-analysis-a-perspective-on-current-applications-and-future-challenges/virtual-and-augmented-reality-a-new-approach-to-aid-users-of-myoelectric-prostheses},
	doi = {10.5772/50600},
	abstract = {Open access peer-reviewed chapter},
	language = {en},
	urldate = {2019-09-14},
	journal = {Computational Intelligence in Electromyography Analysis - A Perspective on Current Applications and Future Challenges},
	author = {Soares, Alcimar Barbosa and Júnior, Edgard Afonso Lamounier and Andrade, Adriano de Oliveira and Cardoso, Alexandre},
	month = oct,
	year = {2012}
}

@article{kenedy_lopes_using_2013,
	title = {Using {Augmented} {Reality} {Techniques} to {Simulate} {Myoelectric} {Upper} {Limb} {Prostheses}},
	issn = {21559538},
	url = {https://www.omicsonline.org/using-augmented-reality-techniques-to-simulate-myoelectric-upper-limb-prostheses-2155-9538.S1-010.php?aid=4717},
	doi = {10.4172/2155-9538.S1-010},
	urldate = {2019-09-14},
	journal = {Journal of Bioengineering and Biomedical Sciences},
	author = {Kenedy Lopes, Edgard Afonso Lamounier},
	year = {2013}
}

@article{ninu_closed-loop_2014,
	title = {Closed-{Loop} {Control} of {Grasping} {With} a {Myoelectric} {Hand} {Prosthesis}: {Which} {Are} the {Relevant} {Feedback} {Variables} for {Force} {Control}?},
	volume = {22},
	issn = {1534-4320, 1558-0210},
	shorttitle = {Closed-{Loop} {Control} of {Grasping} {With} a {Myoelectric} {Hand} {Prosthesis}},
	url = {http://ieeexplore.ieee.org/document/6807741/},
	doi = {10.1109/TNSRE.2014.2318431},
	number = {5},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Ninu, Andrei and Dosen, Strahinja and Muceli, Silvia and Rattay, Frank and Dietl, Hans and Farina, Dario},
	month = sep,
	year = {2014},
	pages = {1041--1052}
}

@inproceedings{tabor_game-based_2016,
	address = {Austin, Texas, USA},
	title = {Game-{Based} {Myoelectric} {Training}},
	isbn = {9781450344586},
	url = {http://dl.acm.org/citation.cfm?doid=2968120.2987731},
	doi = {10.1145/2968120.2987731},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the 2016 {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play} {Companion} {Extended} {Abstracts} - {CHI} {PLAY} {Companion} '16},
	publisher = {ACM Press},
	author = {Tabor, Aaron and Bateman, Scott and Scheme, Erik},
	year = {2016},
	pages = {299--306}
}

@article{clemente_humans_2017,
	title = {Humans {Can} {Integrate} {Augmented} {Reality} {Feedback} in {Their} {Sensorimotor} {Control} of a {Robotic} {Hand}},
	volume = {47},
	issn = {2168-2291, 2168-2305},
	url = {http://ieeexplore.ieee.org/document/7588033/},
	doi = {10.1109/THMS.2016.2611998},
	number = {4},
	urldate = {2019-09-14},
	journal = {IEEE Transactions on Human-Machine Systems},
	author = {Clemente, Francesco and Dosen, Strahinja and Lonini, Luca and Markovic, Marko and Farina, Dario and Cipriani, Christian},
	month = aug,
	year = {2017},
	pages = {583--589}
}

@article{markovic_glimpse:_2017,
	title = {{GLIMPSE}: {Google} {Glass} interface for sensory feedback in myoelectric hand prostheses},
	volume = {14},
	issn = {1741-2560, 1741-2552},
	shorttitle = {{GLIMPSE}},
	url = {http://stacks.iop.org/1741-2552/14/i=3/a=036007?key=crossref.5da5d68d8ce7f07868eef5b4347fcba5},
	doi = {10.1088/1741-2552/aa620a},
	number = {3},
	urldate = {2019-09-14},
	journal = {Journal of Neural Engineering},
	author = {Markovic, Marko and Karnal, Hemanth and Graimann, Bernhard and Farina, Dario and Dosen, Strahinja},
	month = jun,
	year = {2017},
	pages = {036007}
}

@inproceedings{boschmann_novel_2016,
	address = {Las Vegas, NV},
	title = {A novel immersive augmented reality system for prosthesis training and assessment},
	isbn = {9781509024551},
	url = {http://ieeexplore.ieee.org/document/7455889/},
	doi = {10.1109/BHI.2016.7455889},
	urldate = {2019-09-14},
	booktitle = {2016 {IEEE}-{EMBS} {International} {Conference} on {Biomedical} and {Health} {Informatics} ({BHI})},
	publisher = {IEEE},
	author = {Boschmann, Alexander and Dosen, Strahinja and Werner, Andreas and Raies, Ali and Farina, Dario},
	month = feb,
	year = {2016},
	pages = {280--283}
}

@inproceedings{ban_augmented_2013,
	address = {Paris, France},
	title = {Augmented endurance: controlling fatigue while handling objects by affecting weight perception using augmented reality},
	isbn = {9781450318990},
	shorttitle = {Augmented endurance},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2470665},
	doi = {10.1145/2470654.2470665},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
	year = {2013},
	pages = {69}
}


@inproceedings{Si-Mohammed_2017,
author = {Si-Mohammed, Hakim and Argelaguet, Ferran and Casiez, Géry and Roussel, Nicolas and Lécuyer, Anatole},
year = {2017},
month = {09},
pages = {},
title = {Brain-Computer Interfaces and Augmented Reality: A State of the Art},
doi = {10.3217/978-3-85125-533-1-82}
}

@INPROCEEDINGS{K_Higa_2007,
author={K. {Higa} and T. {Nishiura} and A. {Kimura} and F. {Shibata} and H. {Tamura}},
booktitle={2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
title={A Two-by-Two Mixed Reality System That Merges Real and Virtual Worlds in Both Audio and Visual Senses},
year={2007},
volume={},
number={},
pages={203-206},
keywords={virtual reality;two-by-two mixed reality system;virtual reality;geometric consistency;audio sense;closed-air headphones;Virtual reality;Headphones;Auditory displays;Real time systems;Optical sensors;Computer displays;Merging;Layout;Humans;Chromium;Mixed Reality;Audio and Visual Senses;Geometric Consistency;Open-Air Headphones;Closed-Air Headphones},
doi={10.1109/ISMAR.2007.4538847},
ISSN={},
month={Nov},
}

@article{Feng-Zhou_2008,
author = {Zhou, Feng and Duh, Henry and Billinghurst, Mark},
year = {2008},
month = {09},
pages = {193-202},
title = {Trends in Augmented Reality Tracking, Interaction and Display: A Review of Ten Years of ISMAR},
volume = {2},
journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2008.4637362}
}

@INPROCEEDINGS{Abbasi-Asl_2019,
author={R. {Abbasi-Asl} and M. {Keshavarzi} and D. Y. {Chan}},
booktitle={2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)},
title={Brain-Computer Interface in Virtual Reality},
year={2019},
volume={},
number={},
pages={1220-1224},
keywords={biomedical electrodes;brain-computer interfaces;electroencephalography;handicapped aids;medical computing;medical signal processing;virtual reality;brain computer interface systems;virtual reality environments;2D regular displays;wearable electroencephalography device;VR headset;virtual interface;human subjects;object rotation;mental commands;smile;eyebrow movement;similar tasks;regular 2D monitor screens;VR settings;future BCI systems;virtual reality settings;time 1.0 min;Electroencephalography;Two dimensional displays;Virtual reality;Task analysis;Headphones;Eyebrows;Three-dimensional displays},
doi={10.1109/NER.2019.8717158},
ISSN={},
month={March},
}

@INPROCEEDINGS{Ranasinghe_2012,
author={N. {Ranasinghe} and R. {Nakatsu} and H. {Nii} and P. {Gopalakrishnakone}},
booktitle={2012 16th International Symposium on Wearable Computers},
title={Tongue Mounted Interface for Digitally Actuating the Sense of Taste},
year={2012},
volume={},
number={},
pages={80-87},
keywords={biocontrol;chemioception;digital control;tongue mounted interface;sense of taste;taste sensations;electrical stimulation;thermal stimulation;digital control systems;tongue mounted digital taste interface;digital sour lollipop;human tongue;Tongue;Humans;Electrical stimulation;Computers;Chemicals;Electrodes;Control systems;Taste;Digital Taste;Gustation;User interfaces;Control systems;Virtual reality;Ubiquitous computing},
doi={10.1109/ISWC.2012.16},
ISSN={},
month={June},
}

@article{Kessler_1995,
author = {Kessler, Gregory and Walker, Neff and Hodges, Larry},
year = {1995},
month = {12},
pages = {},
title = {Evaluation of the CyberGlove(TM) as a Whole Hand Input Device},
volume = {2},
journal = {ACM Transactions on Computer-Human Interaction},
doi = {10.1145/212430.212431}
}

@inproceedings{Choi_2017,
author = {Choi, Inrak and Culbertson, Heather and Miller, Mark and Olwal, Alex and Follmer, Sean},
year = {2017},
month = {10},
pages = {119-130},
title = {Grabity: A Wearable Haptic Interface for Simulating Weight and Grasping in Virtual Reality},
doi = {10.1145/3126594.3126599}
}

@article{Minamizawa_2007,
author = {Minamizawa, Kouta and Fukamachi, Souichiro and Kajimoto, Hiroyuki and Kawakami, Naoki and Tachi, Susumu},
year = {2007},
month = {01},
pages = {8},
title = {Gravity grabber: wearable haptic display to present virtual mass sensation},
isbn = {978-1-4503-1824-2},
doi = {10.1145/1278280.1278289}
}

@inproceedings{Moriyama_2018,
author = {Moriyama, Taha and Ayaka, Nishi and Nakamura, Takuto and Yem, Vibol and Kajimoto, Hiroyuk},
year = {2018},
month = {12},
pages = {1-2},
title = {Hap-link: wearable haptic device on the forearm that presents haptics sensations corresponding to the fingers},
doi = {10.1145/3275476.3275488}
}

@inproceedings{Hamza-Lup_2019,
author = {Hamza Lup, Felix and Bergeron, Kyle and Newton, Daniel},
year = {2019},
month = {03},
pages = {},
title = {Haptic Systems in User Interfaces - State of the Art Survey},
doi = {10.1145/3299815.3314445}
}

@inproceedings{Perret_2018,
author = {Perret, Jérôme and Vander Poorten, Emmanuel},
year = {2018},
month = {06},
pages = {},
title = {Touching Virtual Reality: a Review of Haptic Gloves}
}

@inproceedings{Gu_2016,
author = {Gu, Xiaochi and Zhang, Yifei and Sun, Weize and Bian, Yuanzhe and Zhou, Dao and Kristensson, Per},
year = {2016},
month = {05},
pages = {1991-1995},
title = {Dexmo: An Inexpensive and Lightweight Mechanical Exoskeleton for Motion Capture and Force Feedback in VR},
doi = {10.1145/2858036.2858487}
}

@inproceedings{Whitmire_2018,
author = {Whitmire, Eric and Benko, Hrvoje and Holz, Christian and Ofek, Eyal and Sinclair, Michael},
year = {2018},
month = {04},
pages = {1-12},
title = {Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfigurable Virtual Reality Controller},
doi = {10.1145/3173574.3173660}
}

@INPROCEEDINGS{Ahmed_2015,
author={L. {Ahmed} and S. {Hamdy} and D. {Hegazy} and T. {El-Arif}},
booktitle={2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)},
title={Interaction techniques in mobile Augmented Reality: State-of-the-art},
year={2015},
volume={},
number={},
pages={424-433},
keywords={augmented reality;human computer interaction;mobile computing;interaction techniques;mobile augmented reality;intangible techniques;tangible techniques;Visualization;Rendering (computer graphics);Merging;Cameras;Tracking;Image segmentation;Mobile Augmented Reality;Tangible Interaction;Intagible Interaction},
doi={10.1109/IntelCIS.2015.7397255},
ISSN={},
month={Dec},}

@INPROCEEDINGS{Gabardi_2016,
author={M. {Gabardi} and M. {Solazzi} and D. {Leonardis} and A. {Frisoli}},
booktitle={2016 IEEE Haptics Symposium (HAPTICS)},
title={A new wearable fingertip haptic interface for the rendering of virtual shapes and surface features},
year={2016},
volume={},
number={},
pages={140-146},
keywords={haptic interfaces;rendering (computer graphics);wearable fingertip haptic interface;rendering;virtual shape;surface feature;Haptic Thimble;wearable haptic device;surface exploration;tactile feedback;reactive contact;surface asperities;serial kinematics;compact servo motor;voice coil;kinesthetic feedback;Haptic interfaces;Force;Actuators;Rendering (computer graphics);Kinematics;Surface texture;Performance evaluation},
doi={10.1109/HAPTICS.2016.7463168},
ISSN={},
month={April},
}

@ARTICLE{Meli_2018,
author={L. {Meli} and I. {Hussain} and M. {Aurilio} and M. {Malvezzi} and M. K. {O’Malley} and D. {Prattichizzo}},
journal={IEEE Robotics and Automation Letters},
title={The hBracelet: A Wearable Haptic Device for the Distributed Mechanotactile Stimulation of the Upper Limb},
year={2018},
volume={3},
number={3},
pages={2198-2205},
keywords={haptic interfaces;medical computing;virtual reality;robotic manipulators;human body;virtual environment interactions;remote environment interactions;upper limb;distributed mechanotactile stimulation;belt presses;control strategies;wearable haptic display;haptic interface;body area;hBracelet;wearable haptic device;mechatronic devices;tactile sensations;haptic stimuli;linear actuator;servoactuators;wearable skin;wearable solutions;Actuators;Belts;Haptic interfaces;Force;Robots;Skin;Pulleys;Haptics and haptic interfaces;wearable robots;human-centered robotics;telerobotics and teleoperation},
doi={10.1109/LRA.2018.2810958},
ISSN={},
month={July},
}

@article{Rizzo_2017,
author = {Rizzo, Rocco and Musolino, Antonino and Jones, Lynette},
year = {2017},
month = {11},
pages = {1-1},
title = {Shape Localization and Recognition Using a Magnetorheological-Fluid Haptic Display},
volume = {PP},
journal = {IEEE Transactions on Haptics},
doi = {10.1109/TOH.2017.2771420}
}

@INPROCEEDINGS{Nojima_2002,
author={T. {Nojima} and D. {Sekiguchi} and M. {Inami} and S. {Tachi}},
booktitle={Proceedings IEEE Virtual Reality 2002},
title={The SmartTool: a system for augmented reality of haptics},
year={2002},
volume={},
number={},
pages={67-72},
keywords={augmented reality;haptic interfaces;augmented reality;haptics;haptic sensation;SmartTool;real environment;time sensor;haptic display;prototype system;Augmented reality;Haptic interfaces;Humans;Displays;Surgery;Navigation;Cameras;Acoustics;Real time systems;Machine vision},
doi={10.1109/VR.2002.996506},
ISSN={},
month={March},
}

@ARTICLE{Pacchierotti_2017,
author={C. {Pacchierotti} and S. {Sinclair} and M. {Solazzi} and A. {Frisoli} and V. {Hayward} and D. {Prattichizzo}},
journal={IEEE Transactions on Haptics},
title={Wearable Haptic Systems for the Fingertip and the Hand: Taxonomy, Review, and Perspectives},
year={2017},
volume={10},
number={4},
pages={580-600},
keywords={haptic interfaces;representative wearable haptic systems;fingertip;taxonomy;wearable haptic interfaces;wearability challenges;technological design;hand haptic system;Haptic interfaces;Robots;Exoskeletons;Wearable computing;Vibrations;Force feedback;Taxonomy;Haptic interfaces;Wearable haptics;fingertip haptics;hand exoskeletons;wearable devices;wearable interfaces;cutaneous force feedback;tactile force feedback;taxonomy;review;Feedback;Hand;Humans;Physical Stimulation;Touch;Wearable Electronic Devices},
doi={10.1109/TOH.2017.2689006},
ISSN={},
month={Oct},
}

@inproceedings{Ranasinghe_2013,
author = {Ranasinghe, Nimesha and Cheok, Adrian and Nakatsu, Ryohei and Do, Ellen},
year = {2013},
month = {10},
pages = {29-34},
title = {Simulating the sensation of taste for immersive experiences},
doi = {10.1145/2512142.2512148}
}

@article{Jacks_2003,
author = {Jacks, A and Miller, N},
year = {2003},
month = {02},
pages = {7-9},
title = {Spontaneous retinal venous pulsation: Aetiology and significance},
volume = {74},
journal = {Journal of neurology, neurosurgery, and psychiatry},
doi = {10.1136/jnnp.74.1.7}
}

@article{Zander_2011,
author = {Zander, Thorsten and Kothe, Christian},
year = {2011},
month = {03},
pages = {025005},
title = {Towards passive Brain–Computer interfaces: applying Brain–Computer interface technology to human-machine systems in general},
volume = {8},
journal = {Journal of neural engineering},
doi = {10.1088/1741-2560/8/2/025005}
}

@ARTICLE{Jeon_2009,
author={S. {Jeon} and S. {Choi}},
journal={Presence},
title={Haptic Augmented Reality: Taxonomy and an Example of Stiffness Modulation},
year={2009},
volume={18},
number={5},
pages={387-408},
keywords={},
doi={10.1162/pres.18.5.387},
ISSN={},
month={Oct},}

@inproceedings{Milgram_1993,
author = {Milgram, Paul and Zhai, Shumin and Drascic, David and Grodski, J.},
year = {1993},
month = {08},
pages = {1467 - 1472 vol.3},
title = {Applications of augmented reality for human-robot communication},
isbn = {0-7803-0823-9},
journal = {Journal of Intelligent and Robotic Systems - JIRS},
doi = {10.1109/IROS.1993.583833}
}

@inproceedings{Billinghurst_2009,
author = {Billinghurst, Mark and Kato, Hirokazu and Myojin, Seiko},
year = {2009},
month = {07},
pages = {13-22},
title = {Advanced Interaction Techniques for Augmented Reality Applications},
volume = {5622},
journal = {Lecture Notes in Computer Science},
doi = {10.1007/978-3-642-02771-0_2}
}

@inbook{Margallo_2010,
author = {Sánchez Margallo, Francisco and Sánchez-Margallo, Juan A. and Pagador, J Blas and Moyano, José and Moreno_del_Pozo, José and Usón, Jesús},
year = {2010},
month = {01},
pages = {121-128},
title = {Ergonomic Assessment of Hand Movements in Laparoscopic Surgery Using the CyberGlove®},
journal = {Computational Biomechanics for Medicine},
doi = {10.1007/978-1-4419-5874-7_13}
}

@article{Wang_2019,
author = {Wang, Dangxiao and Guo, Yuan and Liu, Shiyi and Zhang, Yuru and Xu, Weiliang and Xiao, Jing},
year = {2019},
month = {04},
pages = {},
title = {Haptic display for virtual reality: progress and challenges},
volume = {1},
journal = {Virtual Reality & Intelligent Hardware},
doi = {10.3724/SP.J.2096-5796.2019.0008}
}

@inproceedings{Marwecki_2018,
author = {Marwecki, Sebastian and Brehm, Maximilian and Wagner, Lukas and Cheng, Lung-Pan and Mueller, Florian and Baudisch, Patrick},
year = {2018},
month = {04},
pages = {1-10},
title = {VirtualSpace - Overloading Physical Space with Multiple Virtual Reality Users},
doi = {10.1145/3173574.3173815}
}

@inproceedings{Lopes_2018,
 author = {Lopes, Pedro and You, Sijing and Ion, Alexandra and Baudisch, Patrick},
 title = {Adding Force Feedback to Mixed Reality Experiences and Games Using Electrical Muscle Stimulation},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {446:1--446:13},
 articleno = {446},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3173574.3174020},
 doi = {10.1145/3173574.3174020},
 acmid = {3174020},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ar, augmented reality, body i/o, electrical muscle stimulation, haptics, hololens, mixed reality, mr, wearable},
} 

@inproceedings{Rietzler_2018,
 author = {Rietzler, Michael and Geiselhart, Florian and Frommel, Julian and Rukzio, Enrico},
 title = {Conveying the Perception of Kinesthetic Feedback in Virtual Reality Using State-of-the-Art Hardware},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {460:1--460:13},
 articleno = {460},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3173574.3174034},
 doi = {10.1145/3173574.3174034},
 acmid = {3174034},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {kinesthetic feedback, pseudo haptics, virtual reality},
} 

@inproceedings{Zhao_2018,
 author = {Zhao, Yuhang and Bennett, Cynthia L. and Benko, Hrvoje and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Sinclair, Mike},
 title = {Enabling People with Visual Impairments to Navigate Virtual Reality with a Haptic and Auditory Cane Simulation},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {116:1--116:14},
 articleno = {116},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3173574.3173690},
 doi = {10.1145/3173574.3173690},
 acmid = {3173690},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {auditory feedback, blindness, haptic feedback, mobility, virtual reality, visual impairments, white cane},
} 

@inproceedings{Yan_2018,
 author = {Yan, Yukang and Yu, Chun and Ma, Xiaojuan and Huang, Shuai and Iqbal, Hasan and Shi, Yuanchun},
 title = {Eyes-Free Target Acquisition in Interaction Space Around the Body for Virtual Reality},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {42:1--42:13},
 articleno = {42},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3173574.3173616},
 doi = {10.1145/3173574.3173616},
 acmid = {3173616},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eyes-free, proprioception, target acquisition, virtual reality},
}

@inproceedings{Vovk_2018,
 author = {Vovk, Alla and Wild, Fridolin and Guest, Will and Kuula, Timo},
 title = {Simulator Sickness in Augmented Reality Training Using the Microsoft HoloLens},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {209:1--209:9},
 articleno = {209},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3173574.3173783},
 doi = {10.1145/3173574.3173783},
 acmid = {3173783},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, microsoft hololens, motion sickness, simulator sickness},
} 

@inproceedings{Albouys-Perrois_2018,
 author = {Albouys-Perrois, J{\'e}r{\'e}my and Laviole, J{\'e}r{\'e}my and Briant, Carine and Brock, Anke M.},
 title = {Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: A Participatory Design Approach},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {629:1--629:14},
 articleno = {629},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3173574.3174203},
 doi = {10.1145/3173574.3174203},
 acmid = {3174203},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {accessibility, augmented reality, geographic maps, participatory design, visual impairment},
}

@inproceedings{Dillman_2018,
 author = {Dillman, Kody R. and Mok, Terrance Tin Hoi and Tang, Anthony and Oehlberg, Lora and Mitchell, Alex},
 title = {A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {140:1--140:12},
 articleno = {140},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3173574.3173714},
 doi = {10.1145/3173574.3173714},
 acmid = {3173714},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, game design, guidance, interaction cues},
}

@inproceedings{Sra_2018,
 author = {Sra, Misha and Xu, Xuhai and Maes, Pattie},
 title = {BreathVR: Leveraging Breathing As a Directly Controlled Interface for Virtual Reality Games},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {340:1--340:12},
 articleno = {340},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3173574.3173914},
 doi = {10.1145/3173574.3173914},
 acmid = {3173914},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {breathing actions, game design, physiological control, virtual reality},
}

@inproceedings{Huang_2018,
author = {Huang, Yu-Hsuan and Chang, Hao-Yu and Yang, Wan-ling and Chiu, Yu-Kai and Yu, Tzu-Chieh and Tsai, Pei-Hsuan and Ouhyoung, Ming},
year = {2018},
month = {04},
pages = {1-12},
title = {CatAR: A Novel Stereoscopic Augmented Reality Cataract Surgery Training System with Dexterous Instruments Tracking Technology},
doi = {10.1145/3173574.3174039}
}

@inproceedings{Gugenheimer_2018,
author = {Gugenheimer, Jan and Stemasov, Evgeny and Sareen, Harpreet and Rukzio, Enrico},
year = {2018},
month = {04},
pages = {1-13},
title = {FaceDisplay: Towards Asymmetric Multi-User Interaction for Nomadic Virtual Reality},
doi = {10.1145/3173574.3173628}
}

@inproceedings{Strasnick_2018,
author = {Strasnick, Evan and Holz, Christian and Ofek, Eyal and Sinclair, Michael and Benko, Hrvoje},
year = {2018},
month = {04},
pages = {1-12},
title = {Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation},
doi = {10.1145/3173574.3174218}
}

@inproceedings{Whitmire_2018,
author = {Whitmire, Eric and Benko, Hrvoje and Holz, Christian and Ofek, Eyal and Sinclair, Michael},
year = {2018},
month = {04},
pages = {1-12},
title = {Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfigurable Virtual Reality Controller},
doi = {10.1145/3173574.3173660}
}

@inproceedings{Cheng_2018,
author = {Cheng, Lung-Pan and Chang, Li and Marwecki, Sebastian and Baudisch, Patrick},
year = {2018},
month = {04},
pages = {1-10},
title = {iTurk: Turning Passive Haptics into Active Haptics by Making Users Reconfigure Props in Virtual Reality},
doi = {10.1145/3173574.3173663}
}

@inproceedings{Gweon_2018,
 author = {Gweon, Gahgene and Kim, Bugeun and Kim, Jinyoung and Lee, Kung Jin and Rhim, Jungwook and Choi, Jueun},
 title = {MABLE: Mediating Young Children's Smart Media Usage with Augmented Reality},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {13:1--13:9},
 articleno = {13},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3173574.3173587},
 doi = {10.1145/3173574.3173587},
 acmid = {3173587},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality (ar), engagement, parental medi-ation, preschoolers, rule compliance, smart media usage},
}

@inproceedings{Nebeling_2018,
 author = {Nebeling, Michael and Nebeling, Janet and Yu, Ao and Rumble, Rob},
 title = {ProtoAR: Rapid Physical-Digital Prototyping of Mobile Augmented Reality Applications},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {353:1--353:12},
 articleno = {353},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3173574.3173927},
 doi = {10.1145/3173574.3173927},
 acmid = {3173927},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mobile augmented reality, physical-digital prototyping, quasi-3d 360-degree captures},
} 

@inproceedings{Lindlbauer_2018,
author = {Lindlbauer, David and Wilson, Andy},
year = {2018},
month = {04},
pages = {1-13},
title = {Remixed Reality: Manipulating Space and Time in Augmented Reality},
doi = {10.1145/3173574.3173703}
}

@inproceedings{Poyade_2017,
author = {Poyade, Matthieu and Morris, Glyn and Taylor, Ian and Portela, Victor},
year = {2017},
month = {11},
pages = {504-505},
title = {Using mobile virtual reality to empower people with hidden disabilities to overcome their barriers},
doi = {10.1145/3136755.3143025}
}

@inproceedings{Tiefenbacher_2014,
author = {Tiefenbacher, Philipp and Wichert, Steven and Merget, Daniel and Rigoll, Gerhard},
year = {2014},
month = {11},
pages = {435-438},
title = {Impact of Coordinate Systems on 3D Manipulations in Mobile Augmented Reality},
doi = {10.1145/2663204.2663234}
}

@inproceedings{Hurst_2016,
 author = {H\"{u}rst, Wolfgang and Iwai, Daisuke and Balakrishnan, Prabhakaran},
 title = {International Workshop on Multimodal Virtual and Augmented Reality (Workshop Summary)},
 booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
 series = {ICMI '16},
 year = {2016},
 isbn = {978-1-4503-4556-9},
 location = {Tokyo, Japan},
 pages = {596--597},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2993148.3007631},
 doi = {10.1145/2993148.3007631},
 acmid = {3007631},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Multimodal virtual reality, multimodal augmented reality, multimodal mixed reality},
} 

@inproceedings{Joachimczak_2017,
author = {Joachimczak, Michał and Liu, Juan and Ando, Hiroshi},
year = {2017},
month = {11},
pages = {514-515},
title = {Real-time mixed-reality telepresence via 3D reconstruction with HoloLens and commodity depth sensors},
doi = {10.1145/3136755.3143031}
}

@inproceedings{Mavridou_2018,
author = {Mavridou, Ifigeneia and Seiss, Ellen and Kostoulas, Theodoros and Nduka, Charles and Balaguer-Ballester, Emili},
year = {2018},
month = {10},
pages = {1-6},
title = {Towards an effective arousal detection system for virtual reality},
doi = {10.1145/3279963.3279969}
}

@inproceedings{Hirshfield_2018,
 author = {Hirshfield, Leanne and Williams, Tom and Sommer, Natalie and Grant, Trevor and Gursoy, Senem Velipasalar},
 title = {Workload-driven Modulation of Mixed-reality Robot-human Communication},
 booktitle = {Proceedings of the Workshop on Modeling Cognitive Processes from Multimodal Data},
 series = {MCPMD '18},
 year = {2016},
 isbn = {978-1-4503-6072-2},
 location = {Boulder, Colorado},
 pages = {3:1--3:8},
 articleno = {3},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/3279810.3279848},
 doi = {10.1145/3279810.3279848},
 acmid = {3279848},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{wen_hand_2014,
	title = {Hand gesture guided robot-assisted surgery based on a direct augmented reality interface},
	volume = {116},
	issn = {01692607},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260713004082},
	doi = {10.1016/j.cmpb.2013.12.018},
	language = {en},
	number = {2},
	urldate = {2019-09-20},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Wen, Rong and Tay, Wei-Liang and Nguyen, Binh P. and Chng, Chin-Boon and Chui, Chee-Kong},
	month = sep,
	year = {2014},
	pages = {68--80}
}

@inproceedings{white_visual_2007,
	address = {Washington, DC, USA},
	series = {{ISMAR} '07},
	title = {Visual {Hints} for {Tangible} {Gestures} in {Augmented} {Reality}},
	isbn = {9781424417490},
	url = {https://doi.org/10.1109/ISMAR.2007.4538824},
	doi = {10.1109/ISMAR.2007.4538824},
	abstract = {Tangible Augmented Reality (AR) systems imbue physical objects with the ability to act and respond in new ways. In particular, physical objects and gestures made with them gain meaning that does not exist outside the tangible AR environment. The existence of this new set of possible actions and outcomes is not always apparent, making it necessary to learn new movements or gestures. Addressing this opportunity, we present visual hints, which are graphical representations in AR of potential actions and their consequences in the augmented physical world. Visual hints enable discovery, learning, and completion of gestures and manipulation in tangible AR. Here, we discuss our investigation of a variety of representations of visual hints and methods for activating them. We then describe a specific implementation that supports gestures developed for a tangible AR user interface to an electronic field guide for botanists, and present results from a pilot study.},
	urldate = {2019-09-20},
	booktitle = {Proceedings of the 2007 6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Computer Society},
	author = {White, Sean and Lister, Levi and Feiner, Steven},
	year = {2007},
	pages = {1--4}
}

@article{lee_hand_2010,
	title = {Hand gesture-based tangible interactions for manipulating virtual objects in a mixed reality environment},
	volume = {51},
	issn = {0268-3768, 1433-3015},
	url = {http://link.springer.com/10.1007/s00170-010-2671-x},
	doi = {10.1007/s00170-010-2671-x},
	language = {en},
	number = {9-12},
	urldate = {2019-09-20},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Lee, Jae Yeol and Rhee, Gue Won and Seo, Dong Woo},
	month = dec,
	year = {2010},
	pages = {1069--1082}
}

@article{hossein_spatial_2013,
	title = {A {Spatial} {Augmented} {Reality} {Rehab} {System} for {Post}-{Stroke} {Hand} {Rehabilitation}},
	copyright = {©2013 \&copy; The authors and IOS Press. All rights reserved.},
	issn = {0926-9630},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospressISSNISBN&issn=0926-9630&volume=184&spage=279},
	doi = {10.3233/978-1-61499-209-7-279},
	abstract = {This paper features a Spatial Augmented Reality system for rehabilitation of hand and arm movement. The table-top home-based system tracks a subject's hand and creates a virtual audio-visual interface for performing rehabilitation-related tasks that involve wrist, elbow, and shoulder movements. It measures range, speed, and smoothness of movements locally and can send the real-time photos and data to the clinic for further assessment. To evaluate the system, it was tested on two normal subjects and proved functional.},
	urldate = {2019-09-20},
	journal = {Studies in Health Technology and Informatics},
	author = {Hossein, Mousavi Hondori and Maryam, Khademi and Lucy, Dodakian and C, Cramer Steven and Videira, Lopes Cristina},
	year = {2013},
	pages = {279--285}
}

@article{escolano_telepresence_2012,
	title = {A {Telepresence} {Mobile} {Robot} {Controlled} {With} a {Noninvasive} {Brain}–{Computer} {Interface}},
	volume = {42},
	issn = {1083-4419, 1941-0492},
	url = {http://ieeexplore.ieee.org/document/6104414/},
	doi = {10.1109/TSMCB.2011.2177968},
	number = {3},
	urldate = {2019-09-20},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Escolano, C. and Antelis, J. M. and Minguez, J.},
	month = jun,
	year = {2012},
	pages = {793--804}
}

@article{kerruish_arranging_2019,
	title = {Arranging sensations: smell and taste in augmented and virtual reality},
	volume = {14},
	issn = {1745-8927},
	shorttitle = {Arranging sensations},
	url = {https://doi.org/10.1080/17458927.2018.1556952},
	doi = {10.1080/17458927.2018.1556952},
	abstract = {The development of digital taste and smell underscores the importance of cultural dimensions of bodily perception in augmented reality (AR) and virtual reality (VR) devices. This can be seen in Vocktail and Season Traveller, two digital devices incorporating taste and smell. Vocktail is an AR technology that augments the experience of drinking water, or even air, through the electrical stimulation of tastebuds and the manipulation of color and smell. Season Traveller is a VR game in which the user moves through four seasonal landscapes. It uses wind, odor, and temperature in addition to the more standard audio-visual displays. The cultural dimensions of these devices can be examined using phenomenological terms. They instigate perceptual circuits, and call on and create sedimented habits. Although VR and AR are often thought of in terms of their similitude to reality, understanding Vocktail and Season Traveller this way illustrates the world-creating dimension of multisensory devices. These technologies structure and shift thresholds of taste and smell, reworking past perceptual styles and habits to develop new perceptual experiences. In so doing, Season Traveller and Vocktail throw to the fore questions about the conditions according to which people exercise their senses in digitally dominated environments.},
	number = {1},
	urldate = {2019-09-20},
	journal = {The Senses and Society},
	author = {Kerruish, Erika},
	month = jan,
	year = {2019},
	keywords = {Taste, smell, postphenomenology, augmented reality, virtual reality, multisensory computing},
	pages = {31--45}
}

@inproceedings{barresi_brain-controlled_2015,
	address = {Kowloon Tong, Hong Kong},
	title = {Brain-{Controlled} {AR} {Feedback} {Design} for {User}'s {Training} in {Surgical} {HRI}},
	isbn = {9781479986972},
	url = {http://ieeexplore.ieee.org/document/7379332/},
	doi = {10.1109/SMC.2015.200},
	urldate = {2019-09-20},
	booktitle = {2015 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
	publisher = {IEEE},
	author = {Barresi, Giacinto and Olivieri, Emidio and Caldwell, Darwin G. and Mattos, Leonardo S.},
	month = oct,
	year = {2015},
	pages = {1116--1121}
}

@inproceedings{hasan_human_2012,
	title = {Human {Computer} {Interaction} for {Vision} {Based} {Hand} {Gesture} {Recognition}: {A} {Survey}},
	shorttitle = {Human {Computer} {Interaction} for {Vision} {Based} {Hand} {Gesture} {Recognition}},
	doi = {10.1109/ACSAT.2012.37},
	abstract = {The ultimate aim is to bring Human Computer Interaction to a regime where interactions with computers will be as natural as an interaction between humans, and to this end, incorporating gestures in HCI is an important research area. Gestures have long been considered as an interaction technique that can potentially deliver more natural, creative and intuitive methods for communicating with our computers. This paper provides a summary of previous surveys done in this area and focuses on the different application domain which employs hand gestures for efficient interaction. The use of hand gestures as a natural interface serves as a motivating force for research in gesture taxonomies, its representations and recognition techniques. Also provides an analysis of existing literature related to gesture recognition systems for human computer interaction by categorizing it based on different parameters. The main goal of this survey is to provide researchers in the field with a summary of progress achieved to date and to help identify areas where further research is needed.},
	booktitle = {2012 {International} {Conference} on {Advanced} {Computer} {Science} {Applications} and {Technologies} ({ACSAT})},
	author = {Hasan, H. S. and Kareem, S. A.},
	month = nov,
	year = {2012},
	keywords = {computer vision, gesture recognition, human computer interaction, human computer interaction, vision based hand gesture recognition, HCI, intuitive method, natural interface, gesture taxonomy, Human-Computer Interaction, Gesture recognition, human computer interaction, representations, recognition, natural interfaces},
	pages = {55--60}
}

@article{kolsch_multimodal_2006,
	title = {Multimodal interaction with a wearable augmented reality system},
	volume = {26},
	doi = {10.1109/MCG.2006.66},
	abstract = {An augmented reality system enhances a mobile user's situational awareness and provides new visualization functionality. The custom-built multimodal interface provides access to information encountered in urban environments. In this article, we detail our experiences with various input devices and modalities and discuss their advantages and drawbacks in the context of interaction tasks in mobile computing. We show how we integrated the input channels to use the modalities beneficially and how this enhances the interface's overall usability},
	number = {3},
	journal = {IEEE Computer Graphics and Applications},
	author = {Kolsch, M. and Bane, R. and Hollerer, T. and Turk, M.},
	month = may,
	year = {2006},
	keywords = {augmented reality, data visualisation, mobile computing, user interfaces, multimodal interaction, wearable augmented reality system, situational awareness, visualization functionality, custom-built multimodal interface, urban environment, mobile computing, Augmented reality, Buildings, Filters, Visualization, Temperature, Clouds, Fingers, Computer displays, Cities and towns, Information filtering, augmented reality, wearable computing, multimodal interface, hand-gesture recognition, information visualization, Clothing, Computer Peripherals, Data Display, Equipment Design, Equipment Failure Analysis, Multimedia, Signal Processing, Computer-Assisted, Systems Integration, User-Computer Interface},
	pages = {62--71}
}

@inproceedings{kaiser_mutual_2003,
	address = {New York, NY, USA},
	series = {{ICMI} '03},
	title = {Mutual {Disambiguation} of 3D {Multimodal} {Interaction} in {Augmented} and {Virtual} {Reality}},
	isbn = {9781581136210},
	url = {http://doi.acm.org/10.1145/958432.958438},
	doi = {10.1145/958432.958438},
	abstract = {We describe an approach to 3D multimodal interaction in immersive augmented and virtual reality environments that accounts for the uncertain nature of the information sources. The resulting multimodal system fuses symbolic and statistical information from a set of 3D gesture, spoken language, and referential agents. The referential agents employ visible or invisible volumes that can be attached to 3D trackers in the environment, and which use a time-stamped history of the objects that intersect them to derive statistics for ranking potential referents. We discuss the means by which the system supports mutual disambiguation of these modalities and information sources, and show through a user study how mutual disambiguation accounts for over 45\% of the successful 3D multimodal interpretations. An accompanying video demonstrates the system in action.},
	urldate = {2019-09-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Multimodal} {Interfaces}},
	publisher = {ACM},
	author = {Kaiser, Ed and Olwal, Alex and McGee, David and Benko, Hrvoje and Corradini, Andrea and Li, Xiaoguang and Cohen, Phil and Feiner, Steven},
	year = {2003},
	note = {event-place: Vancouver, British Columbia, Canada},
	keywords = {augmented/virtual reality, evaluation, multimodal interaction},
	pages = {12--19}
}

@inproceedings{petit_navigation_2014,
	title = {Navigation assistance for a {BCI}-controlled humanoid robot},
	doi = {10.1109/CYBER.2014.6917469},
	abstract = {We present an assisted navigation scheme designed to control a humanoid robot via a brain computer interface in order to let it interact with the environment and with humans. The interface is based on the well-known steady-state visually evoked potentials (SSVEP) and the stimuli are integrated into the live feedback from the robot embedded camera displayed on a Head Mounted Display (HMD). One user controlled the HRP-2 humanoid robot in an experiment designed to measure the performance of the new navigation scheme based on visual SLAM feedback. The new navigation scheme performance is tested in an experience where the user is asked to navigate to a certain location in order to perform a task. It results that without the navigation assistance it is much more difficult to reach the appropriate pose for performing the task. The detailed results of the experiments are reported in this paper, and we discuss the possible improvements of our novel scheme.},
	booktitle = {The 4th {Annual} {IEEE} {International} {Conference} on {Cyber} {Technology} in {Automation}, {Control} and {Intelligent}},
	author = {Petit, D. and Gergondet, P. and Cherubini, A. and Meilland, M. and Comport, A. I. and Kheddar, A.},
	month = jun,
	year = {2014},
	keywords = {brain-computer interfaces, cameras, control engineering computing, feedback, helmet mounted displays, humanoid robots, human-robot interaction, mobile robots, path planning, robot vision, SLAM (robots), visual evoked potentials, BCI-controlled humanoid robot, assisted navigation scheme, brain computer interface, environment interaction, human interaction, steady-state visually evoked potentials, SSVEP, stimuli, live feedback, robot embedded camera, head mounted display, HMD, HRP-2 humanoid robot, navigation scheme performance, visual SLAM feedback, navigation assistance, Navigation, Collision avoidance, Humanoid robots, Cameras, Robot vision systems, Manuals},
	pages = {246--251}
}

@incollection{mortal_portable_2018,
	address = {Cham},
	title = {Portable {Device} for {Touch}, {Taste} and {Smell} {Sensations} in {Augmented} {Reality} {Experiences}},
	isbn = {9783319702711 9783319702728},
	url = {http://link.springer.com/10.1007/978-3-319-70272-8_26},
	language = {en},
	urldate = {2019-09-20},
	booktitle = {{INCREaSE}},
	publisher = {Springer International Publishing},
	author = {Sardo, J. D. P. and Semião, J. and Monteiro, J. M. and Pereira, João A. R. and de Freitas, Marco A. G. and Esteves, E. and Rodrigues, João M. F.},
	editor = {Mortal, António and Aníbal, Jaime and Monteiro, Jânio and Sequeira, Cláudia and Semião, Jorge and Moreira da Silva, Manuela and Oliveira, Miguel},
	year = {2018},
	doi = {10.1007/978-3-319-70272-8_26},
	pages = {305--320}
}

@inproceedings{olwal_senseshapes:_2003,
	address = {Tokyo, Japan},
	title = {{SenseShapes}: using statistical geometry for object selection in a multimodal augmented reality},
	isbn = {9780769520063},
	shorttitle = {{SenseShapes}},
	url = {http://ieeexplore.ieee.org/document/1240730/},
	doi = {10.1109/ISMAR.2003.1240730},
	urldate = {2019-09-20},
	booktitle = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
	publisher = {IEEE Comput. Soc},
	author = {Olwal, A. and Benko, H. and Feiner, S.},
	year = {2003},
	pages = {300--301}
}

@inproceedings{tuceryan_single_2000,
	title = {Single point active alignment method ({SPAAM}) for optical see-through {HMD} calibration for {AR}},
	doi = {10.1109/ISAR.2000.880938},
	abstract = {Augmented reality (AR) is a technology in which a user's view of the real world is enhanced or augmented with additional information generated from a computer model. In order to have a working AR system, the see-through display system must be calibrated so that the graphics is properly rendered. The optical see-through systems present an additional challenge because we do not have access to the image data directly as in video see-through systems. This paper reports on a method we developed for optical see-through head-mounted displays. The method integrates the measurements for the camera and the magnetic tracker which is attached to the camera in order to do the calibration. The calibration is based on the alignment of image points with a single 3D point in the world coordinate system from various viewpoints. The user interaction to do the calibration is extremely easy compared to prior methods, and there is no requirement for keeping the head static while doing the calibration.},
	booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality} ({ISAR} 2000)},
	author = {Tuceryan, M. and Navab, N.},
	month = oct,
	year = {2000},
	keywords = {calibration, augmented reality, computer displays, user interfaces, cameras, rendering (computer graphics), image processing, single point active alignment method, calibration, augmented reality, computer model, camera, rendering, optical see-through head-mounted displays, magnetic tracker, user interaction, Calibration, Cameras, Computer graphics, Augmented reality, Displays, Optical computing, Biomedical optical imaging, Application software, Layout, Information science},
	pages = {149--158}
}

@inproceedings{coomans_towards_1997,
	title = {Towards a taxonomy of virtual reality user interfaces},
	doi = {10.1109/IV.1997.626531},
	abstract = {Virtual reality based user interfaces (VRUIs) are expected to bring about a revolution in computing. VR can potentially communicate large amounts of data in an easily understandable format. VR looks very promising, but it is still a very new interface technology for which very little application oriented knowledge is available. As a basis for such a future VRUI design theory, a taxonomy of VRUIs is required. A general model of human computer communication is formulated. This model constitutes a frame for the integration of partial taxonomies of human computer interaction that are found in the literature. The whole model constitutes a general user interface taxonomy. The field of VRUIs is described and delimited with respect to this taxonomy.},
	booktitle = {Proceedings. 1997 {IEEE} {Conference} on {Information} {Visualization} ({Cat}. {No}.97TB100165)},
	author = {Coomans, M. K. D. and Timmermans, H. J. P.},
	month = aug,
	year = {1997},
	keywords = {graphical user interfaces, virtual reality, interactive systems, human factors, virtual reality user interfaces, VRUIs, VR, understandable format, interface technology, application oriented knowledge, future VRUI design theory, human computer communication, partial taxonomies, human computer interaction, general user interface taxonomy, Taxonomy, Virtual reality, User interfaces, Computer interfaces, Visualization, Computer architecture, Buildings, Technology planning, Postal services, Humans},
	pages = {279--284}
}

@inproceedings{lin_transfork:_2018,
	address = {New York, NY, USA},
	series = {{VRST} '18},
	title = {{TransFork}: {Using} {Olfactory} {Device} for {Augmented} {Tasting} {Experience} with {Video} {See}-through {Head}-mounted {Display}},
	isbn = {9781450360869},
	shorttitle = {{TransFork}},
	url = {http://doi.acm.org/10.1145/3281505.3281560},
	doi = {10.1145/3281505.3281560},
	abstract = {When people eat, the taste is very complex and be influenced easily by other senses. Such as visual, olfactory, and haptic, even past experiences, can affect the human perception, which in turn creates more taste possibilities. We present TransFork, an eating tool with olfactory feedback, which augments the tasting experience with video see-through head-mounted display. Additionally, we design a recipe via preliminary experiments to find out the taste conversion formula, which could enhance the flavor of foods and change the user perception to recognize the food. In this demonstration, we prepare a mini feast with bite-sized fruit, the participants use the TransFork to eat food A and smell the scent of food B stored at the aromatic box via airflow guiding. Before they deliver the food to their mouth, the head-mounted display augmented the color of food B on food A by the QR code on the aromatic box. With this augmented reality techniques and the recipe, the tasting experience could be augmented or enhanced, which is a potential approach and could be a playful used for eating.},
	urldate = {2019-09-20},
	booktitle = {Proceedings of the 24th {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {Lin, Ying-Li and Chou, Tsai-Yi and Lieo, Yu-Cheng and Huang, Yu-Cheng and Han, Ping-Hsuan},
	year = {2018},
	note = {event-place: Tokyo, Japan},
	keywords = {augmented reality, augmented tasting experience, olfactory, video see-through head-mounted display},
	pages = {58:1--58:2}
}

@inproceedings{sales_dias_using_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Using {Hand} {Gesture} and {Speech} in a {Multimodal} {Augmented} {Reality} {Environment}},
	isbn = {9783540928652},
	abstract = {In this work we describe a 3D authoring tool which takes advantage of multimodal interfaces such as gestures and speech. This tool allows real-time Augmented Reality aimed to aid the tasks of interior architects and designers. This approach intends to be an alternative to traditional techniques. The main benefit of using a multimodal based augmented reality system is the provision of a more transparent, flexible, efficient and expressive means of human-computer interaction.},
	language = {en},
	booktitle = {Gesture-{Based} {Human}-{Computer} {Interaction} and {Simulation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sales Dias, Miguel and Bastos, Rafael and Fernandes, João and Tavares, João and Santos, Pedro},
	editor = {Sales Dias, Miguel and Gibet, Sylvie and Wanderley, Marcelo M. and Bastos, Rafael},
	year = {2009},
	keywords = {Gesture Tracking ,  Augmented Reality ,  3D Authoring Tool ,  Speech ,  Multimodal interfaces },
	pages = {175--180}
}

@inproceedings{ranasinghe_vocktail:_2017,
	address = {New York, NY, USA},
	series = {{MM} '17},
	title = {Vocktail: {A} {Virtual} {Cocktail} for {Pairing} {Digital} {Taste}, {Smell}, and {Color} {Sensations}},
	isbn = {9781450349062},
	shorttitle = {Vocktail},
	url = {http://doi.acm.org/10.1145/3123266.3123440},
	doi = {10.1145/3123266.3123440},
	abstract = {Similar to the concept of a cocktail or mocktail, we present Vocktail (a.k.a. Virtual Cocktail) - an interactive drinking utensil that digitally simulates multisensory flavor experiences. The Vocktail system utilizes three common sensory modalities, taste, smell, and visual (color), to create virtual flavors and augment the existing flavors of a beverage. The system is coupled with a mobile application that enables users to create customized virtual flavor sensations by configuring each of the stimuli via Bluetooth. The system consists of a cocktail glass that is seamlessly fused into a 3D printed structure, which holds the electronic control module, three scent cartridges, and three micro air-pumps. When a user drinks from the system, the visual (RGB light projected on the beverage), taste (electrical stimulation at the tip of the tongue), and smell stimuli (emitted by micro air-pumps) are combined to create a virtual flavor sensation, thus altering the flavor of the beverage. In summary, this paper discusses 1) technical details of the Vocktail system and 2) user experiments that investigate the influences of these multimodal stimuli on the perception of virtual flavors in terms of five primary tastes (i.e. salty, sweet, bitter, sour, and umami). Our results suggest that the combination of these stimuli delivers richer flavor experiences, as compared to separately simulating individual modalities, and indicates that the types of pairings that can be formed between smell and electric taste stimuli.},
	urldate = {2019-09-20},
	booktitle = {Proceedings of the 25th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Ranasinghe, Nimesha and Nguyen, Thi Ngoc Tram and Liangkun, Yan and Lin, Lien-Ya and Tolley, David and Do, Ellen Yi-Luen},
	year = {2017},
	note = {event-place: Mountain View, California, USA},
	keywords = {digital taste, electric taste, virtual cocktail, virtual flavor, virtual taste, vocktail},
	pages = {1139--1147}
}

@article{wang_comprehensive_2016,
	title = {A comprehensive survey of augmented reality assembly research},
	volume = {4},
	issn = {2095-3127, 2195-3597},
	url = {http://link.springer.com/10.1007/s40436-015-0131-4},
	doi = {10.1007/s40436-015-0131-4},
	language = {en},
	number = {1},
	urldate = {2019-09-20},
	journal = {Advances in Manufacturing},
	author = {Wang, X. and Ong, S. K. and Nee, A. Y. C.},
	month = mar,
	year = {2016},
	pages = {1--22}
}

@article{muhammad_nizam_review_2018,
	title = {A {Review} of {Multimodal} {Interaction} {Technique} in {Augmented} {Reality} {Environment}},
	volume = {8},
	issn = {2460-6952, 2088-5334},
	url = {http://ijaseit.insightsociety.org/index.php?option=com_content&view=article&id=9&Itemid=1&article_id=6824},
	doi = {10.18517/ijaseit.8.4-2.6824},
	number = {4-2},
	urldate = {2019-09-20},
	journal = {International Journal on Advanced Science, Engineering and Information Technology},
	author = {Muhammad Nizam, Siti Soleha and Zainal Abidin, Rimaniza and Che Hashim, Nurhazarifah and Lam, Meng Chun and Arshad, Haslina and Abd Majid, Nazatul Aini},
	month = sep,
	year = {2018},
	pages = {1460}
}

@article{thomas_survey_2012,
	title = {A survey of visual, mixed, and augmented reality gaming},
	volume = {10},
	issn = {15443574},
	url = {http://dl.acm.org/citation.cfm?doid=2381876.2381879},
	doi = {10.1145/2381876.2381879},
	language = {en},
	number = {3},
	urldate = {2019-09-20},
	journal = {Computers in Entertainment},
	author = {Thomas, Bruce H.},
	month = nov,
	year = {2012},
	pages = {1--33}
}

@article{ong_augmented_2008,
	title = {Augmented reality applications in manufacturing: a survey},
	volume = {46},
	issn = {0020-7543, 1366-588X},
	shorttitle = {Augmented reality applications in manufacturing},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207540601064773},
	doi = {10.1080/00207540601064773},
	language = {en},
	number = {10},
	urldate = {2019-09-20},
	journal = {International Journal of Production Research},
	author = {Ong, S. K. and Yuan, M. L. and Nee, A. Y. C.},
	month = may,
	year = {2008},
	pages = {2707--2742}
}

@article{huang_mobile_2013,
	title = {Mobile augmented reality survey: a bottom-up approach},
	shorttitle = {Mobile augmented reality survey},
	url = {http://arxiv.org/abs/1309.4413},
	abstract = {Augmented Reality (AR) is becoming mobile. Mobile devices have many constraints but also rich new features that traditional desktop computers do not have. There are several survey papers on AR, but none is dedicated to Mobile Augmented Reality (MAR). Our work serves the purpose of closing this gap. The contents are organized with a bottom-up approach. We first present the state-of-the-art in system components including hardware platforms, software frameworks and display devices, follows with enabling technologies such as tracking and data management. We then survey the latest technologies and methods to improve run-time performance and energy efficiency for practical implementation. On top of these, we further introduce the application fields and several typical MAR applications. Finally we conclude the survey with several challenge problems, which are under exploration and require great research efforts in the future.},
	urldate = {2019-09-20},
	journal = {arXiv:1309.4413 [cs]},
	author = {Huang, Zhanpeng and Hui, Pan and Peylo, Christoph and Chatzopoulos, Dimitris},
	month = sep,
	year = {2013},
	note = {arXiv: 1309.4413},
	keywords = {Computer Science - Graphics, Computer Science - Human-Computer Interaction, H.5.1}
}

