% Encoding: UTF-8

@Article{Oviatt1999,
  author     = {Oviatt, Sharon},
  title      = {Ten Myths of Multimodal Interaction},
  journal    = {Commun. ACM},
  year       = {1999},
  volume     = {42},
  number     = {11},
  pages      = {74--81},
  month      = nov,
  issn       = {0001-0782},
  acmid      = {319398},
  address    = {New York, NY, USA},
  doi        = {10.1145/319382.319398},
  issue_date = {Nov. 1999},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/319382.319398},
}

@Article{Jaimes2007,
  author   = {Alejandro Jaimes and Nicu Sebe},
  title    = {Multimodal humancomputer interaction: A survey},
  journal  = {Computer Vision and Image Understanding},
  year     = {2007},
  volume   = {108},
  number   = {1},
  pages    = {116 - 134},
  issn     = {1077-3142},
  note     = {Special Issue on Vision for Human-Computer Interaction},
  abstract = {In this paper, we review the major approaches to multimodal humancomputer interaction, giving an overview of the field from a computer vision perspective. In particular, we focus on body, gesture, gaze, and affective interaction (facial expression recognition and emotion in audio). We discuss user and task modeling, and multimodal fusion, highlighting challenges, open issues, and emerging applications for multimodal humancomputer interaction (MMHCI) research.},
  doi      = {https://doi.org/10.1016/j.cviu.2006.10.019},
  keywords = {Multimodal human-computer interaction, Gesture recognition, Affective computing, Human-centered computing},
  url      = {http://www.sciencedirect.com/science/article/pii/S1077314206002335},
}

@Article{White2007,
  author   = {White, Martin and Petridis, Panagiotis and Liarokapis, Fotis and Plecinckx, Daniel},
  title    = {Multimodal {Mixed} {Reality} {Interfaces} for {Visualizing} {Digital} {Heritage}},
  journal  = {International Journal of Architectural Computing},
  year     = {2007},
  volume   = {5},
  number   = {2},
  pages    = {321--337},
  month    = jun,
  issn     = {1478-0771, 2048-3988},
  doi      = {10.1260/1478-0771.5.2.322},
  language = {en},
  url      = {http://journals.sagepub.com/doi/10.1260/1478-0771.5.2.322},
  urldate  = {2019-09-14},
}

@Article{Ai2018,
  author     = {Ai, Yuan and Peng, Mugen and Zhang, Kecheng},
  title      = {Edge computing technologies for {Internet} of {Things}: a primer},
  journal    = {Digital Communications and Networks},
  year       = {2018},
  volume     = {4},
  number     = {2},
  pages      = {77--86},
  month      = apr,
  issn       = {23528648},
  doi        = {10.1016/j.dcan.2017.07.001},
  language   = {en},
  shorttitle = {Edge computing technologies for {Internet} of {Things}},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S2352864817301335},
  urldate    = {2019-09-14},
}

@Article{Adatia1971,
  author  = {ADATIA, A. K. and GEHRING, E. N.},
  title   = {Proprioceptive innervation of the tongue},
  journal = {J. Anat},
  year    = {1971},
  volume  = {110},
  number  = {2},
  pages   = {215--220},
  month   = nov,
}

@InProceedings{Kalbani2017,
  author     = {Al-Kalbani, Maadh and Frutos-Pascual, Maite and Williams, Ian},
  title      = {Freehand grasping in mixed reality: analysing variation during transition phase of interaction},
  booktitle  = {Proceedings of the 19th {ACM} {International} {Conference} on {Multimodal} {Interaction} - {ICMI} 2017},
  year       = {2017},
  pages      = {110--114},
  address    = {Glasgow, UK},
  publisher  = {ACM Press},
  doi        = {10.1145/3136755.3136776},
  isbn       = {9781450355438},
  language   = {en},
  shorttitle = {Freehand grasping in mixed reality},
  url        = {http://dl.acm.org/citation.cfm?doid=3136755.3136776},
  urldate    = {2019-09-14},
}

@InProceedings{Zhiyun2004,
  author    = {{Zhiyun Li} and Duraiswami, R. and Davis, L.S.},
  title     = {Recording and {Reproducing} {High} {Order} {Surround} {Auditory} {Scenes} for {Mixed} and {Augmented} {Reality}},
  booktitle = {Third {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
  year      = {2004},
  pages     = {240--249},
  address   = {Arlington, VA, USA},
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2004.51},
  isbn      = {9780769521916},
  url       = {http://ieeexplore.ieee.org/document/1383061/},
  urldate   = {2019-09-14},
}

@Article{Xavier2014,
  author  = {Xavier, Anguera and Luque, Jordi and Ciro, Gracia},
  title   = {Audio-to-text {Alignment} for speech recognition with very limited resources},
  journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
  year    = {2014},
}

@Article{Sagaya2014,
  author  = {{Sagaya Aurelia} and { M. Durai Raj} and {Omer Saleh}},
  title   = {A {Survey} on {Mobile} {Augmented} {Reality} {Based} {Interactive} {Storytelling}},
  journal = {Advances in Information Science and Applications},
  year    = {2014},
  volume  = {2},
}

@Article{Azuma1997,
  author   = {Azuma, Ronald T.},
  title    = {A {Survey} of {Augmented} {Reality}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {1997},
  volume   = {6},
  number   = {4},
  pages    = {355--385},
  month    = aug,
  issn     = {1054-7460, 1531-3263},
  doi      = {10.1162/pres.1997.6.4.355},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.355},
  urldate  = {2019-09-14},
}

@Article{Bablani2019,
  author     = {Bablani, Annushree and Edla, Damodar Reddy and Tripathi, Diwakar and Cheruku, Ramalingaswamy},
  title      = {Survey on {Brain}-{Computer} {Interface}: {An} {Emerging} {Computational} {Intelligence} {Paradigm}},
  journal    = {ACM Computing Surveys},
  year       = {2019},
  volume     = {52},
  number     = {1},
  pages      = {1--32},
  month      = feb,
  issn       = {03600300},
  doi        = {10.1145/3297713},
  language   = {en},
  shorttitle = {Survey on {Brain}-{Computer} {Interface}},
  url        = {http://dl.acm.org/citation.cfm?doid=3309872.3297713},
  urldate    = {2019-09-14},
}

@InProceedings{Bace2016,
  author     = {BÃ¢ce, Mihai and LeppÃ€nen, Teemu and de Gomez, David Gil and Gomez, Argenis Ramirez},
  title      = {{ubiGaze}: ubiquitous augmented reality messaging using gaze gestures},
  booktitle  = {{SIGGRAPH} {ASIA} 2016 {Mobile} {Graphics} and {Interactive} {Applications} on - {SA} '16},
  year       = {2016},
  pages      = {1--5},
  address    = {Macau},
  publisher  = {ACM Press},
  doi        = {10.1145/2999508.2999530},
  isbn       = {9781450345514},
  language   = {en},
  shorttitle = {{ubiGaze}},
  url        = {http://dl.acm.org/citation.cfm?doid=2999508.2999530},
  urldate    = {2019-09-14},
}

@InProceedings{Bai2013,
  author    = {Bai, Huidong and Gao, Lei and El-Sana, Jihad and Billinghurst, Mark},
  title     = {Markerless 3D gesture-based interaction for handheld augmented reality interfaces},
  booktitle = {{SIGGRAPH} {Asia} 2013 {Symposium} on {Mobile} {Graphics} and {Interactive} {Applications} on - {SA} '13},
  year      = {2013},
  pages     = {1--1},
  address   = {Hong Kong, Hong Kong},
  publisher = {ACM Press},
  doi       = {10.1145/2543651.2543678},
  isbn      = {9781450326339},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2543651.2543678},
  urldate   = {2019-09-14},
}

@Article{Barfield1996,
  author   = {Barfield, Woodrow and Danas, Eric},
  title    = {Comments on the {Use} of {Olfactory} {Displays} for {Virtual} {Environments}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {1996},
  volume   = {5},
  number   = {1},
  pages    = {109--121},
  month    = jan,
  issn     = {1054-7460, 1531-3263},
  doi      = {10.1162/pres.1996.5.1.109},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/10.1162/pres.1996.5.1.109},
  urldate  = {2019-09-14},
}

@Article{Bau2012,
  author     = {Bau, Olivier and Poupyrev, Ivan},
  title      = {{REVEL}: tactile feedback technology for augmented reality},
  journal    = {ACM Transactions on Graphics},
  year       = {2012},
  volume     = {31},
  number     = {4},
  pages      = {1--11},
  month      = jul,
  issn       = {07300301},
  doi        = {10.1145/2185520.2185585},
  language   = {en},
  shorttitle = {{REVEL}},
  url        = {http://dl.acm.org/citation.cfm?doid=2185520.2185585},
  urldate    = {2019-09-14},
}

@InProceedings{Baudisch2009,
  author    = {Baudisch, Patrick and Chu, Gerry},
  title     = {Back-of-device interaction allows creating very small touch devices},
  booktitle = {Proceedings of the 27th international conference on {Human} factors in computing systems - {CHI} 09},
  year      = {2009},
  pages     = {1923},
  address   = {Boston, MA, USA},
  publisher = {ACM Press},
  doi       = {10.1145/1518701.1518995},
  isbn      = {9781605582467},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=1518701.1518995},
  urldate   = {2019-09-14},
}

@InProceedings{Beaudouin-Lafon2000,
  author     = {Beaudouin-Lafon, Michel},
  title      = {Instrumental interaction: an interaction model for designing post-{WIMP} user interfaces},
  booktitle  = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems - {CHI} '00},
  year       = {2000},
  pages      = {446--453},
  address    = {The Hague, The Netherlands},
  publisher  = {ACM Press},
  doi        = {10.1145/332040.332473},
  isbn       = {9781581132168},
  language   = {en},
  shorttitle = {Instrumental interaction},
  url        = {http://portal.acm.org/citation.cfm?doid=332040.332473},
  urldate    = {2019-09-14},
}

@Article{Bermejo2017,
  author   = {Bermejo, Carlos and Hui, Pan},
  title    = {A survey on haptic technologies for mobile augmented reality},
  journal  = {arXiv:1709.00698 [cs]},
  year     = {2017},
  month    = sep,
  note     = {arXiv: 1709.00698},
  abstract = {Augmented Reality (AR) and Mobile Augmented Reality (MAR) applications have gained much research and industry attention these days. The mobile nature of MAR applications limits users' interaction capabilities such as inputs, and haptic feedbacks. This survey reviews current research issues in the area of human computer interaction for MAR and haptic devices. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile: touch, active surfaces, and mid-air, kinesthetic: manipulandum, grasp, and exoskeleton. Due to the mobile capabilities of MAR applications, we mainly focus our study on wearable haptic devices for each category and their AR possibilities. To conclude, we discuss the future paths that haptic feedbacks should follow for MAR applications and their challenges.},
  keywords = {Computer Science - Human-Computer Interaction},
  url      = {http://arxiv.org/abs/1709.00698},
  urldate  = {2019-09-14},
}

@InProceedings{Billinghurst2013,
  author     = {Billinghurst, Mark},
  title      = {Hands and speech in space: multimodal interaction with augmented reality interfaces},
  booktitle  = {Proceedings of the 15th {ACM} on {International} conference on multimodal interaction - {ICMI} '13},
  year       = {2013},
  pages      = {379--380},
  address    = {Sydney, Australia},
  publisher  = {ACM Press},
  doi        = {10.1145/2522848.2532202},
  isbn       = {9781450321297},
  language   = {en},
  shorttitle = {Hands and speech in space},
  url        = {http://dl.acm.org/citation.cfm?doid=2522848.2532202},
  urldate    = {2019-09-14},
}

@Article{Billinghurst2015,
  author   = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
  title    = {A {Survey} of {Augmented} {Reality}},
  journal  = {Foundations and TrendsÂ® in HumanâComputer Interaction},
  year     = {2015},
  volume   = {8},
  number   = {2-3},
  pages    = {73--272},
  issn     = {1551-3955, 1551-3963},
  doi      = {10.1561/1100000049},
  language = {en},
  url      = {http://www.nowpublishers.com/article/Details/HCI-049},
  urldate  = {2019-09-14},
}

@Article{Blum2012,
  author  = {{T. Blum} and {V. Kleeberger} and {C. Bichlmeier} and {N. Navab}},
  title   = {An augmented reality magic mirror system for anatomy education.},
  journal = {2012 IEEE Virtual Reality Workshops (VRW)},
  year    = {2012},
  pages   = {115--116},
  doi     = {http://dx.doi.org/10.1109/VR.2012.6180909},
}

@InProceedings{Tobias2012,
  author    = {{Tobias Blum} and {Ralf Stauder} and {Ekkehard Euler} and {Nassir Navab}},
  title     = {Superman-like {X}-ray vision: {Towards} brain-computer interfaces for medical augmented reality},
  year      = {2012},
  address   = {Atlanta, GA, USA},
  month     = nov,
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2012.6402569},
  isbn      = {978-1-4673-4661-0},
}

@InProceedings{Boldu2017,
  author     = {Boldu, Roger and Zhang, Haimo and CortÃ©s, Juan Pablo Forero and Muthukumarana, Sachith and Nanayakkara, Suranga},
  title      = {{InSight}: a systematic approach to create dynamic human-controller-interactions},
  booktitle  = {Proceedings of the 8th {Augmented} {Human} {International} {Conference} on - {AH} '17},
  year       = {2017},
  pages      = {1--5},
  address    = {Silicon Valley, California},
  publisher  = {ACM Press},
  doi        = {10.1145/3041164.3041195},
  isbn       = {9781450348355},
  language   = {en},
  shorttitle = {{InSight}},
  url        = {http://dl.acm.org/citation.cfm?doid=3041164.3041195},
  urldate    = {2019-09-14},
}

@Article{Bolopion2013,
  author  = {Bolopion, A. and Regnier, S.},
  title   = {A {Review} of {Haptic} {Feedback} {Teleoperation} {Systems} for {Micromanipulation} and {Microassembly}},
  journal = {IEEE Transactions on Automation Science and Engineering},
  year    = {2013},
  volume  = {10},
  number  = {3},
  pages   = {496--502},
  month   = jul,
  issn    = {1545-5955, 1558-3783},
  doi     = {10.1109/TASE.2013.2245122},
  url     = {http://ieeexplore.ieee.org/document/6476754/},
  urldate = {2019-09-14},
}

@Article{Borst2005,
  author   = {Borst, Christoph W. and Volz, Richard A.},
  title    = {Evaluation of a {Haptic} {Mixed} {Reality} {System} for {Interactions} with a {Virtual} {Control} {Panel}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {2005},
  volume   = {14},
  number   = {6},
  pages    = {677--696},
  month    = dec,
  issn     = {1054-7460, 1531-3263},
  doi      = {10.1162/105474605775196562},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/10.1162/105474605775196562},
  urldate  = {2019-09-14},
}

@InProceedings{Jorge2015,
  author  = {{Jorge BrandÃ£o} and {Pedro Cunha} and {JosÃ© Vasconcelos} and {VÃ­tor Carvalho} and {Filomena Soares}},
  title   = {An {Augmented} {Reality} {GameBook} for {Children} with {Autism} {Spectrum} {Disorders}},
  year    = {2015},
  address = {New York, NY, USA},
  month   = jun,
}

@Article{Cavazza_2004,
  author   = {Cavazza, M. and Charles, F. and Mead, S.J. and Martin, O. and Marichal, X. and Nandi, A.},
  title    = {Multimodal acting in mixed reality interactive storytelling},
  journal  = {IEEE Multimedia},
  year     = {2004},
  volume   = {11},
  number   = {3},
  pages    = {30--39},
  month    = jul,
  issn     = {1070-986X},
  doi      = {10.1109/MMUL.2004.11},
  language = {en},
  url      = {http://ieeexplore.ieee.org/document/1316795/},
  urldate  = {2019-09-14},
}

@Article{Chatzopoulos2017,
  author     = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Hui, Pan},
  title      = {Mobile {Augmented} {Reality} {Survey}: {From} {Where} {We} {Are} to {Where} {We} {Go}},
  journal    = {IEEE Access},
  year       = {2017},
  volume     = {5},
  pages      = {6917--6950},
  issn       = {2169-3536},
  doi        = {10.1109/ACCESS.2017.2698164},
  shorttitle = {Mobile {Augmented} {Reality} {Survey}},
  url        = {http://ieeexplore.ieee.org/document/7912316/},
  urldate    = {2019-09-14},
}

@InProceedings{Cheok2015,
  author    = {Cheok, Adrian David and Karunanayaka, Kasun and Samshir, Nur Amira and Johari, Nurafiqah},
  title     = {Initial basic concept of thermal sweet taste interface},
  booktitle = {Proceedings of the 12th {International} {Conference} on {Advances} in {Computer} {Entertainment} {Technology} - {ACE} '15},
  year      = {2015},
  pages     = {1--3},
  address   = {Iskandar, Malaysia},
  publisher = {ACM Press},
  doi       = {10.1145/2832932.2856225},
  isbn      = {9781450338523},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2832932.2856225},
  urldate   = {2019-09-14},
}

@InProceedings{Chung2009,
  author     = {Chung, Keywon and Chiu, Carnaven and Xiao, Xiao and Chi, Pei-Yu (Peggy)},
  title      = {Stress outsourced: a haptic social network via crowdsourcing},
  booktitle  = {Proceedings of the 27th international conference extended abstracts on {Human} factors in computing systems - {CHI} {EA} '09},
  year       = {2009},
  pages      = {2439},
  address    = {Boston, MA, USA},
  publisher  = {ACM Press},
  doi        = {10.1145/1520340.1520346},
  isbn       = {9781605582474},
  language   = {en},
  shorttitle = {Stress outsourced},
  url        = {http://portal.acm.org/citation.cfm?doid=1520340.1520346},
  urldate    = {2019-09-14},
}

@InCollection{Costanza2009,
  author     = {Costanza, Enrico and Kunz, Andreas and Fjeld, Morten},
  title      = {Mixed {Reality}: {A} {Survey}},
  booktitle  = {Human {Machine} {Interaction}},
  publisher  = {Springer Berlin Heidelberg},
  year       = {2009},
  editor     = {Lalanne, Denis and Kohlas, JÃŒrg},
  volume     = {5440},
  pages      = {47--68},
  address    = {Berlin, Heidelberg},
  isbn       = {9783642004360 9783642004377},
  doi        = {10.1007/978-3-642-00437-7_3},
  shorttitle = {Mixed {Reality}},
  url        = {http://link.springer.com/10.1007/978-3-642-00437-7_3},
  urldate    = {2019-09-14},
}

@InProceedings{Coutrix2006,
  author     = {Coutrix, CÃ©line and Nigay, Laurence},
  title      = {Mixed reality: a model of mixed interaction},
  booktitle  = {Proceedings of the working conference on {Advanced} visual interfaces - {AVI} '06},
  year       = {2006},
  pages      = {43},
  address    = {Venezia, Italy},
  publisher  = {ACM Press},
  doi        = {10.1145/1133265.1133274},
  isbn       = {9781595933539},
  language   = {en},
  shorttitle = {Mixed reality},
  url        = {http://portal.acm.org/citation.cfm?doid=1133265.1133274},
  urldate    = {2019-09-14},
}

@Article{Culbertson2018,
  author     = {Culbertson, Heather and Schorr, Samuel B. and Okamura, Allison M.},
  title      = {Haptics: {The} {Present} and {Future} of {Artificial} {Touch} {Sensation}},
  journal    = {Annual Review of Control, Robotics, and Autonomous Systems},
  year       = {2018},
  volume     = {1},
  number     = {1},
  pages      = {385--409},
  month      = may,
  issn       = {2573-5144},
  abstract   = {This article reviews the technology behind creating artificial touch sensations and the relevant aspects of human touch. We focus on the design and control of haptic devices and discuss the best practices for generating distinct and effective touch sensations. Artificial haptic sensations can present information to users, help them complete a task, augment or replace the other senses, and add immersiveness and realism to virtual interactions. We examine these applications in the context of different haptic feedback modalities and the forms that haptic devices can take. We discuss the prior work, limitations, and design considerations of each feedback modality and individual haptic technology. We also address the need to consider the neuroscience and perception behind the human sense of touch in the design and control of haptic devices.},
  doi        = {10.1146/annurev-control-060117-105043},
  language   = {en},
  shorttitle = {Haptics},
  url        = {https://www.annualreviews.org/doi/10.1146/annurev-control-060117-105043},
  urldate    = {2019-09-14},
}

@InProceedings{Dinh1999,
  author    = {Dinh, H.Q. and Walker, N. and Hodges, L.F. and {Chang Song} and Kobayashi, A.},
  title     = {Evaluating the importance of multi-sensory input on memory and the sense of presence in virtual environments},
  booktitle = {Proceedings {IEEE} {Virtual} {Reality} ({Cat}. {No}. 99CB36316)},
  year      = {1999},
  pages     = {222--228},
  address   = {Houston, TX, USA},
  publisher = {IEEE Comput. Soc},
  doi       = {10.1109/VR.1999.756955},
  isbn      = {9780769500935},
  url       = {http://ieeexplore.ieee.org/document/756955/},
  urldate   = {2019-09-14},
}

@Book{Dix2004,
  title     = {Human-computer interaction},
  publisher = {Pearson/Prentice-Hall},
  year      = {2004},
  editor    = {Dix, Alan},
  address   = {Harlow, England ; New York},
  edition   = {3rd ed},
  isbn      = {9780130461094},
  keywords  = {Human-computer interaction},
}

@InCollection{Dumas2009,
  author     = {Dumas, Bruno and Lalanne, Denis and Oviatt, Sharon},
  title      = {Multimodal {Interfaces}: {A} {Survey} of {Principles}, {Models} and {Frameworks}},
  booktitle  = {Human {Machine} {Interaction}},
  publisher  = {Springer Berlin Heidelberg},
  year       = {2009},
  editor     = {Lalanne, Denis and Kohlas, JÃŒrg},
  volume     = {5440},
  pages      = {3--26},
  address    = {Berlin, Heidelberg},
  isbn       = {9783642004360 9783642004377},
  doi        = {10.1007/978-3-642-00437-7_1},
  shorttitle = {Multimodal {Interfaces}},
  url        = {http://link.springer.com/10.1007/978-3-642-00437-7_1},
  urldate    = {2019-09-14},
}

@InProceedings{Elkoubaiti2018,
  author    = {Elkoubaiti, Houda and Mrabet, Radouane},
  title     = {A {Survey} of {Pedagogical} {Affordances} of {Augmented} and {Virtual} {Realities} {Technologies} in {loT} - {Based} {Classroom}},
  booktitle = {2018 {IEEE} 5th {International} {Congress} on {Information} {Science} and {Technology} ({CiSt})},
  year      = {2018},
  pages     = {334--341},
  address   = {Marrakech},
  month     = oct,
  publisher = {IEEE},
  doi       = {10.1109/CIST.2018.8596654},
  isbn      = {9781538643853},
  url       = {https://ieeexplore.ieee.org/document/8596654/},
  urldate   = {2019-09-14},
}

@Article{Escobedo2014,
  author  = {Escobedo, Lizbeth and Tentori, Monica and Quintana, Eduardo and Favela, Jesus and Garcia-Rosas, Daniel},
  title   = {Using {Augmented} {Reality} to {Help} {Children} with {Autism} {Stay} {Focused}},
  journal = {IEEE Pervasive Computing},
  year    = {2014},
  volume  = {13},
  number  = {1},
  pages   = {38--46},
  issn    = {1536-1268},
  doi     = {10.1109/MPRV.2014.19},
  url     = {http://ieeexplore.ieee.org/document/6750495/},
  urldate = {2019-09-14},
}

@Article{Bladin2006,
  author   = {Bladin, Peter F.},
  title    = {W. {Grey} {Walter}, pioneer in the electroencephalogram, robotics, cybernetics, artificial intelligence},
  journal  = {Journal of Clinical Neuroscience},
  year     = {2006},
  volume   = {13},
  number   = {2},
  pages    = {170--177},
  month    = feb,
  issn     = {09675868},
  doi      = {10.1016/j.jocn.2005.04.010},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S096758680500398X},
  urldate  = {2019-09-14},
}

@Article{Farwell1988,
  author     = {Farwell, L.A. and Donchin, E.},
  title      = {Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials},
  journal    = {Electroencephalography and Clinical Neurophysiology},
  year       = {1988},
  volume     = {70},
  number     = {6},
  pages      = {510--523},
  month      = dec,
  issn       = {00134694},
  doi        = {10.1016/0013-4694(88)90149-6},
  language   = {en},
  shorttitle = {Talking off the top of your head},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/0013469488901496},
  urldate    = {2019-09-14},
}

@Article{Fazel-Rezai2009,
  author  = {Fazel-Rezai, Reza and Abhari, Kamyar},
  title   = {A region-based {P}300 speller for brain-computer interface},
  journal = {Canadian Journal of Electrical and Computer Engineering},
  year    = {2009},
  volume  = {34},
  number  = {3},
  pages   = {81--85},
  issn    = {0840-8688},
  doi     = {10.1109/CJECE.2009.5443854},
  url     = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5443854},
  urldate = {2019-09-14},
}

@Article{Fazel-Rezai2012,
  author     = {Fazel-Rezai, Reza and Allison, Brendan Z. and Guger, Christoph and Sellers, Eric W. and Kleih, Sonja C. and KÃŒbler, Andrea},
  title      = {P300 brain computer interface: current challenges and emerging trends},
  journal    = {Frontiers in Neuroengineering},
  year       = {2012},
  volume     = {5},
  issn       = {1662-6443},
  doi        = {10.3389/fneng.2012.00014},
  shorttitle = {P300 brain computer interface},
  url        = {http://journal.frontiersin.org/article/10.3389/fneng.2012.00014/abstract},
  urldate    = {2019-09-14},
}

@Article{Fernandez2018,
  author   = {FernÃ¡ndez-CaramÃ©s, Tiago and Fraga-Lamas, Paula and SuÃ¡rez-Albela, Manuel and Vilar-Montesinos, Miguel},
  title    = {A {Fog} {Computing} and {Cloudlet} {Based} {Augmented} {Reality} {System} for the {Industry} 4.0 {Shipyard}},
  journal  = {Sensors},
  year     = {2018},
  volume   = {18},
  number   = {6},
  pages    = {1798},
  month    = jun,
  issn     = {1424-8220},
  doi      = {10.3390/s18061798},
  language = {en},
  url      = {http://www.mdpi.com/1424-8220/18/6/1798},
  urldate  = {2019-09-14},
}

@Article{Furdea2009,
  author   = {Furdea, A. and Halder, S. and Krusienski, D.J. and Bross, D. and Nijboer, F. and Birbaumer, N. and KÃŒbler, A.},
  title    = {An auditory oddball ({P}300) spelling system for brain-computer interfaces},
  journal  = {Psychophysiology},
  year     = {2009},
  volume   = {46},
  number   = {3},
  pages    = {617--625},
  month    = may,
  issn     = {00485772, 14698986},
  doi      = {10.1111/j.1469-8986.2008.00783.x},
  language = {en},
  url      = {http://doi.wiley.com/10.1111/j.1469-8986.2008.00783.x},
  urldate  = {2019-09-14},
}

@Article{Gaillard2017,
  author   = {Gaillard, Maxence},
  title    = {â{Invasive}â and â{Non}-invasiveâ {Technologies} in {Neuroscience} {Communication}},
  journal  = {BioÃ©thiqueOnline},
  year     = {2017},
  volume   = {6},
  pages    = {1044618ar},
  issn     = {1923-2799},
  doi      = {10.7202/1044618ar},
  language = {fr},
  url      = {http://id.erudit.org/iderudit/1044618ar},
  urldate  = {2019-09-14},
}

@InProceedings{Gallego2019,
  author    = {Gallego CascÃ³n, Pablo and Matthies, Denys J.C. and Muthukumarana, Sachith and Nanayakkara, Suranga},
  title     = {{ChewIt}. {An} {Intraoral} {Interface} for {Discreet} {Interactions}},
  booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '19},
  year      = {2019},
  pages     = {1--13},
  address   = {Glasgow, Scotland Uk},
  publisher = {ACM Press},
  doi       = {10.1145/3290605.3300556},
  isbn      = {9781450359702},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3290605.3300556},
  urldate   = {2019-09-14},
}

@Article{Gandy2003,
  author     = {Gandy, M. and Ross, D. and Starner, T.E.},
  title      = {Universal design: {Lessons} for wearable computing},
  journal    = {IEEE Pervasive Computing},
  year       = {2003},
  volume     = {2},
  number     = {3},
  pages      = {19--23},
  month      = jul,
  issn       = {1536-1268},
  doi        = {10.1109/MPRV.2003.1228523},
  language   = {en},
  shorttitle = {Universal design},
  url        = {http://ieeexplore.ieee.org/document/1228523/},
  urldate    = {2019-09-14},
}

@Article{Guenther2012,
  author   = {Guenther, Frank H. and Vladusich, Tony},
  title    = {A neural theory of speech acquisition and production},
  journal  = {Journal of Neurolinguistics},
  year     = {2012},
  volume   = {25},
  number   = {5},
  pages    = {408--422},
  month    = sep,
  issn     = {09116044},
  doi      = {10.1016/j.jneuroling.2009.08.006},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0911604409000682},
  urldate  = {2019-09-14},
}

@Article{Guger2009,
  author   = {Guger, Christoph and Daban, Shahab and Sellers, Eric and Holzner, Clemens and Krausz, Gunther and Carabalona, Roberta and Gramatica, Furio and Edlinger, Guenter},
  title    = {How many people are able to control a {P}300-based brainâcomputer interface ({BCI})?},
  journal  = {Neuroscience Letters},
  year     = {2009},
  volume   = {462},
  number   = {1},
  pages    = {94--98},
  month    = sep,
  issn     = {03043940},
  doi      = {10.1016/j.neulet.2009.06.045},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0304394009008192},
  urldate  = {2019-09-14},
}

@Article{Guo2008,
  author  = {Guo, Fei and Hong, Bo and Gao, Xiaorong and Gao, Shangkai},
  title   = {A brainâcomputer interface using motion-onset visual evoked potential},
  journal = {Journal of Neural Engineering},
  year    = {2008},
  volume  = {5},
  number  = {4},
  pages   = {477--485},
  month   = dec,
  issn    = {1741-2560, 1741-2552},
  doi     = {10.1088/1741-2560/5/4/011},
  url     = {http://stacks.iop.org/1741-2552/5/i=4/a=011?key=crossref.bcc667d28df0d88901563c3d560b024f},
  urldate = {2019-09-14},
}

@InProceedings{Massie1994,
  author = {Massie, T.H. and Salisbury., J.K.},
  title  = {The {PHANTOM} haptic interface: a device for probing virtual objects},
  year   = {1994},
}

@Article{Haas2003,
  author  = {Haas, L F},
  title   = {Hans {Berger} (1873-1941), {Richard} {Caton} (1842-1926), and electroencephalography},
  journal = {Journal of Neurology, Neurosurgery \& Psychiatry},
  year    = {2003},
  volume  = {74},
  number  = {1},
  pages   = {9--9},
  month   = jan,
  issn    = {00223050},
  doi     = {10.1136/jnnp.74.1.9},
  url     = {http://jnnp.bmj.com/cgi/doi/10.1136/jnnp.74.1.9},
  urldate = {2019-09-14},
}

@InProceedings{Han2018,
  author     = {Han, Teng and Anderson, Fraser and Irani, Pourang and Grossman, Tovi},
  title      = {{HydroRing}: {Supporting} {Mixed} {Reality} {Haptics} {Using} {Liquid} {Flow}},
  booktitle  = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} - {UIST} '18},
  year       = {2018},
  pages      = {913--925},
  address    = {Berlin, Germany},
  publisher  = {ACM Press},
  doi        = {10.1145/3242587.3242667},
  isbn       = {9781450359481},
  language   = {en},
  shorttitle = {{HydroRing}},
  url        = {http://dl.acm.org/citation.cfm?doid=3242587.3242667},
  urldate    = {2019-09-14},
}

@Article{Hannun2014,
  author     = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew Y.},
  title      = {Deep {Speech}: {Scaling} up end-to-end speech recognition},
  journal    = {arXiv:1412.5567 [cs]},
  year       = {2014},
  month      = dec,
  note       = {arXiv: 1412.5567},
  abstract   = {We present a state-of-the-art speech recognition system developed using end-to-end deep learning. Our architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast, our system does not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learns a function that is robust to such effects. We do not need a phoneme dictionary, nor even the concept of a "phoneme." Key to our approach is a well-optimized RNN training system that uses multiple GPUs, as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training. Our system, called Deep Speech, outperforms previously published results on the widely studied Switchboard Hub5'00, achieving 16.0\% error on the full test set. Deep Speech also handles challenging noisy environments better than widely used, state-of-the-art commercial speech systems.},
  keywords   = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
  shorttitle = {Deep {Speech}},
  url        = {http://arxiv.org/abs/1412.5567},
  urldate    = {2019-09-14},
}

@Article{Hasegawa2018,
  author  = {Hasegawa, Keisuke and Qiu, Liwei and Shinoda, Hiroyuki},
  title   = {Midair {Ultrasound} {Fragrance} {Rendering}},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year    = {2018},
  volume  = {24},
  number  = {4},
  pages   = {1477--1485},
  month   = apr,
  issn    = {1077-2626},
  doi     = {10.1109/TVCG.2018.2794118},
  url     = {http://ieeexplore.ieee.org/document/8260917/},
  urldate = {2019-09-14},
}

@InCollection{Hayward2001,
  author     = {Hayward, Vincent},
  title      = {Haptics: {A} {Key} to {Fast} {Paced} {Interactivity}},
  booktitle  = {Human {Friendly} {Mechatronics}},
  publisher  = {Elsevier},
  year       = {2001},
  pages      = {11--16},
  isbn       = {9780444506498},
  doi        = {10.1016/B978-044450649-8/50004-8},
  language   = {en},
  shorttitle = {Haptics},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/B9780444506498500048},
  urldate    = {2019-09-14},
}

@InProceedings{Herbst2008,
  author     = {Herbst, Iris and Braun, Anne-Kathrin and McCall, Rod and Broll, Wolfgang},
  title      = {{TimeWarp}: interactive time travel with a mobile mixed reality game},
  booktitle  = {Proceedings of the 10th international conference on {Human} computer interaction with mobile devices and services - {MobileHCI} '08},
  year       = {2008},
  pages      = {235},
  address    = {Amsterdam, The Netherlands},
  publisher  = {ACM Press},
  doi        = {10.1145/1409240.1409266},
  isbn       = {9781595939524},
  language   = {en},
  shorttitle = {{TimeWarp}},
  url        = {http://portal.acm.org/citation.cfm?doid=1409240.1409266},
  urldate    = {2019-09-14},
}

@Article{Hirche2012,
  author  = {Hirche, S. and Buss, M.},
  title   = {Human-{Oriented} {Control} for {Haptic} {Teleoperation}},
  journal = {Proceedings of the IEEE},
  year    = {2012},
  volume  = {100},
  number  = {3},
  pages   = {623--647},
  month   = mar,
  issn    = {0018-9219, 1558-2256},
  doi     = {10.1109/JPROC.2011.2175150},
  url     = {http://ieeexplore.ieee.org/document/6127891/},
  urldate = {2019-09-14},
}

@Article{Honda2003,
  author   = {{Masaaki Honda}},
  title    = {Human {Speech} {Production} {Mechanisms}},
  journal  = {NTT Technical Review},
  year     = {2003},
  volume   = {1},
  number   = {2},
  pages    = {24--29},
  month    = may,
  issn     = {1348-3447},
  language = {English},
}

@InProceedings{Hornbaek2017,
  author    = {HornbÃŠk, Kasper and Oulasvirta, Antti},
  title     = {What {Is} {Interaction}?},
  booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '17},
  year      = {2017},
  pages     = {5040--5052},
  address   = {Denver, Colorado, USA},
  publisher = {ACM Press},
  doi       = {10.1145/3025453.3025765},
  isbn      = {9781450346559},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3025453.3025765},
  urldate   = {2019-09-14},
}

@Article{Charles2004,
  author  = {{Charles E. Hughes.}},
  title   = {Augmenting {Museum} {Experiences} with {Mixed} {Reality}},
  journal = {Proceedings of Knowledge Sharing and Collaborative Engineering 2004},
  year    = {2004},
  pages   = {22--24},
}

@Article{Hughes2005,
  author   = {Hughes, C.E. and Stapleton, C.B. and Hughes, D.E. and Smith, E.M.},
  title    = {Mixed {Reality} in {Education}, {Entertainment}, and {Training}},
  journal  = {IEEE Computer Graphics and Applications},
  year     = {2005},
  volume   = {25},
  number   = {6},
  pages    = {24--30},
  month    = nov,
  issn     = {0272-1716},
  doi      = {10.1109/MCG.2005.139},
  language = {en},
  url      = {http://ieeexplore.ieee.org/document/1528429/},
  urldate  = {2019-09-14},
}

@InProceedings{Wolfgang2016,
  author    = {Hurst, Wolfgang and Vriens, Kevin},
  title     = {Multimodal feedback for finger-based interaction in mobile augmented reality},
  booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {Multimodal} {Interaction} - {ICMI} 2016},
  year      = {2016},
  pages     = {302--306},
  address   = {Tokyo, Japan},
  publisher = {ACM Press},
  doi       = {10.1145/2993148.2993163},
  isbn      = {9781450345569},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2993148.2993163},
  urldate   = {2019-09-14},
}

@InCollection{Irawati2006,
  author    = {Irawati, Sylvia and Green, Scott and Billinghurst, Mark and Duenser, Andreas and Ko, Heedong},
  title     = {An {Evaluation} of an {Augmented} {Reality} {Multimodal} {Interface} {Using} {Speech} and {Paddle} {Gestures}},
  booktitle = {Advances in {Artificial} {Reality} and {Tele}-{Existence}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2006},
  editor    = {Pan, Zhigeng and Cheok, Adrian and Haller, Michael and Lau, Rynson W. H. and Saito, Hideo and Liang, Ronghua},
  volume    = {4282},
  pages     = {272--283},
  address   = {Berlin, Heidelberg},
  isbn      = {9783540497769 9783540497790},
  doi       = {10.1007/11941354_28},
  language  = {en},
  url       = {http://link.springer.com/10.1007/11941354_28},
  urldate   = {2019-09-14},
}

@Article{Jain1996,
  author     = {Jain, A.K. and {Jianchang Mao} and Mohiuddin, K.M.},
  title      = {Artificial neural networks: a tutorial},
  journal    = {Computer},
  year       = {1996},
  volume     = {29},
  number     = {3},
  pages      = {31--44},
  month      = mar,
  issn       = {00189162},
  doi        = {10.1109/2.485891},
  shorttitle = {Artificial neural networks},
  url        = {http://ieeexplore.ieee.org/document/485891/},
  urldate    = {2019-09-14},
}

@Article{Jakobsson2014,
  author   = {Jakobsson, Jan},
  title    = {Pain {Management} in {Ambulatory} {Surgery}â{A} {Review}},
  journal  = {Pharmaceuticals},
  year     = {2014},
  volume   = {7},
  number   = {8},
  pages    = {850--865},
  month    = jul,
  issn     = {1424-8247},
  doi      = {10.3390/ph7080850},
  language = {en},
  url      = {http://www.mdpi.com/1424-8247/7/8/850},
  urldate  = {2019-09-14},
}

@InProceedings{Jantz2017,
  author    = {Jantz, Jay and Molnar, Adam and Alcaide, Ramses},
  title     = {A brain-computer interface for extended reality interfaces},
  booktitle = {{ACM} {SIGGRAPH} 2017 {VR} {Village} on - {SIGGRAPH} '17},
  year      = {2017},
  pages     = {1--2},
  address   = {Los Angeles, California},
  publisher = {ACM Press},
  doi       = {10.1145/3089269.3089290},
  isbn      = {9781450350136},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3089269.3089290},
  urldate   = {2019-09-14},
}

@Article{Kansaku2010,
  author     = {Kansaku, Kenji and Hata, Naoki and Takano, Kouji},
  title      = {My thoughts through a robot's eyes: {An} augmented reality-brainâmachine interface},
  journal    = {Neuroscience Research},
  year       = {2010},
  volume     = {66},
  number     = {2},
  pages      = {219--222},
  month      = feb,
  issn       = {01680102},
  doi        = {10.1016/j.neures.2009.10.006},
  language   = {en},
  shorttitle = {My thoughts through a robot's eyes},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S0168010209020094},
  urldate    = {2019-09-14},
}

@InProceedings{Kapur2018,
  author     = {Kapur, Arnav and Kapur, Shreyas and Maes, Pattie},
  title      = {{AlterEgo}: {A} {Personalized} {Wearable} {Silent} {Speech} {Interface}},
  booktitle  = {Proceedings of the 2018 {Conference} on {Human} {Information} {Interaction}\&{Retrieval} - {IUI} '18},
  year       = {2018},
  pages      = {43--53},
  address    = {Tokyo, Japan},
  publisher  = {ACM Press},
  doi        = {10.1145/3172944.3172977},
  isbn       = {9781450349451},
  language   = {en},
  shorttitle = {{AlterEgo}},
  url        = {http://dl.acm.org/citation.cfm?doid=3172944.3172977},
  urldate    = {2019-09-14},
}

@Article{Fakhri2008,
  author  = {{Fakhri Karray}},
  title   = {Human-computer interaction: {Overview} on state of the art},
  journal = {International journal on smart sensing and intelligent systems},
  year    = {2008},
  month   = mar,
}

@InProceedings{Kato2000,
  author    = {Kato, H. and Billinghurst, M. and Poupyrev, I. and Imamoto, K. and Tachibana, K.},
  title     = {Virtual object manipulation on a table-top {AR} environment},
  booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality} ({ISAR} 2000)},
  year      = {2000},
  pages     = {111--119},
  address   = {Munich, Germany},
  publisher = {IEEE},
  doi       = {10.1109/ISAR.2000.880934},
  isbn      = {9780769508467},
  url       = {http://ieeexplore.ieee.org/document/880934/},
  urldate   = {2019-09-14},
}

@InProceedings{Kyto2018,
  author     = {KytÃ¶, Mikko and Ens, Barrett and Piumsomboon, Thammathip and Lee, Gun A. and Billinghurst, Mark},
  title      = {Pinpointing: {Precise} {Head}- and {Eye}-{Based} {Target} {Selection} for {Augmented} {Reality}},
  booktitle  = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '18},
  year       = {2018},
  pages      = {1--14},
  address    = {Montreal QC, Canada},
  publisher  = {ACM Press},
  doi        = {10.1145/3173574.3173655},
  isbn       = {9781450356206},
  language   = {en},
  shorttitle = {Pinpointing},
  url        = {http://dl.acm.org/citation.cfm?doid=3173574.3173655},
  urldate    = {2019-09-14},
}

@Article{Lahat2015,
  author     = {Lahat, Dana and Adali, Tulay and Jutten, Christian},
  title      = {Multimodal {Data} {Fusion}: {An} {Overview} of {Methods}, {Challenges}, and {Prospects}},
  journal    = {Proceedings of the IEEE},
  year       = {2015},
  volume     = {103},
  number     = {9},
  pages      = {1449--1477},
  month      = sep,
  issn       = {0018-9219, 1558-2256},
  doi        = {10.1109/JPROC.2015.2460697},
  shorttitle = {Multimodal {Data} {Fusion}},
  url        = {http://ieeexplore.ieee.org/document/7214350/},
  urldate    = {2019-09-14},
}

@Article{Lee2013,
  author  = {Lee, Dongjun and Franchi, Antonio and Son, Hyoung Il and Ha, ChangSu and Bulthoff, Heinrich H. and Giordano, Paolo Robuffo},
  title   = {Semiautonomous {Haptic} {Teleoperation} {Control} {Architecture} of {Multiple} {Unmanned} {Aerial} {Vehicles}},
  journal = {IEEE/ASME Transactions on Mechatronics},
  year    = {2013},
  volume  = {18},
  number  = {4},
  pages   = {1334--1345},
  month   = aug,
  issn    = {1083-4435, 1941-014X},
  doi     = {10.1109/TMECH.2013.2263963},
  url     = {http://ieeexplore.ieee.org/document/6522198/},
  urldate = {2019-09-14},
}

@Article{Lenhardt2008,
  author  = {Lenhardt, A. and Kaper, M. and Ritter, H.J.},
  title   = {An {Adaptive} {P}300-{Based} {Online} {Brain}â{Computer} {Interface}},
  journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year    = {2008},
  volume  = {16},
  number  = {2},
  pages   = {121--130},
  month   = apr,
  issn    = {1534-4320, 1558-0210},
  doi     = {10.1109/TNSRE.2007.912816},
  url     = {http://ieeexplore.ieee.org/document/4389810/},
  urldate = {2019-09-14},
}

@InCollection{Lenhardt2010,
  author    = {Lenhardt, Alexander and Ritter, Helge},
  title     = {An {Augmented}-{Reality} {Based} {Brain}-{Computer} {Interface} for {Robot} {Control}},
  booktitle = {Neural {Information} {Processing}. {Models} and {Applications}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2010},
  editor    = {Wong, Kok Wai and Mendis, B. Sumudu U. and Bouzerdoum, Abdesselam},
  volume    = {6444},
  pages     = {58--65},
  address   = {Berlin, Heidelberg},
  isbn      = {9783642175336 9783642175343},
  doi       = {10.1007/978-3-642-17534-3_8},
  url       = {http://link.springer.com/10.1007/978-3-642-17534-3_8},
  urldate   = {2019-09-14},
}

@InProceedings{Li2017,
  author    = {Li, Sukun and Leider, Avery and Qiu, Meikang and Gai, Keke and Liu, Meiqin},
  title     = {Brain-{Based} {Computer} {Interfaces} in {Virtual} {Reality}},
  booktitle = {2017 {IEEE} 4th {International} {Conference} on {Cyber} {Security} and {Cloud} {Computing} ({CSCloud})},
  year      = {2017},
  pages     = {300--305},
  address   = {New York, NY, USA},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/CSCloud.2017.51},
  isbn      = {9781509066445},
  url       = {http://ieeexplore.ieee.org/document/7987213/},
  urldate   = {2019-09-14},
}

@Article{Licklider1960,
  author  = {Licklider, J. C. R.},
  title   = {Man-{Computer} {Symbiosis}},
  journal = {IRE Transactions on Human Factors in Electronics},
  year    = {1960},
  volume  = {HFE-1},
  number  = {1},
  pages   = {4--11},
  month   = mar,
  issn    = {0099-4561, 2168-2836},
  doi     = {10.1109/THFE2.1960.4503259},
  url     = {http://ieeexplore.ieee.org/document/4503259/},
  urldate = {2019-09-14},
}

@InProceedings{Lindeman2007,
  author    = {Lindeman, R.W. and Noma, H. and de Barros, P.G.},
  title     = {Hear-{Through} and {Mic}-{Through} {Augmented} {Reality}: {Using} {Bone} {Conduction} to {Display} {Spatialized} {Audio}},
  year      = {2007},
  address   = {Nara, Japan},
  month     = nov,
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2007.4538843},
}

@Article{Lotte2010,
  author   = {Lotte, Fabien and van Langhenhove, AurÃ©lien and Lamarche, Fabrice and Ernest, Thomas and Renard, Yann and Arnaldi, Bruno and LÃ©cuyer, Anatole},
  title    = {Exploring {Large} {Virtual} {Environments} by {Thoughts} {Using} a {Brain}â{Computer} {Interface} {Based} on {Motor} {Imagery} and {High}-{Level} {Commands}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {2010},
  volume   = {19},
  number   = {1},
  pages    = {54--70},
  month    = feb,
  issn     = {1054-7460, 1531-3263},
  doi      = {10.1162/pres.19.1.54},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/10.1162/pres.19.1.54},
  urldate  = {2019-09-14},
}

@Article{Jose2018,
  author  = {{Jose Luis Mosso Vazquez} and {Angelica Torres Morales} and {Melissa Garcia}},
  title   = {Brain {Computer} {Interface} : {A} {Future} {Solution} for {Virtual} {Reality} {Navigation} in {Surgery} {Hands} to {Mind} {Control} , {Just} {Thinking}.},
  journal = {Developments in C Anaesthetics \& Pain Management},
  year    = {2018},
  pages   = {5--8},
  issn    = {2640-9399},
  doi     = {http://dx.doi.org/10.31031/DAPM.2018.01.000522},
}

@Article{Macdonald1978,
  author   = {Macdonald, John and McGurk, Harry},
  title    = {Visual influences on speech perception processes},
  journal  = {Perception \& Psychophysics},
  year     = {1978},
  volume   = {24},
  number   = {3},
  pages    = {253--257},
  month    = may,
  issn     = {0031-5117, 1532-5962},
  doi      = {10.3758/BF03206096},
  language = {en},
  url      = {http://www.springerlink.com/index/10.3758/BF03206096},
  urldate  = {2019-09-14},
}

@InProceedings{Machesney2014,
  author     = {Machesney, Dawn and Wexler, Sharon Stahl and Chen, Tony and Coppola, Jean F.},
  title      = {Gerontechnology {Companion}: {Virutal} pets for dementia patients},
  booktitle  = {{IEEE} {Long} {Island} {Systems}, {Applications} and {Technology} ({LISAT}) {Conference} 2014},
  year       = {2014},
  pages      = {1--3},
  address    = {Farmingdale, NY, USA},
  month      = may,
  publisher  = {IEEE},
  doi        = {10.1109/LISAT.2014.6845226},
  isbn       = {9781479938506},
  shorttitle = {Gerontechnology {Companion}},
  url        = {http://ieeexplore.ieee.org/document/6845226/},
  urldate    = {2019-09-14},
}

@InProceedings{Marin2002,
  author    = {Marin, R. and Sanz, P.J. and Sanchez, J.S.},
  title     = {A very high level interface to teleoperate a robot via {Web} including augmented reality},
  booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.02CH37292)},
  year      = {2002},
  volume    = {3},
  pages     = {2725--2730},
  address   = {Washington, DC, USA},
  publisher = {IEEE},
  doi       = {10.1109/ROBOT.2002.1013644},
  isbn      = {9780780372726},
  url       = {http://ieeexplore.ieee.org/document/1013644/},
  urldate   = {2019-09-14},
}

@InProceedings{Matthies2017,
  author     = {Matthies, Denys J. C. and Strecker, Bernhard A. and Urban, Bodo},
  title      = {\textit{{EarFieldSensing}}: {A} {Novel} {In}-{Ear} {Electric} {Field} {Sensing} to {Enrich} {Wearable} {Gesture} {Input} through {Facial} {Expressions}},
  booktitle  = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '17},
  year       = {2017},
  pages      = {1911--1922},
  address    = {Denver, Colorado, USA},
  publisher  = {ACM Press},
  doi        = {10.1145/3025453.3025692},
  isbn       = {9781450346559},
  language   = {en},
  shorttitle = {\textit{{EarFieldSensing}}},
  url        = {http://dl.acm.org/citation.cfm?doid=3025453.3025692},
  urldate    = {2019-09-14},
}

@Article{Milgram1994,
  author  = {{Paul Milgram} and {Fumio Kishino }},
  title   = {A {TAXONOMY} {OF} {MIXED} {REALITY} {VISUAL} {DISPLAYS}},
  journal = {IEICE Transactions on Information Systems},
  year    = {1994},
  volume  = {E77-D},
  number  = {12},
  pages   = {1321--1329},
  month   = dec,
}

@Article{Motti2014,
  author   = {Motti, Vivian Genaro and Caine, Kelly},
  title    = {Human {Factors} {Considerations} in the {Design} of {Wearable} {Devices}},
  journal  = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  year     = {2014},
  volume   = {58},
  number   = {1},
  pages    = {1820--1824},
  month    = sep,
  issn     = {1541-9312},
  doi      = {10.1177/1541931214581381},
  language = {en},
  url      = {http://journals.sagepub.com/doi/10.1177/1541931214581381},
  urldate  = {2019-09-14},
}

@Book{Nelkon1998,
  title     = {Advanced level physics},
  publisher = {Heinemann Educational},
  year      = {1998},
  author    = {{Michael Nelkon} and {P. Parker}},
}

@Article{Nordahl2011,
  author  = {Nordahl, Rolf and Turchet, Luca and Serafin, Stefania},
  title   = {Sound {Synthesis} and {Evaluation} of {Interactive} {Footsteps} and {Environmental} {Sounds} {Rendering} for {Virtual} {Reality} {Applications}},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year    = {2011},
  volume  = {17},
  number  = {9},
  pages   = {1234--1244},
  month   = sep,
  issn    = {1077-2626},
  doi     = {10.1109/TVCG.2011.30},
  url     = {http://ieeexplore.ieee.org/document/5708144/},
  urldate = {2019-09-14},
}

@Book{Norman1990,
  title     = {The design of everyday things},
  publisher = {Doubleday},
  year      = {1990},
  author    = {Norman, Donald A.},
  address   = {New York},
  edition   = {1st Doubleday/Currency ed},
  isbn      = {9780385267748},
  keywords  = {Industrial design, Psychological aspects, Human engineering},
}

@Article{Okamura2009,
  author     = {Okamura, Allison M},
  title      = {Haptic feedback in robot-assisted minimally invasive surgery:},
  journal    = {Current Opinion in Urology},
  year       = {2009},
  volume     = {19},
  number     = {1},
  pages      = {102--107},
  month      = jan,
  issn       = {0963-0643},
  doi        = {10.1097/MOU.0b013e32831a478c},
  language   = {en},
  shorttitle = {Haptic feedback in robot-assisted minimally invasive surgery},
  url        = {https://insights.ovid.com/crossref?an=00042307-200901000-00020},
  urldate    = {2019-09-14},
}

@Article{Ott2007,
  author   = {Ott, Renaud and Thalmann, Daniel and Vexo, FrÃ©dÃ©ric},
  title    = {Haptic feedback in mixed-reality environment},
  journal  = {The Visual Computer},
  year     = {2007},
  volume   = {23},
  number   = {9-11},
  pages    = {843--849},
  month    = aug,
  issn     = {0178-2789, 1432-2315},
  doi      = {10.1007/s00371-007-0159-y},
  language = {en},
  url      = {http://link.springer.com/10.1007/s00371-007-0159-y},
  urldate  = {2019-09-14},
}

@InProceedings{Outram2016,
  author    = {Outram, Benjamin I.},
  title     = {Synesthesia audio-visual interactive-sound and music visualization in virtual reality with orbital observation and navigation},
  booktitle = {2016 {IEEE} {International} {Workshop} on {Mixed} {Reality} {Art} ({MRA})},
  year      = {2016},
  pages     = {7--8},
  address   = {Greenville, SC, USA},
  month     = mar,
  publisher = {IEEE},
  doi       = {10.1109/MIXRA.2016.7858997},
  isbn      = {9781509013753},
  url       = {http://ieeexplore.ieee.org/document/7858997/},
  urldate   = {2019-09-14},
}

@InProceedings{Pacchierotti2016,
  author     = {Pacchierotti, Claudio and Salvietti, Gionata and Hussain, Irfan and Meli, Leonardo and Prattichizzo, Domenico},
  title      = {The {hRing}: {A} wearable haptic device to avoid occlusions in hand tracking},
  booktitle  = {2016 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
  year       = {2016},
  pages      = {134--139},
  address    = {Philadelphia, PA, USA},
  month      = apr,
  publisher  = {IEEE},
  doi        = {10.1109/HAPTICS.2016.7463167},
  isbn       = {9781509009039},
  shorttitle = {The {hRing}},
  url        = {http://ieeexplore.ieee.org/document/7463167/},
  urldate    = {2019-09-14},
}

@Article{Hangue2012,
  author  = {{Hangue Park} and Kiani, M. and {Hyung-Min Lee} and {Jeonghee Kim} and Block, J. and Gosselin, B. and Ghovanloo, M.},
  title   = {A {Wireless} {Magnetoresistive} {Sensing} {System} for an {Intraoral} {Tongue}-{Computer} {Interface}},
  journal = {IEEE Transactions on Biomedical Circuits and Systems},
  year    = {2012},
  volume  = {6},
  number  = {6},
  pages   = {571--585},
  month   = dec,
  issn    = {1932-4545, 1940-9990},
  doi     = {10.1109/TBCAS.2012.2227962},
  url     = {http://ieeexplore.ieee.org/document/6392916/},
  urldate = {2019-09-14},
}

@Article{Parra2007,
  author   = {Parra, Jaime and Lopes da Silva, Fernando H. and Stroink, Hans and Kalitzin, Stiliyan},
  title    = {Is colour modulation an independent factor in human visual photosensitivity?},
  journal  = {Brain},
  year     = {2007},
  volume   = {130},
  number   = {6},
  pages    = {1679--1689},
  month    = jun,
  issn     = {1460-2156, 0006-8950},
  doi      = {10.1093/brain/awm103},
  language = {en},
  url      = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awm103},
  urldate  = {2019-09-14},
}

@InProceedings{Patil2016,
  author    = {Patil, Siddhant and Prabhu, Chiquitha and Neogi, Omkar and Joshi, Abhijit R. and Katre, Neha},
  title     = {E-learning system using {Augmented} {Reality}},
  booktitle = {2016 {International} {Conference} on {Computing} {Communication} {Control} and automation ({ICCUBEA})},
  year      = {2016},
  pages     = {1--5},
  address   = {Pune, India},
  month     = aug,
  publisher = {IEEE},
  doi       = {10.1109/ICCUBEA.2016.7860038},
  isbn      = {9781509032914},
  url       = {http://ieeexplore.ieee.org/document/7860038/},
  urldate   = {2019-09-14},
}

@Article{Pauly2015,
  author   = {Pauly, Olivier and Diotte, Benoit and Fallavollita, Pascal and Weidert, Simon and Euler, Ekkehard and Navab, Nassir},
  title    = {Machine learning-based augmented reality for improved surgical scene understanding},
  journal  = {Computerized Medical Imaging and Graphics},
  year     = {2015},
  volume   = {41},
  pages    = {55--60},
  month    = apr,
  issn     = {08956111},
  doi      = {10.1016/j.compmedimag.2014.06.007},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0895611114001001},
  urldate  = {2019-09-14},
}

@Article{Pfurtscheller2001,
  author  = {Pfurtscheller, G. and Neuper, C.},
  title   = {Motor imagery and direct brain-computer communication},
  journal = {Proceedings of the IEEE},
  year    = {2001},
  volume  = {89},
  number  = {7},
  pages   = {1123--1134},
  month   = jul,
  issn    = {00189219},
  doi     = {10.1109/5.939829},
  url     = {http://ieeexplore.ieee.org/document/939829/},
  urldate = {2019-09-14},
}

@Article{Prattichizzo2012,
  author  = {Prattichizzo, D. and Pacchierotti, C. and Rosati, G.},
  title   = {Cutaneous {Force} {Feedback} as a {Sensory} {Subtraction} {Technique} in {Haptics}},
  journal = {IEEE Transactions on Haptics},
  year    = {2012},
  volume  = {5},
  number  = {4},
  pages   = {289--300},
  issn    = {1939-1412},
  doi     = {10.1109/TOH.2012.15},
  url     = {http://ieeexplore.ieee.org/document/6175016/},
  urldate = {2019-09-14},
}

@InProceedings{Ranasinghe2016,
  author     = {Ranasinghe, Nimesha and Do, Ellen Yi-Luen},
  title      = {Virtual {Sweet}: {Simulating} {Sweet} {Sensation} {Using} {Thermal} {Stimulation} on the {Tip} of the {Tongue}},
  booktitle  = {Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology} - {UIST} '16 {Adjunct}},
  year       = {2016},
  pages      = {127--128},
  address    = {Tokyo, Japan},
  publisher  = {ACM Press},
  doi        = {10.1145/2984751.2985729},
  isbn       = {9781450345316},
  language   = {en},
  shorttitle = {Virtual {Sweet}},
  url        = {http://dl.acm.org/citation.cfm?doid=2984751.2985729},
  urldate    = {2019-09-14},
}

@InProceedings{Ranasinghe2018,
  author     = {Ranasinghe, Nimesha and Eason Wai Tung, Chow and Yen, Ching Chiuan and Do, Ellen Yi-Luen and Jain, Pravar and Thi Ngoc Tram, Nguyen and Koh, Koon Chuan Raymond and Tolley, David and Karwita, Shienny and Lien-Ya, Lin and Liangkun, Yan and Shamaiah, Kala},
  title      = {Season {Traveller}: {Multisensory} {Narration} for {Enhancing} the {Virtual} {Reality} {Experience}},
  booktitle  = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '18},
  year       = {2018},
  pages      = {1--13},
  address    = {Montreal QC, Canada},
  publisher  = {ACM Press},
  doi        = {10.1145/3173574.3174151},
  isbn       = {9781450356206},
  language   = {en},
  shorttitle = {Season {Traveller}},
  url        = {http://dl.acm.org/citation.cfm?doid=3173574.3174151},
  urldate    = {2019-09-14},
}

@InProceedings{Rawat2016,
  author    = {Rawat, Seema and Vats, Somya and Kumar, Praveen},
  title     = {Evaluating and exploring the {MYO} {ARMBAND}},
  booktitle = {2016 {International} {Conference} {System} {Modeling} \& {Advancement} in {Research} {Trends} ({SMART})},
  year      = {2016},
  pages     = {115--120},
  address   = {Moradabad, India},
  publisher = {IEEE},
  doi       = {10.1109/SYSMART.2016.7894501},
  isbn      = {9781509035434},
  url       = {http://ieeexplore.ieee.org/document/7894501/},
  urldate   = {2019-09-14},
}

@Article{Rekimoto1997,
  author     = {Rekimoto, Jun},
  title      = {{NaviCam}:{A} {Magnifying} {Glass} {Approach} to {Augmented} {Reality}},
  journal    = {Presence: Teleoperators and Virtual Environments},
  year       = {1997},
  volume     = {6},
  number     = {4},
  pages      = {399--412},
  month      = aug,
  issn       = {1054-7460, 1531-3263},
  doi        = {10.1162/pres.1997.6.4.399},
  language   = {en},
  shorttitle = {{NaviCam}},
  url        = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.399},
  urldate    = {2019-09-14},
}

@InProceedings{Richard2007,
  author     = {Richard, E. and Billaudeau, V. and Richard, P. and Gaudin, G.},
  title      = {Augmented {Reality} for {Rehabilitation} of {Cognitive} {Disabled} {Children}: {A} {Preliminary} {Study}},
  booktitle  = {2007 {Virtual} {Rehabilitation}},
  year       = {2007},
  pages      = {102--108},
  address    = {Venice, Italy},
  month      = sep,
  publisher  = {IEEE},
  doi        = {10.1109/ICVR.2007.4362148},
  isbn       = {9781424412037},
  shorttitle = {Augmented {Reality} for {Rehabilitation} of {Cognitive} {Disabled} {Children}},
  url        = {http://ieeexplore.ieee.org/document/4362148/},
  urldate    = {2019-09-14},
}

@Article{Richards2019,
  author     = {Richards, Michael D. and Goltz, Herbert C. and Wong, Agnes M.F.},
  title      = {Audiovisual perception in amblyopia: {A} review and synthesis},
  journal    = {Experimental Eye Research},
  year       = {2019},
  volume     = {183},
  pages      = {68--75},
  month      = jun,
  issn       = {00144835},
  doi        = {10.1016/j.exer.2018.04.017},
  language   = {en},
  shorttitle = {Audiovisual perception in amblyopia},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S0014483518301404},
  urldate    = {2019-09-14},
}

@Article{Rosenblum2000,
  author  = {Rosenblum, L.},
  title   = {Virtual and augmented reality 2020},
  journal = {IEEE Computer Graphics and Applications},
  year    = {2000},
  volume  = {20},
  number  = {1},
  pages   = {38--39},
  month   = feb,
  issn    = {02721716},
  doi     = {10.1109/38.814551},
  url     = {http://ieeexplore.ieee.org/document/814551/},
  urldate = {2019-09-14},
}

@Article{Satyanarayanan2001,
  author     = {Satyanarayanan, M.},
  title      = {Pervasive computing: vision and challenges},
  journal    = {IEEE Personal Communications},
  year       = {2001},
  volume     = {8},
  number     = {4},
  pages      = {10--17},
  month      = aug,
  issn       = {10709916},
  doi        = {10.1109/98.943998},
  shorttitle = {Pervasive computing},
  url        = {http://ieeexplore.ieee.org/document/943998/},
  urldate    = {2019-09-14},
}

@Article{Satyanarayanan2009,
  author  = {Satyanarayanan, M. and Bahl, P. and Caceres, R. and Davies, N.},
  title   = {The {Case} for {VM}-{Based} {Cloudlets} in {Mobile} {Computing}},
  journal = {IEEE Pervasive Computing},
  year    = {2009},
  volume  = {8},
  number  = {4},
  pages   = {14--23},
  month   = oct,
  issn    = {1536-1268},
  doi     = {10.1109/MPRV.2009.82},
  url     = {http://ieeexplore.ieee.org/document/5280678/},
  urldate = {2019-09-14},
}

@Article{Schalk2004,
  author     = {Schalk, G. and McFarland, D.J. and Hinterberger, T. and Birbaumer, N. and Wolpaw, J.R.},
  title      = {{BCI}2000: {A} {General}-{Purpose} {Brain}-{Computer} {Interface} ({BCI}) {System}},
  journal    = {IEEE Transactions on Biomedical Engineering},
  year       = {2004},
  volume     = {51},
  number     = {6},
  pages      = {1034--1043},
  month      = jun,
  issn       = {0018-9294},
  doi        = {10.1109/TBME.2004.827072},
  language   = {en},
  shorttitle = {{BCI}2000},
  url        = {http://ieeexplore.ieee.org/document/1300799/},
  urldate    = {2019-09-14},
}

@InProceedings{Serafin2017,
  author    = {Serafin, Stefania and Adjorlu, Ali and Nilsson, Niels and Thomsen, Lui and Nordahl, Rolf},
  title     = {Considerations on the use of virtual and augmented reality technologies in music education},
  booktitle = {2017 {IEEE} {Virtual} {Reality} {Workshop} on {K}-12 {Embodied} {Learning} through {Virtual} \& {Augmented} {Reality} ({KELVAR})},
  year      = {2017},
  pages     = {1--4},
  address   = {Los Angeles, CA, USA},
  month     = mar,
  publisher = {IEEE},
  doi       = {10.1109/KELVAR.2017.7961562},
  isbn      = {9781538618929},
  url       = {http://ieeexplore.ieee.org/document/7961562/},
  urldate   = {2019-09-14},
}

@Article{Seufert2009,
  author     = {Seufert, Tina and SchÃŒtze, Maren and BrÃŒnken, Roland},
  title      = {Memory characteristics and modality in multimedia learning: {An} aptitudeâtreatmentâinteraction study},
  journal    = {Learning and Instruction},
  year       = {2009},
  volume     = {19},
  number     = {1},
  pages      = {28--42},
  month      = feb,
  issn       = {09594752},
  doi        = {10.1016/j.learninstruc.2008.01.002},
  language   = {en},
  shorttitle = {Memory characteristics and modality in multimedia learning},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S0959475208000121},
  urldate    = {2019-09-14},
}

@Article{Mohammed2018,
  author     = {Si-Mohammed, Hakim and Petit, Jimmy and Jeunet, Camille and Argelaguet, Ferran and Spindler, Fabien and Evain, Andeol and Roussel, Nicolas and Casiez, Gery and Lecuyer, Anatole},
  title      = {Towards {BCI}-based {Interfaces} for {Augmented} {Reality}: {Feasibility}, {Design} and {Evaluation}},
  journal    = {IEEE Transactions on Visualization and Computer Graphics},
  year       = {2018},
  pages      = {1--1},
  issn       = {1077-2626, 1941-0506, 2160-9306},
  doi        = {10.1109/TVCG.2018.2873737},
  shorttitle = {Towards {BCI}-based {Interfaces} for {Augmented} {Reality}},
  url        = {https://ieeexplore.ieee.org/document/8481564/},
  urldate    = {2019-09-14},
}

@Article{Starner1997,
  author   = {Starner, Thad and Mann, Steve and Rhodes, Bradley and Levine, Jeffrey and Healey, Jennifer and Kirsch, Dana and Picard, Rosalind W. and Pentland, Alex},
  title    = {Augmented {Reality} through {Wearable} {Computing}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {1997},
  volume   = {6},
  number   = {4},
  pages    = {386--398},
  month    = aug,
  issn     = {1054-7460, 1531-3263},
  doi      = {10.1162/pres.1997.6.4.386},
  language = {en},
  url      = {http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.386},
  urldate  = {2019-09-14},
}

@InProceedings{Sundareswaran2003,
  author     = {Sundareswaran, V. and Wang, K. and Chen, S. and Behringer, R. and McGee, J. and Tam, C. and Zahorik, P.},
  title      = {3D audio augmented reality: implementation and experiments},
  booktitle  = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
  year       = {2003},
  pages      = {296--297},
  address    = {Tokyo, Japan},
  publisher  = {IEEE Comput. Soc},
  doi        = {10.1109/ISMAR.2003.1240728},
  isbn       = {9780769520063},
  shorttitle = {3D audio augmented reality},
  url        = {http://ieeexplore.ieee.org/document/1240728/},
  urldate    = {2019-09-14},
}

@InProceedings{Amir2005,
  author    = {Amir M. Tahmasebi, Babak Taati},
  title     = {Dynamic parameter identification and analysis of a {PHANToM} haptic device},
  booktitle = {Proceedings of 2005 {IEEE} {Conference} on {Control} {Applications}, 2005. {CCA} 2005.},
  year      = {2005},
  pages     = {1251--1256},
  address   = {Toronto, Canada},
  publisher = {IEEE},
  doi       = {10.1109/CCA.2005.1507303},
  isbn      = {9780780393547},
  url       = {http://ieeexplore.ieee.org/document/1507303/},
  urldate   = {2019-09-14},
}

@Article{Takano2011,
  author     = {Takano, Kouji and Hata, Naoki and Kansaku, Kenji},
  title      = {Towards {Intelligent} {Environments}: {An} {Augmented} {Reality}â{Brain}â{Machine} {Interface} {Operated} with a {See}-{Through} {Head}-{Mount} {Display}},
  journal    = {Frontiers in Neuroscience},
  year       = {2011},
  volume     = {5},
  issn       = {1662-4548},
  doi        = {10.3389/fnins.2011.00060},
  shorttitle = {Towards {Intelligent} {Environments}},
  url        = {http://journal.frontiersin.org/article/10.3389/fnins.2011.00060/abstract},
  urldate    = {2019-09-14},
}

@Article{Haar2010,
  author   = {Haar, G ter},
  title    = {Ultrasound bioeffects and safety},
  journal  = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
  year     = {2010},
  volume   = {224},
  number   = {2},
  pages    = {363--373},
  month    = feb,
  issn     = {0954-4119, 2041-3033},
  doi      = {10.1243/09544119JEIM613},
  language = {en},
  url      = {http://journals.sagepub.com/doi/10.1243/09544119JEIM613},
  urldate  = {2019-09-14},
}

@InProceedings{Hussain2009,
  author = {{Hussain Tinwala} and {I. Scott MacKenzie}},
  title  = {Eyes-free text entry on a touchscreen phone},
  year   = {2009},
  pages  = {83 -- 88},
  month  = oct,
  doi    = {10.1109/TIC-STH.2009.5444381},
  url    = {http://dx.doi.org/10.1109/TIC-STH.2009.5444381},
}

@Book{Vanderah2016,
  title      = {Nolte's {The} human brain: an introduction to its functional anatomy},
  publisher  = {Elsevier},
  year       = {2016},
  author     = {Vanderah, Todd W. and Gould, Douglas J. and Nolte, John},
  address    = {Philadelphia, PA},
  edition    = {Seventh edition},
  isbn       = {9781455728596},
  keywords   = {Central Nervous System, anatomy \& histology, Brain, anatomy \& histology, Nervous System Physiological Phenomena},
  shorttitle = {Nolte's {The} human brain},
}

@Article{Townsend2010,
  author     = {Townsend, G. and LaPallo, B.K. and Boulay, C.B. and Krusienski, D.J. and Frye, G.E. and Hauser, C.K. and Schwartz, N.E. and Vaughan, T.M. and Wolpaw, J.R. and Sellers, E.W.},
  title      = {A novel {P}300-based brainâcomputer interface stimulus presentation paradigm: {Moving} beyond rows and columns},
  journal    = {Clinical Neurophysiology},
  year       = {2010},
  volume     = {121},
  number     = {7},
  pages      = {1109--1120},
  month      = jul,
  issn       = {13882457},
  doi        = {10.1016/j.clinph.2010.01.030},
  language   = {en},
  shorttitle = {A novel {P}300-based brainâcomputer interface stimulus presentation paradigm},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S1388245710000738},
  urldate    = {2019-09-14},
}

@InProceedings{Uchiyama2002,
  author     = {Uchiyama, S. and Takemoto, K. and Satoh, K. and Yamamoto, H. and Tamura, H.},
  title      = {{MR} {Platform}: a basic body on which mixed reality applications are built},
  booktitle  = {Proceedings. {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
  year       = {2002},
  pages      = {246--320},
  address    = {Darmstadt, Germany},
  publisher  = {IEEE Comput. Soc},
  doi        = {10.1109/ISMAR.2002.1115095},
  isbn       = {9780769517810},
  shorttitle = {{MR} {Platform}},
  url        = {http://ieeexplore.ieee.org/document/1115095/},
  urldate    = {2019-09-14},
}

@Article{Vaidya2018,
  author   = {Vaidya, Saurabh and Ambad, Prashant and Bhosle, Santosh},
  title    = {Industry 4.0 â {A} {Glimpse}},
  journal  = {Procedia Manufacturing},
  year     = {2018},
  volume   = {20},
  pages    = {233--238},
  issn     = {23519789},
  doi      = {10.1016/j.promfg.2018.02.034},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S2351978918300672},
  urldate  = {2019-09-14},
}

@InProceedings{Annie2013,
  author = {{Annie Joyce Vullamparthi} and { Sarat Chandra Babu Nelaturu } and {Dakshayani D Mallaya} and {Chandrasekhar S.}},
  title  = {Assistive {Learning} for {Children} with {Autism} using {Augmented} {Reality}},
  year   = {2013},
  doi    = {10.1109/T4E.2013.18},
  url    = {http://dx.doi.org/10.1109/T4E.2013.18},
}

@Article{Waldert2016,
  author     = {Waldert, Stephan},
  title      = {Invasive vs. {Non}-{Invasive} {Neuronal} {Signals} for {Brain}-{Machine} {Interfaces}: {Will} {One} {Prevail}?},
  journal    = {Frontiers in Neuroscience},
  year       = {2016},
  volume     = {10},
  month      = jun,
  issn       = {1662-453X},
  doi        = {10.3389/fnins.2016.00295},
  shorttitle = {Invasive vs. {Non}-{Invasive} {Neuronal} {Signals} for {Brain}-{Machine} {Interfaces}},
  url        = {http://journal.frontiersin.org/Article/10.3389/fnins.2016.00295/abstract},
  urldate    = {2019-09-14},
}

@Article{Wang2018,
  author     = {Wang, Jeff and Erkoyuncu, John and Roy, Rajkumar},
  title      = {A {Conceptual} {Design} for {Smell} {Based} {Augmented} {Reality}: {Case} {Study} in {Maintenance} {Diagnosis}},
  journal    = {Procedia CIRP},
  year       = {2018},
  volume     = {78},
  pages      = {109--114},
  issn       = {22128271},
  doi        = {10.1016/j.procir.2018.09.067},
  language   = {en},
  shorttitle = {A {Conceptual} {Design} for {Smell} {Based} {Augmented} {Reality}},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S2212827118312472},
  urldate    = {2019-09-14},
}

@Article{Wang2012,
  author  = {Wang, Po T and King, Christine E and Chui, Luis A and Do, An H and Nenadic, Zoran},
  title   = {Self-paced brainâcomputer interface control of ambulation in a virtual reality environment},
  journal = {Journal of Neural Engineering},
  year    = {2012},
  volume  = {9},
  number  = {5},
  pages   = {056016},
  month   = oct,
  issn    = {1741-2560, 1741-2552},
  doi     = {10.1088/1741-2560/9/5/056016},
  url     = {http://stacks.iop.org/1741-2552/9/i=5/a=056016?key=crossref.a886b904b0269fc0852e04b012d6ed4c},
  urldate = {2019-09-14},
}

@InCollection{Wang2011,
  author    = {Wang, Xiangyu and Wang, Rui},
  title     = {Co-presence in {Mixed} {Reality}-{Mediated} {Collaborative} {Design} {Space}},
  booktitle = {Collaborative {Design} in {Virtual} {Environments}},
  publisher = {Springer Netherlands},
  year      = {2011},
  editor    = {Wang, Xiangyu and Tsai, Jerry Jen-Hung},
  pages     = {51--64},
  address   = {Dordrecht},
  isbn      = {9789400706040 9789400706057},
  doi       = {10.1007/978-94-007-0605-7_5},
  language  = {en},
  url       = {http://www.springerlink.com/index/10.1007/978-94-007-0605-7_5},
  urldate   = {2019-09-14},
}

@Article{Weichert2013,
  author   = {Weichert, Frank and Bachmann, Daniel and Rudak, BartholomÃ€us and Fisseler, Denis},
  title    = {Analysis of the {Accuracy} and {Robustness} of the {Leap} {Motion} {Controller}},
  journal  = {Sensors},
  year     = {2013},
  volume   = {13},
  number   = {5},
  pages    = {6380--6393},
  month    = may,
  issn     = {1424-8220},
  doi      = {10.3390/s130506380},
  language = {en},
  url      = {http://www.mdpi.com/1424-8220/13/5/6380},
  urldate  = {2019-09-14},
}

@InProceedings{Wenig2017,
  author     = {Wenig, Dirk and SchÃ¶ning, Johannes and Olwal, Alex and Oben, Mathias and Malaka, Rainer},
  title      = {{WatchThru}: {Expanding} {Smartwatch} {Displays} with {Mid}-air {Visuals} and {Wrist}-worn {Augmented} {Reality}},
  booktitle  = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '17},
  year       = {2017},
  pages      = {716--721},
  address    = {Denver, Colorado, USA},
  publisher  = {ACM Press},
  doi        = {10.1145/3025453.3025852},
  isbn       = {9781450346559},
  language   = {en},
  shorttitle = {{WatchThru}},
  url        = {http://dl.acm.org/citation.cfm?doid=3025453.3025852},
  urldate    = {2019-09-14},
}

@InProceedings{Wolf2018,
  author     = {Wolf, Dennis and Besserer, Daniel and Sejunaite, Karolina and Riepe, Matthias and Rukzio, Enrico},
  title      = {{cARe}: {An} {Augmented} {Reality} {Support} {System} for {Dementia} {Patients}},
  booktitle  = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} {Adjunct} {Proceedings} - {UIST} '18 {Adjunct}},
  year       = {2018},
  pages      = {42--44},
  address    = {Berlin, Germany},
  publisher  = {ACM Press},
  doi        = {10.1145/3266037.3266095},
  isbn       = {9781450359498},
  language   = {en},
  shorttitle = {{cARe}},
  url        = {http://dl.acm.org/citation.cfm?doid=3266037.3266095},
  urldate    = {2019-09-14},
}

@Book{Wolpaw2012,
  title     = {Brainâ{Computer} {InterfacesPrinciples} and {Practice}},
  publisher = {Oxford University Press},
  year      = {2012},
  author    = {Wolpaw, Jonathan and Wolpaw, Elizabeth Winter},
  month     = jan,
  isbn      = {9780195388855},
  doi       = {10.1093/acprof:oso/9780195388855.001.0001},
  url       = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195388855.001.0001/acprof-9780195388855},
  urldate   = {2019-09-14},
}

@InProceedings{Yamada1992,
  author    = {Yamada, K. and Tasei, K. and Nakamura, K.},
  title     = {Weighted conical transducer for generation of {Bessel} beam ultrasound},
  booktitle = {{IEEE} 1992 {Ultrasonics} {Symposium} {Proceedings}},
  year      = {1992},
  pages     = {613--618},
  address   = {Tucson, AZ, USA},
  publisher = {IEEE},
  doi       = {10.1109/ULTSYM.1992.275927},
  isbn      = {9780780305625},
  url       = {http://ieeexplore.ieee.org/document/275927/},
  urldate   = {2019-09-14},
}

@InProceedings{Yamada2006,
  author     = {Yamada, T. and Yokoyama, S. and Tanikawa, T. and Hirota, K. and Hirose, M.},
  title      = {Wearable {Olfactory} {Display}: {Using} {Odor} in {Outdoor} {Environment}},
  booktitle  = {{IEEE} {Virtual} {Reality} {Conference} ({VR} 2006)},
  year       = {2006},
  pages      = {199--206},
  address    = {Alexandria, VA, USA},
  publisher  = {IEEE},
  doi        = {10.1109/VR.2006.147},
  isbn       = {9781424402243},
  shorttitle = {Wearable {Olfactory} {Display}},
  url        = {http://ieeexplore.ieee.org/document/1667645/},
  urldate    = {2019-09-14},
}

@InProceedings{Yanagida2004,
  author    = {Yanagida, Y. and Kawato, S. and Noma, H. and Tomono, A. and Tesutani, N.},
  title     = {Projection based olfactory display with nose tracking},
  booktitle = {{IEEE} {Virtual} {Reality} 2004},
  year      = {2004},
  pages     = {43--50},
  address   = {Chicago, IL, USA},
  publisher = {IEEE},
  doi       = {10.1109/VR.2004.1310054},
  isbn      = {9780780384156},
  url       = {http://ieeexplore.ieee.org/document/1310054/},
  urldate   = {2019-09-14},
}

@InProceedings{Flintham2003,
  author    = {Flintham, Martin and Benford, Steve and Anastasi, Rob and Hemmings, Terry and Crabtree, Andy and Greenhalgh, Chris and Tandavanitj, Nick and Adams, Matt and Row-Farr, Ju},
  title     = {Where On-line Meets on the Streets: Experiences with Mobile Mixed Reality Games},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2003},
  series    = {CHI '03},
  pages     = {569--576},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {642710},
  doi       = {10.1145/642611.642710},
  isbn      = {1-58113-630-7},
  location  = {Ft. Lauderdale, Florida, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/642611.642710},
}

@InProceedings{Brown2003,
  author    = {Brown, Barry and MacColl, Ian and Chalmers, Matthew and Galani, Areti and Randell, Cliff and Steed, Anthony},
  title     = {Lessons from the Lighthouse: Collaboration in a Shared Mixed Reality System},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2003},
  series    = {CHI '03},
  pages     = {577--584},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {642711},
  doi       = {10.1145/642611.642711},
  isbn      = {1-58113-630-7},
  keywords  = {WWW, context-awareness, location-awareness, mixed reality, museum visiting, virtual reality},
  location  = {Ft. Lauderdale, Florida, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/642611.642711},
}

@Article{Bulman2004,
author="Bulman, J.
and Crabtree, B.
and Gower, A.
and Oldroyd, A.
and Lawson, M.
and Sutton, J.",
title="Mixed Reality Applications in Urban Environments",
journal="BT Technology Journal",
year="2004",
month="Jul",
day="01",
volume="22",
number="3",
pages="84--94",
abstract="Mixed reality applications are concerned with blurring the divide between the real and virtual, where the user perception of the real world is contextually enhanced with additional information. This paper will provide an overview of three related projects that explore opportunities for how virtual reality and mixed reality technologies can be effectively used across consumer, industrial and military domains. A common theme is dealing with the amount of data that can be potentially displayed in the applications.",
issn="1573-1995",
doi="10.1023/B:BTTJ.0000047123.94280.3a",
url="https://doi.org/10.1023/B:BTTJ.0000047123.94280.3a"
}

@InProceedings{Koleva2001,
  author    = {Koleva, Boriana and Taylor, Ian and Benford, Steve and Fraser, Mike and Greenhalgh, Chris and Schn\"{a}delbach, Holger and vom Lehn, Dirk and Heath, Christian and Row-Farr, Ju and Adams, Matt},
  title     = {Orchestrating a Mixed Reality Performance},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2001},
  series    = {CHI '01},
  pages     = {38--45},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {365033},
  doi       = {10.1145/365024.365033},
  isbn      = {1-58113-327-8},
  keywords  = {mixed reality, performance, traversable interfaces},
  location  = {Seattle, Washington, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/365024.365033},
}

@InProceedings{Grasset2008,
  author    = {Grasset, Raphael and Dunser, Andreas and Billinghurst, Mark},
  title     = {The Design of a Mixed-reality Book: Is It Still a Real Book?},
  booktitle = {Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
  year      = {2008},
  series    = {ISMAR '08},
  pages     = {99--102},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1605354},
  doi       = {10.1109/ISMAR.2008.4637333},
  isbn      = {978-1-4244-2840-3},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ISMAR.2008.4637333},
}

@InProceedings{Chatzidimitris2016,
  author    = {T. {Chatzidimitris} and D. {Gavalas} and D. {Michael}},
  title     = {SoundPacman: Audio augmented reality in location-based games},
  booktitle = {2016 18th Mediterranean Electrotechnical Conference (MELECON)},
  year      = {2016},
  pages     = {1-6},
  month     = {April},
  doi       = {10.1109/MELCON.2016.7495414},
  keywords  = {audio acoustics;augmented reality;biology computing;computer games;electroencephalography;medical computing;SoundPacman;audio augmented reality;sound design;location-based games research;visual information;game information;3D sounds;EEG analysis;immersion levels;players;Games;Three-dimensional displays;Engines;Servers;Prototypes;Roads;Augmented reality;pervasive games;augmented reality;3D sound;location-based games;EEG},
}

@InProceedings{Schnadelbach2002,
  author    = {Schn\"{a}delbach, Holger and Koleva, Boriana and Flintham, Martin and Fraser, Mike and Izadi, Shahram and Chandler, Paul and Foster, Malcolm and Benford, Steve and Greenhalgh, Chris and Rodden, Tom and Rodden, Tom},
  title     = {The Augurscope: A Mixed Reality Interface for Outdoors},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2002},
  series    = {CHI '02},
  pages     = {9--16},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {503379},
  doi       = {10.1145/503376.503379},
  isbn      = {1-58113-453-3},
  keywords  = {augmented reality, mixed reality, mobile and wireless applications, outdoors applications, virtual reality},
  location  = {Minneapolis, Minnesota, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/503376.503379},
}

@InProceedings{Komninos2012,
  author    = {Komninos, Andreas and Barrie, Peter and Stefanis, Vassilios and Plessas, Athanasios},
  title     = {Urban Exploration Using Audio Scents},
  booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services},
  year      = {2012},
  series    = {MobileHCI '12},
  pages     = {349--358},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2371629},
  doi       = {10.1145/2371574.2371629},
  isbn      = {978-1-4503-1105-2},
  keywords  = {audio mixed reality, implicit navigation, urban environments},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2371574.2371629},
}

@InProceedings{Crabtree2004,
  author    = {Crabtree, Andy and Benford, Steve and Rodden, Tom and Rodden, Tom and Greenhalgh, Chris and Flintham, Martin and Anastasi, Rob and Drozd, Adam and Adams, Matt and Row-Farr, Ju and Tandavanitj, Nick and Steed, Anthony and Steed, Anthony},
  title     = {Orchestrating a Mixed Reality Game 'on the Ground'},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2004},
  series    = {CHI '04},
  pages     = {391--398},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {985742},
  doi       = {10.1145/985692.985742},
  isbn      = {1-58113-702-8},
  keywords  = {GPS, ethnography, mobile \& wireless games, orchestration},
  location  = {Vienna, Austria},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/985692.985742},
}

@InProceedings{Kagimoto2009,
  author    = {Kagimoto, Mami and Kimura, Asako and Shibata, Fumihisa and Tamura, Hideyuki},
  title     = {Analysis of Tactual Impression by Audio and Visual Stimulation for User Interface Design in Mixed Reality Environment},
  booktitle = {Virtual and Mixed Reality},
  year      = {2009},
  editor    = {Shumaker, Randall},
  pages     = {326--335},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In a mixed-reality (MR) environment, a touchable object can be made to change its appearance when a computer-generated image (MR visual stimulation) is superimposed onto it. In this research, we conduct experiments to study the effects of MR visual and audio stimuli on the tactual impression of the ``roughness'' of an object. We show that MR visual stimulation alters a subject's tactual impression of the roughness of an object and that the addition of MR audio stimulation intensifies that effect.},
  isbn      = {978-3-642-02771-0},
}

@Article{Birchfield2009,
author="Birchfield, David
and Megowan-Romanowicz, Colleen",
title="Earth science learning in SMALLab: A design experiment for mixed reality",
journal="International Journal of Computer-Supported Collaborative Learning",
year="2009",
month="Dec",
day="01",
volume="4",
number="4",
pages="403--421",
abstract="Conversational technologies such as email, chat rooms, and blogs have made the transition from novel communication technologies to powerful tools for learning. Currently virtual worlds are undergoing the same transition. We argue that the next wave of innovation is at the level of the computer interface, and that mixed-reality environments offer important advantages over prior technologies. Thus, mixed reality is positioned to have a broad impact on the future of K-12 collaborative learning. We propose three design imperatives that arise from our ongoing work in this area grounded in research from the learning sciences and human-computer interaction. By way of example, we present one such platform, the Situated Multimedia Arts Learning Lab [SMALLab]. SMALLab is a mixed-reality environment that affords face-to-face interaction by colocated participants within a mediated space. We present a recent design experiment that involved the development of a new SMALLab learning scenario and a collaborative student participation framework for a 3-day intervention for 72 high school earth science students. We analyzed student and teacher exchanges from classroom sessions both during the intervention and during regular classroom instruction and found significant increases in the number of student-driven exchanges within SMALLab. We also found that students made significant achievement gains. We conclude that mixed reality can have a positive impact on collaborative learning and that it is poised for broad dissemination into mainstream K-12 contexts.",
issn="1556-1615",
doi="10.1007/s11412-009-9074-8",
url="https://doi.org/10.1007/s11412-009-9074-8"
}

@InProceedings{Langlotz2013,
  author    = {Langlotz, Tobias and Regenbrecht, Holger and Zollmann, Stefanie and Schmalstieg, Dieter},
  title     = {Audio Stickies: Visually-guided Spatial Audio Annotations on a Mobile Augmented Reality Platform},
  booktitle = {Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration},
  year      = {2013},
  series    = {OzCHI '13},
  pages     = {545--554},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2541022},
  doi       = {10.1145/2541016.2541022},
  isbn      = {978-1-4503-2525-7},
  keywords  = {augmented reality, mobile phone, spatial audio},
  location  = {Adelaide, Australia},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2541016.2541022},
}

@Article{Zhou2004,
  author   = {Zhiying Zhou and Adrian David Cheok and Xubo Yang and Yan Qiu},
  title    = {An experimental study on the role of 3D sound in augmented reality environment},
  journal  = {Interacting with Computers},
  year     = {2004},
  volume   = {16},
  number   = {6},
  pages    = {1043 - 1068},
  issn     = {0953-5438},
  abstract = {Investigation of augmented reality (AR) environments has become a popular research topic for engineers, computer and cognitive scientists. Although application oriented studies focused on audio AR environments have been published, little work has been done to vigorously study and evaluate the important research questions of the effectiveness of three-dimensional (3D) sound in the AR context, and to what extent the addition of 3D sound would contribute to the AR experience. Thus, we have developed two AR environments and performed vigorous experiments with human subjects to study the effects of 3D sound in the AR context. The study concerns two scenarios. In the first scenario, one participant must use vision only and vision with 3D sound to judge the relative depth of augmented virtual objects. In the second scenario, two participants must cooperate to perform a joint task in a game-based AR environment. Hence, the goals of this study are (1) to access the impact of 3D sound on depth perception in a single-camera AR environment, (2) to study the impact of 3D sound on task performance and the feeling of ‘human presence and collaboration’, (3) to better understand the role of 3D sound in human–computer and human–human interactions, (4) to investigate if gender can affect the impact of 3D sound in AR environments. The outcomes of this research can have a useful impact on the development of audio AR systems, which provide more immersive, realistic and entertaining experiences by introducing 3D sound. Our results suggest that 3D sound in AR environment significantly improves the accuracy of depth judgment and improves task performance. Our results also suggest that 3D sound contributes significantly to the feeling of human presence and collaboration and helps the subjects to ‘identify spatial objects’.},
  doi      = {https://doi.org/10.1016/j.intcom.2004.06.016},
  keywords = {3D sound, Augmented reality, User study},
  url      = {http://www.sciencedirect.com/science/article/pii/S0953543804000864},
}

@Article{Rumiński2015,
author="Rumi{\'{n}}ski, Dariusz",
title="An experimental study of spatial sound usefulness in searching and navigating through AR environments",
journal="Virtual Reality",
year="2015",
month="Nov",
day="01",
volume="19",
number="3",
pages="223--233",
abstract="This paper presents an experimental study of spatial sound usefulness in searching and navigating through augmented reality environments. Participants were asked to find three objects hidden within no-sound and spatial sound AR environments. The experiment showed that the participants of the spatialized sound group performed faster and more efficiently than working in no-sound configuration. What is more, 3D sound was a valuable cue for navigation in AR environment. The collected data suggest that the use of spatial sound in AR environments can be a significant factor in searching and navigating for hidden objects within indoor AR scenes. To conduct the experiment, the CARE approach was applied, while its CARL language was extended with new elements responsible for controlling audio in 3D space.",
issn="1434-9957",
doi="10.1007/s10055-015-0274-4",
url="https://doi.org/10.1007/s10055-015-0274-4"
}

@Article{Mion2006,
author="Mion, Luca
and D'Inc{\`a}, Gianluca",
title="Analysis of expression in simple musical gestures to enhance audio in interfaces",
journal="Virtual Reality",
year="2006",
month="May",
day="03",
volume="10",
number="1",
pages="62",
abstract="Expression could play a key role in the audio rendering of virtual reality applications. Its understanding is an ambitious issue in the scientific environment, and several studies have investigated the analysis techniques to detect expression in music performances. The knowledge coming from these analyses is widely applicable: embedding expression on audio interfaces can drive to attractive solutions to emphasize interfaces in mixed-reality environments. Synthesized expressive sounds can be combined with real stimuli to experience augmented reality, and they can be used in multi-sensory stimulations to provide the sensation of first-person experience in virtual expressive environments. In this work we focus on the expression of violin and flute performances, with reference to sensorial and affective domains. By means of selected audio features, we draw a set of parameters describing performers' strategies which are suitable both for tuning expressive synthesis instruments and enhancing audio in human--computer interfaces.",
issn="1434-9957",
doi="10.1007/s10055-006-0029-3",
url="https://doi.org/10.1007/s10055-006-0029-3"
}

@Article{Harma2004,
  author  = {Härmä, Aki and Jakka, Julia and Tikander, Miikka and Karjalainen, Matti and Lokki, Tapio and Hiipakka, Jarmo and Lorho, Gaëtan},
  title   = {Augmented Reality Audio for Mobile and Wearable Appliances},
  journal = {J. Audio Eng. Soc},
  year    = {2004},
  volume  = {52},
  number  = {6},
  pages   = {618--639},
  url     = {http://www.aes.org/e-lib/browse.cfm?elib=13010},
}

@InProceedings{Burke2006,
  author    = {Burke, Jennifer L. and Prewett, Matthew S. and Gray, Ashley A. and Yang, Liuquin and Stilson, Frederick R. B. and Coovert, Michael D. and Elliot, Linda R. and Redden, Elizabeth},
  title     = {Comparing the Effects of Visual-auditory and Visual-tactile Feedback on User Performance: A Meta-analysis},
  booktitle = {Proceedings of the 8th International Conference on Multimodal Interfaces},
  year      = {2006},
  series    = {ICMI '06},
  pages     = {108--117},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1181017},
  doi       = {10.1145/1180995.1181017},
  isbn      = {1-59593-541-X},
  keywords  = {meta-analysis, multimodal interface, visual-auditory feedback, visual-tactile feedback},
  location  = {Banff, Alberta, Canada},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1180995.1181017},
}

@Article{Yao2017,
  author   = {S. {Yao}},
  title    = {Headphone-based immersive audio for virtual reality headsets},
  journal  = {IEEE Transactions on Consumer Electronics},
  year     = {2017},
  volume   = {63},
  number   = {3},
  pages    = {300-308},
  month    = {August},
  doi      = {10.1109/TCE.2017.014951},
  keywords = {acoustic signal processing;audio signal processing;handicapped aids;headphones;hearing;loudspeakers;optimisation;rendering (computer graphics);transfer functions;virtual reality;ambisonic surround sound;binaural ambisonic system;image-source model;listening-room simulation;ambisonic rotator;binaural ambisonic decoder;system optimization technique;subjective measurements;objective measurements;perceived audio quality;audio quality assessment;immersive sound;binaural system;virtual auditory space synthesis;subjective listening test;virtual reality headset;headphone-based immersive audio;audio quality enhancement;head-related transfer function customization;closest-matching HRTF dataset;front-back discrimination;up-down discrimination;multiple sound source synthesis;head motion;computational cost minimization;frequency hearing impairment;localization error;localization blur;immersive sound rendering;immersive sound mixing;virtual auditory space repoduction;Loudspeakers;Headphones;Harmonic analysis;Real-time systems;Computational modeling;Solid modeling;Virtual reality;Virtual reality;headphones;head-related transfer function;binaural},
}

@Article{Moustakas2011,
  author = {Moustakas, Nikos and Floros, Andreas and Grigoriou, Nikolas},
  title  = {Interactive Audio Realities: An Augmented / Mixed Reality Audio Game Prototype},
  year   = {2011},
  pages  = {13-16},
  month  = {05},
}

@Article{Ginns2005,
  author   = {Paul Ginns},
  title    = {Meta-analysis of the modality effect},
  journal  = {Learning and Instruction},
  year     = {2005},
  volume   = {15},
  number   = {4},
  pages    = {313 - 331},
  issn     = {0959-4752},
  abstract = {This article reviews research on the modality effect, the educational practice of presenting to-be-learned graphical information visually, and related textual information through an auditory mode. Meta-analytic methods were applied to 43 independent effects (39 between-subjects designs, 4 within-subjects designs). Major hypotheses regarding the instructional benefits of presenting information across modalities were supported, including the effect of two hypothesised moderators, level of element interactivity and pacing of presentation, and between certain fields of study. The strong observed modality effect under system-paced conditions must be weighed against the additional cost of developing audio-visual instructional materials.},
  doi      = {https://doi.org/10.1016/j.learninstruc.2005.07.001},
  url      = {http://www.sciencedirect.com/science/article/pii/S0959475205000459},
}

@Article{Balan2015,
  author  = {Balan, Oana and Moldoveanu, Alin and Moldoveanu, Florica},
  title   = {Navigational audio games: An effective approach toward improving spatial contextual learning for blind people},
  journal = {International Journal on Disability and Human Development},
  year    = {2015},
  volume  = {0},
  month   = {01},
  doi     = {10.1515/ijdhd-2014-0018},
}

@Article{Cooperstock2001,
  author    = {Cooperstock, Jeremy R and others},
  title     = {The classroom of the future: enhancing education through augmented reality},
  journal   = {Usability evaluation and interface design: cognitive engineering, intelligent agents and virtual reality},
  year      = {2001},
  pages     = {688--692},
  publisher = {Lawrence Erlbaum Associates},
}

@InProceedings{Sayed2010,
  author     = {Sayed, N. A. M. El and Zayed, H. H. and Sharawy, M. I.},
  title      = {{ARSC}: {Augmented} {Reality} {Student} {Card}},
  booktitle  = {2010 {International} {Computer} {Engineering} {Conference} ({ICENCO})},
  year       = {2010},
  pages      = {113--120},
  month      = dec,
  abstract   = {Augmented Reality (AR) is the technology of adding virtual objects to the real scenes through enabling the addition of missing information at real life. As the lack of resources is a problem that can be solved through AR, this paper represents and explains the usage of AR technology in what can be named Augmented Reality Student Card (ARSC) for serving the education field. ARSC uses single static markers combined in one card for assigning different objects, leaving the choice to the computer application for minimizing the tracking process. ARSC is designed to be a useful low cost solution for serving the education field. ARSC represents any lesson in a 3D format that helps students to visualize the facts, interact with theories and deal with the information in a totally new effective and interactive way. ARSC can be used in offline, online and game applications with seven markers, four of them are used as a joystick game controller. One of the novelties in this paper is that full experimental tests had been made for the ARTag marker set for sorting them according to their efficiency. The results of the tests are used in this research to choose the most efficient markers for ARSC, and can be used for further researches. The experimental work that had been made in this paper also shows the constraints for marker creation for an AR application. Due to the need to work for online and offline application, merging of toolkits and libraries has been made, as presented in this paper. ARSC was examined by a number of students of both genders with average age between 10-17 years and it was found to have a great acceptance among them.},
  doi        = {10.1109/ICENCO.2010.5720437},
  keywords   = {augmented reality, computer aided instruction, interactive devices, natural scenes, augmented reality student card, real scenes, virtual objects, AR technology, ARSC, joystick game controller, tracking process, Lead, Navigation, Optical imaging, Education, Cameras, Productivity, Software, Augmented Reality, Mixed Reality, Computer Assisted Learning, Optical tracking},
  shorttitle = {{ARSC}},
}

@InProceedings{Dahne2002,
  author     = {Dahne, P. and Karigiannis, J.N.},
  title      = {Archeoguide: system architecture of a mobile outdoor augmented reality system},
  booktitle  = {Proceedings. {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
  year       = {2002},
  pages      = {263--264},
  address    = {Darmstadt, Germany},
  publisher  = {IEEE Comput. Soc},
  doi        = {10.1109/ISMAR.2002.1115103},
  isbn       = {9780769517810},
  shorttitle = {Archeoguide},
  url        = {http://ieeexplore.ieee.org/document/1115103/},
  urldate    = {2019-09-14},
}

@Article{Li2004,
  author   = {Li, G. and Xi, N. and Yu, M. and Fung, W.-K.},
  title    = {Development of {Augmented} {Reality} {System} for {AFM}-{Based} {Nanomanipulation}},
  journal  = {IEEE/ASME Transactions on Mechatronics},
  year     = {2004},
  volume   = {9},
  number   = {2},
  pages    = {358--365},
  month    = jun,
  issn     = {1083-4435},
  doi      = {10.1109/TMECH.2004.828651},
  language = {en},
  url      = {http://ieeexplore.ieee.org/document/1306449/},
  urldate  = {2019-09-14},
}

@InProceedings{Nawab2007,
  author    = {Nawab, A. and Chintamani, K. and Ellis, D. and Auner, G. and Pandya, A.},
  title     = {Joystick mapped {Augmented} {Reality} {Cues} for {End}-{Effector} controlled {Tele}-operated {Robots}},
  booktitle = {2007 {IEEE} {Virtual} {Reality} {Conference}},
  year      = {2007},
  pages     = {263--266},
  month     = mar,
  abstract  = {End-effector control of robots using just remote camera views is difficult due to lack of perceived correspondence between the joysticks and the end-effector coordinate frame. This paper reports the positive effects of augmented reality visual cues on operator performance during end-effector controlled tele-operation using only camera views. Our solution is to overlay a color-coded coordinate system on the end-effector of the robot using AR techniques. This mapped and color-coded coordinate system is then directly mapped to similarly color-coded joysticks used for control of both position and orientation. The AR view along with mapped markings on the joystick give the user a clear notion of the effect of their joystick movements on the end-effector of the robot. All camera views display this registered dynamic overlay information on-demand. An insertion task was used to compare performance with and without the coordinate mapping using fifteen subjects. Preliminary results indicate a significant reduction in distance and reversal errors},
  doi       = {10.1109/VR.2007.352496},
  keywords  = {augmented reality, end effectors, manipulator kinematics, telerobotics, joystick mapped augmented reality, tele-operated robots, robot end-effector control, Augmented reality, Robot control, Cameras, Robot kinematics, Robot vision systems, Software testing, Intelligent robots, Displays, Human factors, Navigation, Robotics, Augmented Reality, Tele-operations, Kinematics, Performance Testing},
}

@Article{Fang2012,
  author   = {Fang, H. C. and Ong, S. K. and Nee, A. Y. C.},
  title    = {Interactive robot trajectory planning and simulation using {Augmented} {Reality}},
  journal  = {Robotics and Computer-Integrated Manufacturing},
  year     = {2012},
  volume   = {28},
  number   = {2},
  pages    = {227--237},
  month    = apr,
  issn     = {0736-5845},
  abstract = {Human–robot interaction in industrial robotics has largely been confined to finding better ways to reconfigure or program the robots. In this paper, an Augmented Reality based (RPAR-II) system is proposed to facilitate robot programming and trajectory planning considering the dynamic constraints of the robots. Through the various simulation capabilities provided in the proposed AR environment, the users are able to preview the simulated motion, perceive any possible overshoot, and resolve discrepancies between the planned and simulated paths prior to the execution of a task. By performing the simulation, the performance of the trajectory planning and the fitness of the selection of the robot controller model/parameters in the robot programming process can be visually evaluated. Practical issues concerning the system implementation are also discussed.},
  doi      = {10.1016/j.rcim.2011.09.003},
  keywords = {Augmented Reality, Robot programming, Human–robot interaction, Trajectory planning, Simulation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0736584511001116},
  urldate  = {2019-09-14},
}

@InProceedings{Jung2015,
  author    = {Jung, Jinki and Lee, Hyeopwoo and Yang, Hyun Seung},
  title     = {[{POSTER}] {An} {Adaptive} {Augmented} {Reality} {Interface} for {Hand} {Based} on {Probabilistic} {Approach}},
  booktitle = {2015 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
  year      = {2015},
  pages     = {152--155},
  address   = {Fukuoka, Japan},
  month     = sep,
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2015.44},
  isbn      = {9781467376600},
  url       = {http://ieeexplore.ieee.org/document/7328084/},
  urldate   = {2019-09-14},
}

@InProceedings{Lakshmiprabha2014,
  author    = {Lakshmiprabha, N. S. and Santos, Alexandre and Mladenov, Dimitar and Beltramello, Olga},
  title     = {[{Poster}] {An} augmented and virtual reality system for training autistic children},
  booktitle = {2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
  year      = {2014},
  pages     = {277--278},
  address   = {Munich, Germany},
  month     = sep,
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2014.6948448},
  isbn      = {9781479961849},
  url       = {http://ieeexplore.ieee.org/document/6948448/},
  urldate   = {2019-09-14},
}

@InProceedings{Lee2018,
  author    = {Lee, Gun A. and Teo, Theophilus and Kim, Seungwon and Billinghurst, Mark},
  title     = {A {User} {Study} on {MR} {Remote} {Collaboration} {Using} {Live} 360 {Video}},
  booktitle = {2018 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
  year      = {2018},
  pages     = {153--164},
  address   = {Munich, Germany},
  month     = oct,
  publisher = {IEEE},
  doi       = {10.1109/ISMAR.2018.00051},
  isbn      = {9781538674598},
  url       = {https://ieeexplore.ieee.org/document/8613761/},
  urldate   = {2019-09-14},
}

@InProceedings{Yamada2018,
  author     = {Yamada, Wataru and Manabe, Hiroyuki and Ikeda, Daizo},
  title      = {{CamTrackPoint}: {Camera}-{Based} {Pointing} {Stick} {Using} {Transmitted} {Light} through {Finger}},
  booktitle  = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} - {UIST} '18},
  year       = {2018},
  pages      = {313--320},
  address    = {Berlin, Germany},
  publisher  = {ACM Press},
  doi        = {10.1145/3242587.3242641},
  isbn       = {9781450359481},
  language   = {en},
  shorttitle = {{CamTrackPoint}},
  url        = {http://dl.acm.org/citation.cfm?doid=3242587.3242641},
  urldate    = {2019-09-14},
}

@InProceedings{Pfeuffer2017,
  author    = {Pfeuffer, Ken and Mayer, Benedikt and Mardanbegi, Diako and Gellersen, Hans},
  title     = {Gaze + pinch interaction in virtual reality},
  booktitle = {Proceedings of the 5th {Symposium} on {Spatial} {User} {Interaction} - {SUI} '17},
  year      = {2017},
  pages     = {99--108},
  address   = {Brighton, United Kingdom},
  publisher = {ACM Press},
  doi       = {10.1145/3131277.3132180},
  isbn      = {9781450354868},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3131277.3132180},
  urldate   = {2019-09-14},
}

@InProceedings{Chang2017,
  author    = {Chang, Yun Suk and Nuernberger, Benjamin and Luan, Bo and Hollerer, Tobias and O'Donovan, John},
  title     = {Gesture-based augmented reality annotation},
  booktitle = {2017 {IEEE} {Virtual} {Reality} ({VR})},
  year      = {2017},
  pages     = {469--470},
  address   = {Los Angeles, CA, USA},
  publisher = {IEEE},
  doi       = {10.1109/VR.2017.7892383},
  isbn      = {9781509066476},
  url       = {http://ieeexplore.ieee.org/document/7892383/},
  urldate   = {2019-09-14},
}

@Article{Hurst2013,
  author   = {Hürst, Wolfgang and van Wezel, Casper},
  title    = {Gesture-based interaction via finger tracking for mobile augmented reality},
  journal  = {Multimedia Tools and Applications},
  year     = {2013},
  volume   = {62},
  number   = {1},
  pages    = {233--258},
  month    = jan,
  issn     = {1380-7501, 1573-7721},
  doi      = {10.1007/s11042-011-0983-y},
  language = {en},
  url      = {http://link.springer.com/10.1007/s11042-011-0983-y},
  urldate  = {2019-09-14},
}

@InProceedings{Piumsomboon2014,
  author     = {Piumsomboon, Thammathip and Altimira, David and Kim, Hyungon and Clark, Adrian and Lee, Gun and Billinghurst, Mark},
  title      = {Grasp-{Shell} vs gesture-speech: {A} comparison of direct and indirect natural interaction techniques in augmented reality},
  booktitle  = {2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
  year       = {2014},
  pages      = {73--82},
  address    = {Munich, Germany},
  month      = sep,
  publisher  = {IEEE},
  doi        = {10.1109/ISMAR.2014.6948411},
  isbn       = {9781479961849},
  shorttitle = {Grasp-{Shell} vs gesture-speech},
  url        = {http://ieeexplore.ieee.org/document/6948411/},
  urldate    = {2019-09-14},
}

@Article{Jenny2019,
  author   = {Jenny, Bernhard and Satriadi, Kadek Ananta and Yang, Yalong and Austin, Christopher R. and Lee, Simond and Chan, Nian and Cordeil, Maxime and Ens, Barrett},
  title    = {Interacting with {Maps} in {Virtual} and {Augmented} {Reality}},
  journal  = {Abstracts of the ICA},
  year     = {2019},
  volume   = {1},
  pages    = {1--1},
  month    = jul,
  issn     = {2570-2106},
  abstract = {{\textless}p{\textgreater}{\textless}strong{\textgreater}Abstract.{\textless}/strong{\textgreater} Augmented reality (AR) and virtual reality (VR) technology are increasingly used for the analysis and visualisation of geospatial data. It has become simple to create an immersive three-dimensional AR or VR map with a combination of game engines (e.g., Unity), software development kits for streaming and rendering geospatial data (e.g., Mapbox), and affordable hardware (e.g., HTC Vive). However, it is not clear how to best interact with geospatial visualisations in AR and VR. For example, there are no established standards to efficiently zoom and pan, select map features, or place markers on AR and VR maps. In this paper, we explore interaction with AR and VR maps using gestures and handheld controllers.{\textless}/p{\textgreater}{\textless}p{\textgreater}As for gesture-controlled interaction, we present the results of recent research projects exploring how body gestures can control basic AR and VR map operations. We use motion-tracking controllers (e.g., Leap Motion) to capture and interpret gestures. We conducted a set of user studies to identify, explore and compare various gestures for controlling map-related operations. This includes, for example, mid-air hand gestures for zooming and panning (Satriadi et al. 2019), selecting points of interest, adjusting the orientation of maps, or placing markers on maps. Additionally, we present novel VR interfaces and interaction methods for controlling the content of maps with gestures.{\textless}/p{\textgreater}{\textless}p{\textgreater}As for handheld controllers, we discuss interaction with exocentric globes, egocentric globes (where the user stands inside a large virtual globe), flat maps, and curved maps in VR. We demonstrate controller-based interaction for adjusting the centre of world maps displayed on these four types of projection surfaces (Yang et al. 2018), and illustrate the utility of interactively movable VR maps by the example of three-dimensional origin-destination flow maps (Yang et al. 2019).{\textless}/p{\textgreater}},
  doi      = {10.5194/ica-abs-1-147-2019},
  language = {en},
  url      = {https://www.abstr-int-cartogr-assoc.net/1/147/2019/},
  urldate  = {2019-09-14},
}

@InProceedings{Brun2018,
  author    = {Brun, Damien},
  title     = {Multimodal and {Context}-{Aware} {Interaction} in {Augmented} {Reality} for {Active} {Assistance}},
  booktitle = {Proceedings of the 2018 on {International} {Conference} on {Multimodal} {Interaction} - {ICMI} '18},
  year      = {2018},
  pages     = {506--510},
  address   = {Boulder, CO, USA},
  publisher = {ACM Press},
  doi       = {10.1145/3242969.3264966},
  isbn      = {9781450356923},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3242969.3264966},
  urldate   = {2019-09-14},
}

@InProceedings{Datcu2012,
  author    = {Datcu, Dragoş and Swart, Thomas and Lukosch, Stephan and Rusak, Zoltan},
  title     = {Multimodal collaboration for crime scene investigation in mediated reality},
  booktitle = {Proceedings of the 14th {ACM} international conference on {Multimodal} interaction - {ICMI} '12},
  year      = {2012},
  pages     = {299},
  address   = {Santa Monica, California, USA},
  publisher = {ACM Press},
  doi       = {10.1145/2388676.2388739},
  isbn      = {9781450314671},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2388676.2388739},
  urldate   = {2019-09-14},
}

@InProceedings{Knierim2018,
  author     = {Knierim, Pascal and Schwind, Valentin and Feit, Anna Maria and Nieuwenhuizen, Florian and Henze, Niels},
  title      = {Physical {Keyboards} in {Virtual} {Reality}: {Analysis} of {Typing} {Performance} and {Effects} of {Avatar} {Hands}},
  booktitle  = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '18},
  year       = {2018},
  pages      = {1--9},
  address    = {Montreal QC, Canada},
  publisher  = {ACM Press},
  doi        = {10.1145/3173574.3173919},
  isbn       = {9781450356206},
  language   = {en},
  shorttitle = {Physical {Keyboards} in {Virtual} {Reality}},
  url        = {http://dl.acm.org/citation.cfm?doid=3173574.3173919},
  urldate    = {2019-09-14},
}

@InProceedings{Lien2016,
  author     = {Lien, Kuo-Chin and Nuernberger, Benjamin and Hollerer, Tobias and Turk, Matthew},
  title      = {{PPV}: {Pixel}-{Point}-{Volume} {Segmentation} for {Object} {Referencing} in {Collaborative} {Augmented} {Reality}},
  booktitle  = {2016 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
  year       = {2016},
  pages      = {77--83},
  address    = {Merida, Yucatan, Mexico},
  month      = sep,
  publisher  = {IEEE},
  doi        = {10.1109/ISMAR.2016.21},
  isbn       = {9781509036417},
  shorttitle = {{PPV}},
  url        = {http://ieeexplore.ieee.org/document/7781769/},
  urldate    = {2019-09-14},
}

@InProceedings{Chun2013,
  author    = {Chun, Wendy H. and Höllerer, Tobias},
  title     = {Real-time hand interaction for augmented reality on mobile phones},
  booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces - {IUI} '13},
  year      = {2013},
  pages     = {307},
  address   = {Santa Monica, California, USA},
  publisher = {ACM Press},
  doi       = {10.1145/2449396.2449435},
  isbn      = {9781450319652},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2449396.2449435},
  urldate   = {2019-09-14},
}

@InProceedings{Benavides2015,
  author     = {Benavides, Xavier and Amores, Judith and Maes, Pattie},
  title      = {Invisibilia: revealing invisible data using augmented reality and internet connected devices},
  booktitle  = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2015 {ACM} {International} {Symposium} on {Wearable} {Computers} - {UbiComp} '15},
  year       = {2015},
  pages      = {341--344},
  address    = {Osaka, Japan},
  publisher  = {ACM Press},
  doi        = {10.1145/2800835.2800882},
  isbn       = {9781450335751},
  language   = {en},
  shorttitle = {Invisibilia},
  url        = {http://dl.acm.org/citation.cfm?doid=2800835.2800882},
  urldate    = {2019-09-14},
}

@InCollection{Reifinger2007,
  author    = {Reifinger, Stefan and Wallhoff, Frank and Ablassmeier, Markus and Poitschke, Tony and Rigoll, Gerhard},
  title     = {Static and {Dynamic} {Hand}-{Gesture} {Recognition} for {Augmented} {Reality} {Applications}},
  booktitle = {Human-{Computer} {Interaction}. {HCI} {Intelligent} {Multimodal} {Interaction} {Environments}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2007},
  editor    = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Jacko, Julie A.},
  volume    = {4552},
  pages     = {728--737},
  address   = {Berlin, Heidelberg},
  isbn      = {9783540731085 9783540731108},
  doi       = {10.1007/978-3-540-73110-8_79},
  language  = {en},
  url       = {http://link.springer.com/10.1007/978-3-540-73110-8_79},
  urldate   = {2019-09-14},
}

@Article{Lv2014,
  author   = {Lv, Zhihan and Halawani, Alaa and Feng, Shengzhong and Li, Haibo and Réhman, Shafiq Ur},
  title    = {Multimodal {Hand} and {Foot} {Gesture} {Interaction} for {Handheld} {Devices}},
  journal  = {ACM Transactions on Multimedia Computing, Communications, and Applications},
  year     = {2014},
  volume   = {11},
  number   = {1s},
  pages    = {1--19},
  month    = oct,
  issn     = {15516857},
  doi      = {10.1145/2645860},
  language = {en},
  url      = {http://dl.acm.org/citation.cfm?doid=2675060.2645860},
  urldate  = {2019-09-14},
}

@Article{Kim2005,
  author     = {Kim, Hyosun and Albuquerque, Georgia and Havemann, Sven and Fellner, Dieter W.},
  title      = {Tangible 3D: {Hand} {Gesture} {Interaction} for {Immersive} 3D {Modeling}},
  journal    = {Eurographics Symposium on Virtual Environments},
  year       = {2005},
  pages      = {9 pages},
  issn       = {1727-530X},
  abstract   = {Most of all interaction tasks relevant for a general three-dimensional virtual environment can be supported by 6DOF control and grab/select input. Obviously a very efficient method is direct manipulation with bare hands, like in real environment. This paper shows the possibility to perform non-trivial tasks using only a few well-known hand gestures, so that almost no training is necessary to interact with 3D-softwares. Using this gesture interaction we have built an immersive 3D modeling system with 3D model representation based on a mesh library, which is optimized not only for real-time rendering but also accommodates for changes of both vertex positions and mesh connectivity in real-time. For performing the gesture interaction, the users hand is marked with just four fingertipthimbles made of inexpensive material as simple as white paper. Within our scenario, the recognized hand gestures are used to select, create, manipulate and deform the meshes in a spontaneous and intuitive way. All modeling tasks are performed wirelessly through a camera/vision tracking method for the head and hand interaction.},
  doi        = {10.2312/egve/ipt_egve2005/191-199},
  keywords   = {Categories and Subject Descriptors (according to ACM CCS): I.3.6 [Computer Graphics]: Interaction Techniques},
  language   = {eng},
  shorttitle = {Tangible 3D},
  url        = {http://diglib.eg.org/handle/10.2312/EGVE.IPT_EGVE2005.191-199},
  urldate    = {2019-09-14},
}

@InProceedings{Barioni2018,
  author    = {Barioni, Ricardo R. and Figueiredo, Lucas and Cunha, Kelvin and Teichrieb, Veronica},
  title     = {Human {Pose} {Tracking} from {RGB} {Inputs}},
  booktitle = {2018 20th {Symposium} on {Virtual} and {Augmented} {Reality} ({SVR})},
  year      = {2018},
  pages     = {176--182},
  address   = {Foz do Iguaçu, Brazil},
  month     = oct,
  publisher = {IEEE},
  doi       = {10.1109/SVR.2018.00035},
  isbn      = {9781728106045},
  url       = {https://ieeexplore.ieee.org/document/8802469/},
  urldate   = {2019-09-14},
}

@InProceedings{Sun2019,
  author     = {Sun, Yongbin and Armengol-Urpi, Alexandre and Reddy Kantareddy, Sai Nithin and Siegel, Joshua and Sarma, Sanjay},
  title      = {{MagicHand}: {Interact} with {IoT} {Devices} in {Augmented} {Reality} {Environment}},
  booktitle  = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
  year       = {2019},
  pages      = {1738--1743},
  address    = {Osaka, Japan},
  month      = mar,
  publisher  = {IEEE},
  doi        = {10.1109/VR.2019.8798053},
  isbn       = {9781728113777},
  shorttitle = {{MagicHand}},
  url        = {https://ieeexplore.ieee.org/document/8798053/},
  urldate    = {2019-09-14},
}

@InProceedings{Techasarntikul2019,
  author    = {Techasarntikul, Nattaon and Mashita, Tomohiro and Ratsamee, Photchara and Uranishi, Yuki and Takemura, Haruo and Orlosky, Jason and Kiyokawa, Kiyoshi},
  title     = {Evaluation of {Pointing} {Interfaces} with an {AR} {Agent} for {Multi}-section {Information} {Guidance}},
  booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and 3D {User} {Interfaces} ({VR})},
  year      = {2019},
  pages     = {1185--1186},
  address   = {Osaka, Japan},
  month     = mar,
  publisher = {IEEE},
  doi       = {10.1109/VR.2019.8798061},
  isbn      = {9781728113777},
  url       = {https://ieeexplore.ieee.org/document/8798061/},
  urldate   = {2019-09-14},
}

@InCollection{Piumsomboon2013,
  author    = {Piumsomboon, Thammathip and Clark, Adrian and Billinghurst, Mark and Cockburn, Andy},
  title     = {User-{Defined} {Gestures} for {Augmented} {Reality}},
  booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2013},
  publisher = {Springer Berlin Heidelberg},
  year      = {2013},
  editor    = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Kotzé, Paula and Marsden, Gary and Lindgaard, Gitte and Wesson, Janet and Winckler, Marco},
  volume    = {8118},
  pages     = {282--299},
  address   = {Berlin, Heidelberg},
  isbn      = {9783642404795 9783642404801},
  doi       = {10.1007/978-3-642-40480-1_18},
  url       = {http://link.springer.com/10.1007/978-3-642-40480-1_18},
  urldate   = {2019-09-14},
}

@InProceedings{Pomsar2019,
  author    = {Pomsar, Ladislav and Ferencik, Norbert and Jascur, Miroslav and Bundzel, Marek},
  title     = {Using surface electromyography for gesture detection},
  booktitle = {2019 {IEEE} 17th {World} {Symposium} on {Applied} {Machine} {Intelligence} and {Informatics} ({SAMI})},
  year      = {2019},
  pages     = {95--100},
  address   = {Herlany, Slovakia},
  month     = jan,
  publisher = {IEEE},
  doi       = {10.1109/SAMI.2019.8782744},
  isbn      = {9781728102504},
  url       = {https://ieeexplore.ieee.org/document/8782744/},
  urldate   = {2019-09-14},
}

@Article{Ro2019,
  author     = {Ro, Hyocheol and Byun, Jung-Hyun and Park, Yoon Jung and Lee, Nam Kyu and Han, Tack-Don},
  title      = {{AR} {Pointer}: {Advanced} {Ray}-{Casting} {Interface} {Using} {Laser} {Pointer} {Metaphor} for {Object} {Manipulation} in 3D {Augmented} {Reality} {Environment}},
  journal    = {Applied Sciences},
  year       = {2019},
  volume     = {9},
  number     = {15},
  pages      = {3078},
  month      = jan,
  abstract   = {In this paper, we propose AR Pointer, a new augmented reality (AR) interface that allows users to manipulate three-dimensional (3D) virtual objects in AR environment. AR Pointer uses a built-in 6-degrees of freedom (DoF) inertial measurement unit (IMU) sensor in an off-the-shelf mobile device to cast a virtual ray that is used to accurately select objects. It is also implemented using simple touch gestures commonly used in smartphones for 3D object manipulation, so users can easily manipulate 3D virtual objects using the AR Pointer, without a long training period. To demonstrate the usefulness of AR Pointer, we introduce two use-cases, constructing an AR furniture layout and AR education. Then, we conducted two experiments, performance tests and usability tests, to represent the excellence of the designed interaction methods using AR Pointer. We found that AR Pointer is more efficient than other interfaces, achieving 39.4\% faster task completion time in the object manipulation. In addition, the participants gave an average of 8.61 points (13.4\%) on the AR Pointer in the usability test conducted through the system usability scale (SUS) questionnaires and 8.51 points (15.1\%) on the AR Pointer in the fatigue test conducted through the NASA task load index (NASA-TLX) questionnaire. Previous AR applications have been implemented in a passive AR environment where users simply check and pop up the AR objects those are prepared in advance. However, if AR Pointer is used for AR object manipulation, it is possible to provide an immersive AR environment for the user who want/wish to actively interact with the AR objects.},
  copyright  = {http://creativecommons.org/licenses/by/3.0/},
  doi        = {10.3390/app9153078},
  keywords   = {augmented reality, head-mounted display, intelligent user interface, ray-casting, mixed reality, augmented reality interface, head-mounted display interface, ray-casting interface},
  language   = {en},
  shorttitle = {{AR} {Pointer}},
  url        = {https://www.mdpi.com/2076-3417/9/15/3078},
  urldate    = {2019-09-14},
}

@Article{Maitlo2019,
  author   = {Maitlo, Nizamuddin and Wang, Yanbo and Chen, Chao Ping and Mi, Lantian and Zhang, Wenbo},
  title    = {Hand-{Gesture}-{Recognition} {Based} {Text} {Input} {Method} for {AR}/{VR} {Wearable} {Devices}},
  journal  = {arXiv:1907.12188 [cs]},
  year     = {2019},
  month    = jul,
  note     = {arXiv: 1907.12188},
  abstract = {Static and dynamic hand movements are basic way for human-machine interactions. To recognize and classify these movements, first these movements are captured by the cameras mounted on the augmented reality (AR) or virtual reality (VR) wearable devices. The hand is segmented using segmentation method and its gestures are passed to hand gesture recognition algorithm, which depends on depth-wise separable convolutional neural network for training, testing and finally running smoothly on mobile AR/VR devices, while maintaining the accuracy and balancing the load. A number of gestures are processed for identification of right gesture and to classify the gesture and ignore the all intermittent gestures. With proposed method, a user can write letters and numbers in air by just moving his/her hand in air. Gesture based operations are performed, and trajectory of hand is recorded as handwritten text. Finally, that handwritten text is processed for the text recognition.},
  keywords = {Computer Science - Human-Computer Interaction},
  url      = {http://arxiv.org/abs/1907.12188},
  urldate  = {2019-09-14},
}

@Article{Hou2019,
  author  = {Hou, Weiting},
  title   = {Augmented {Reality} {Museum} {Visiting} {Application} based on the {Microsoft} {HoloLens}},
  journal = {Journal of Physics: Conference Series},
  year    = {2019},
  volume  = {1237},
  pages   = {052018},
  month   = jun,
  issn    = {1742-6588, 1742-6596},
  doi     = {10.1088/1742-6596/1237/5/052018},
  url     = {https://iopscience.iop.org/article/10.1088/1742-6596/1237/5/052018},
  urldate = {2019-09-14},
}

@InCollection{Kistler2011,
  author    = {Kistler, Felix and Sollfrank, Dominik and Bee, Nikolaus and André, Elisabeth},
  title     = {Full {Body} {Gestures} {Enhancing} a {Game} {Book} for {Interactive} {Story} {Telling}},
  booktitle = {Interactive {Storytelling}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2011},
  editor    = {Si, Mei and Thue, David and André, Elisabeth and Lester, James C. and Tanenbaum, Joshua and Zammitto, Veronica},
  volume    = {7069},
  pages     = {207--218},
  address   = {Berlin, Heidelberg},
  isbn      = {9783642252884 9783642252891},
  doi       = {10.1007/978-3-642-25289-1_23},
  url       = {http://link.springer.com/10.1007/978-3-642-25289-1_23},
  urldate   = {2019-09-14},
}

@InProceedings{Barakonyi2005,
  author     = {Barakonyi, István and Weilguny, Markus and Psik, Thomas and Schmalstieg, Dieter},
  title      = {{MonkeyBridge}: autonomous agents in augmented reality games},
  booktitle  = {Proceedings of the 2005 {ACM} {SIGCHI} {International} {Conference} on {Advances} in computer entertainment technology - {ACE} '05},
  year       = {2005},
  pages      = {172--175},
  address    = {Valencia, Spain},
  publisher  = {ACM Press},
  doi        = {10.1145/1178477.1178500},
  isbn       = {9781595931108},
  language   = {en},
  shorttitle = {{MonkeyBridge}},
  url        = {http://portal.acm.org/citation.cfm?doid=1178477.1178500},
  urldate    = {2019-09-14},
}

@Article{Pachoulakis2012,
  author  = {Pachoulakis, Ioannis},
  title   = {Augmented {Reality} {Platforms} for {Virtual} {Fitting} {Rooms}},
  journal = {The International journal of Multimedia \& Its Applications},
  year    = {2012},
  volume  = {4},
  number  = {4},
  pages   = {35--46},
  month   = aug,
  issn    = {09755934},
  doi     = {10.5121/ijma.2012.4404},
  url     = {http://www.airccse.org/journal/jma/4412ijma04.pdf},
  urldate = {2019-09-14},
}

@InProceedings{Barakonyi2004,
  author    = {Barakonyi, Istvan and Fahmy, Tamer and Schmalstieg, Dieter},
  title     = {Remote {Collaboration} {Using} {Augmented} {Reality} {Videoconferencing}},
  booktitle = {Proceedings of {Graphics} {Interface} 2004},
  year      = {2004},
  series    = {{GI} '04},
  pages     = {89--96},
  address   = {School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada},
  publisher = {Canadian Human-Computer Communications Society},
  note      = {event-place: London, Ontario, Canada},
  abstract  = {This paper describes an Augmented Reality (AR) Videoconferencing System, which is a novel remote collaboration tool combining a desktop-based AR system and a videoconference module. The novelty of our system is the combination of these tools with AR applications superimposed on live video background displaying the conference parties' real environment, merging the advantages of the natural face-to-face communication of videoconferencing and AR's interaction capabilities with distributed virtual objects using tangible physical artifacts. The simplicity of the system makes it affordable for everyday use. We explain our system design based on concurrent video streaming, optical tracking and 3D application sharing, and provide experimental proof that it yields superior quality compared to pure video streaming with successive optical tracking from the compressed streams. We demonstrate the system's collaborative features with a volume rendering application that allows users to display and examine volumetric data simultaneously and to highlight or explore slices of the volume by manipulating an optical marker as a cutting plane interaction device.},
  isbn      = {9781568812274},
  keywords  = {Augmented Reality, Videoconferencing, computer-supported collaborative work, volume rendering},
  url       = {http://dl.acm.org/citation.cfm?id=1006058.1006070},
  urldate   = {2019-09-14},
}

@InProceedings{Hsiao2011a,
  author    = {Hsiao, K. and Rashvand, H. F.},
  title     = {Body {Language} and {Augmented} {Reality} {Learning} {Environment}},
  booktitle = {2011 {Fifth} {FTRA} {International} {Conference} on {Multimedia} and {Ubiquitous} {Engineering}},
  year      = {2011},
  pages     = {246--250},
  month     = jun,
  abstract  = {A recent national survey of Taiwanese students shows that their physical health condition has been worsening more than many other countries. In this study we examine use of a new learning system enhanced with augmented reality (AR) to address this growing global problem. In order to apply three different physical activities for the experiment the learners use their body language for interacting with the computer. In order to increase effectiveness of the AR system, we then combine students' academic achievement and their preferences for using the system. The experimental results from 419 students indicate much higher achievements in their academic work and gain significantly more those who come with their minds set for stronger challenging preferences in the seven subscales.},
  doi       = {10.1109/MUE.2011.51},
  keywords  = {augmented reality, computer aided instruction, body language, augmented reality learning environment, physical health condition, student academic achievement, Learning systems, Augmented reality, Educational institutions, Animation, Conferences, augmented reality, virtual reality, learning, education, preference},
}

@Article{Hsiao2011b,
  author   = {Hsiao, Kuei-Fang and Rashvand, Habib F},
  title    = {Integrating body language movements in augmented reality learning environment},
  journal  = {Human-centric Computing and Information Sciences},
  year     = {2011},
  volume   = {1},
  number   = {1},
  pages    = {1},
  issn     = {2192-1962},
  doi      = {10.1186/2192-1962-1-1},
  language = {en},
  url      = {http://hcis-journal.springeropen.com/articles/10.1186/2192-1962-1-1},
  urldate  = {2019-09-14},
}

@InProceedings{Kantonen2010,
  author    = {Kantonen, T. and Woodward, C. and Katz, N.},
  title     = {Mixed reality in virtual world teleconferencing},
  booktitle = {2010 {IEEE} {Virtual} {Reality} {Conference} ({VR})},
  year      = {2010},
  pages     = {179--182},
  month     = mar,
  abstract  = {In this paper we present a Mixed Reality (MR) teleconferencing application based on Second Life (SL) and the OpenSim virtual world. Augmented Reality (AR) techniques are used for displaying virtual avatars of remote meeting participants in real physical spaces, while Augmented Virtuality (AV), in form of video based gesture detection, enables capturing of human expressions to control avatars and to manipulate virtual objects in virtual worlds. The use of Second Life for creating a shared augmented space to represent different physical locations allows us to incorporate the application into existing infrastructure. The application is implemented using open source Second Life viewer, ARToolKit and OpenCV libraries.},
  doi       = {10.1109/VR.2010.5444792},
  keywords  = {augmented reality, avatars, teleconferencing, mixed reality, virtual world teleconferencing, second life, OpenSim virtual world, augmented reality, augmented virtuality, virtual avatars, video based gesture detection, Virtual reality, Teleconferencing, Second Life, Avatars, Augmented virtuality, Augmented reality, Video sharing, Object detection, Humans, Libraries, mixed reality, virtual worlds, Second Life, teleconferencing, immersive virtual environments, collaborative augmented reality},
}

@InProceedings{Konrad2003,
  author     = {Konrad, Tollmar and Demirdjian, David and Darrell, Trevor},
  title      = {Gesture + play: full-body interaction for virtual environments},
  booktitle  = {{CHI} '03 extended abstracts on {Human} factors in computing systems - {CHI} '03},
  year       = {2003},
  pages      = {620},
  address    = {Ft. Lauderdale, Florida, USA},
  publisher  = {ACM Press},
  doi        = {10.1145/765891.765894},
  isbn       = {9781581136371},
  language   = {en},
  shorttitle = {Gesture + play},
  url        = {http://portal.acm.org/citation.cfm?doid=765891.765894},
  urldate    = {2019-09-14},
}

@InProceedings{Toyama2014,
  author    = {Toyama, Takumi and Sonntag, Daniel and Dengel, Andreas and Matsuda, Takahiro and Iwamura, Masakazu and Kise, Koichi},
  title     = {A mixed reality head-mounted text translation system using eye gaze input},
  booktitle = {Proceedings of the 19th international conference on {Intelligent} {User} {Interfaces} - {IUI} '14},
  year      = {2014},
  pages     = {329--334},
  address   = {Haifa, Israel},
  publisher = {ACM Press},
  doi       = {10.1145/2557500.2557528},
  isbn      = {9781450321846},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2557500.2557528},
  urldate   = {2019-09-14},
}

@InProceedings{Rantala2014,
  author    = {Rantala, Jussi and Kangas, Jari and Akkil, Deepak and Isokoski, Poika and Raisamo, Roope},
  title     = {Glasses with haptic feedback of gaze gestures},
  booktitle = {Proceedings of the extended abstracts of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} {EA} '14},
  year      = {2014},
  pages     = {1597--1602},
  address   = {Toronto, Ontario, Canada},
  publisher = {ACM Press},
  doi       = {10.1145/2559206.2581163},
  isbn      = {9781450324748},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2559206.2581163},
  urldate   = {2019-09-14},
}

@InProceedings{Delamare2017,
  author    = {Delamare, William and Han, Teng and Irani, Pourang},
  title     = {Designing a gaze gesture guiding system},
  booktitle = {Proceedings of the 19th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services} - {MobileHCI} '17},
  year      = {2017},
  pages     = {1--13},
  address   = {Vienna, Austria},
  publisher = {ACM Press},
  doi       = {10.1145/3098279.3098561},
  isbn      = {9781450350754},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=3098279.3098561},
  urldate   = {2019-09-14},
}

@InCollection{Kangas2014,
  author    = {Kangas, Jari and Rantala, Jussi and Akkil, Deepak and Isokoski, Poika and Majaranta, Päivi and Raisamo, Roope},
  title     = {Delayed {Haptic} {Feedback} to {Gaze} {Gestures}},
  booktitle = {Haptics: {Neuroscience}, {Devices}, {Modeling}, and {Applications}},
  publisher = {Springer Berlin Heidelberg},
  year      = {2014},
  editor    = {Auvray, Malika and Duriez, Christian},
  volume    = {8618},
  pages     = {25--31},
  address   = {Berlin, Heidelberg},
  isbn      = {9783662441923 9783662441930},
  doi       = {10.1007/978-3-662-44193-0_4},
  url       = {http://link.springer.com/10.1007/978-3-662-44193-0_4},
  urldate   = {2019-09-14},
}

@InProceedings{Buchmann2004,
  author     = {Buchmann, Volkert and Violich, Stephen and Billinghurst, Mark and Cockburn, Andy},
  title      = {{FingARtips}: {Gesture} {Based} {Direct} {Manipulation} in {Augmented} {Reality}},
  booktitle  = {Proceedings of the 2Nd {International} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques} in {Australasia} and {South} {East} {Asia}},
  year       = {2004},
  series     = {{GRAPHITE} '04},
  pages      = {212--221},
  address    = {New York, NY, USA},
  publisher  = {ACM},
  note       = {event-place: Singapore},
  abstract   = {This paper presents a technique for natural, fingertip-based interaction with virtual objects in Augmented Reality (AR) environments. We use image processing software and finger- and hand-based fiducial markers to track gestures from the user, stencil buffering to enable the user to see their fingers at all times, and fingertip-based haptic feedback devices to enable the user to feel virtual objects. Unlike previous AR interfaces, this approach allows users to interact with virtual content using natural hand gestures. The paper describes how these techniques were applied in an urban planning interface, and also presents preliminary informal usability results.},
  doi        = {10.1145/988834.988871},
  isbn       = {9781581138832},
  keywords   = {Augmented Reality, gesture interaction, occlusion},
  shorttitle = {{FingARtips}},
  url        = {http://doi.acm.org/10.1145/988834.988871},
  urldate    = {2019-09-16},
}

@Article{Anderson2014,
  author  = {Anderson, Fraser and Bischof, Walter F.},
  title   = {Augmented reality improves myoelectric prosthesis training},
  journal = {International Journal on Disability and Human Development},
  year    = {2014},
  volume  = {13},
  number  = {3},
  month   = jan,
  issn    = {2191-0367, 2191-1231},
  doi     = {10.1515/ijdhd-2014-0327},
  url     = {https://www.degruyter.com/view/j/ijdhd.2014.13.issue-3/ijdhd-2014-0327/ijdhd-2014-0327.xml},
  urldate = {2019-09-14},
}

@InProceedings{Lamounier2010,
  author    = {Lamounier, E. and Lopes, K. and Cardoso, A. and Andrade, A. and Soares, A.},
  title     = {On the use of {Virtual} and {Augmented} {Reality} for upper limb prostheses training and simulation},
  booktitle = {2010 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology}},
  year      = {2010},
  pages     = {2451--2454},
  month     = aug,
  abstract  = {Accidents happen and unfortunately people may loose part of their body members. Studies have shown that in this case, most individuals suffer physically and psychologically. For this reason, actions to restore the patient's freedom and mobility are imperative. Traditional solutions require ways to adapt the individual to prosthetic devices. This idea is also applied to patients who have congenital limitations. However, one of the major difficulties faced by those who are fitted with these devices is the great mental effort needed during first stages of training. As a result, a meaningful number of patients give up the use of theses devices very soon. Thus, this article reports on a solution designed by the authors to help patients during the learning phases, without actually having to wear the prosthesis. This solution considers Virtual (VR) and Augmented Reality (AR) techniques to mimic the prosthesis natural counterparts. Thus, it is expected that problems such as weight, heat and pain should not contribute to an already hard task.},
  doi       = {10.1109/IEMBS.2010.5626370},
  keywords  = {augmented reality, medical computing, patient rehabilitation, prosthetics, virtual reality, virtual reality, augmented reality, upper limb prostheses training, upper limb prostheses simulation, prosthetic devices, congenital limitations, prosthetic natural counterpart mimicking, Electromyography, Augmented reality, Solid modeling, Prosthetics, Real time systems, Training, Algorithms, Amputation, Artificial Limbs, Biomechanics, Computer Simulation, Equipment Design, Humans, Monitoring, Ambulatory, Pain, Prosthesis Design, Signal Processing, Computer-Assisted, Upper Extremity},
}

@Article{Ortiz-Catalan2016,
  author     = {Ortiz-Catalan, Max and Guðmundsdóttir, Rannveig A and Kristoffersen, Morten B and Zepeda-Echavarria, Alejandra and Caine-Winterberger, Kerstin and Kulbacka-Ortiz, Katarzyna and Widehammar, Cathrine and Eriksson, Karin and Stockselius, Anita and Ragnö, Christina and Pihlar, Zdenka and Burger, Helena and Hermansson, Liselotte},
  title      = {Phantom motor execution facilitated by machine learning and augmented reality as treatment for phantom limb pain: a single group, clinical trial in patients with chronic intractable phantom limb pain},
  journal    = {The Lancet},
  year       = {2016},
  volume     = {388},
  number     = {10062},
  pages      = {2885--2894},
  month      = dec,
  issn       = {01406736},
  doi        = {10.1016/S0140-6736(16)31598-7},
  language   = {en},
  shorttitle = {Phantom motor execution facilitated by machine learning and augmented reality as treatment for phantom limb pain},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S0140673616315987},
  urldate    = {2019-09-14},
}

@Article{Ortiz-Catalan2014,
  author     = {Ortiz-Catalan, Max and Sander, Nichlas and Kristoffersen, Morten B. and Håkansson, Bo and Brånemark, Rickard},
  title      = {Treatment of phantom limb pain ({PLP}) based on augmented reality and gaming controlled by myoelectric pattern recognition: a case study of a chronic {PLP} patient},
  journal    = {Frontiers in Neuroscience},
  year       = {2014},
  volume     = {8},
  issn       = {1662-453X},
  doi        = {10.3389/fnins.2014.00024},
  shorttitle = {Treatment of phantom limb pain ({PLP}) based on augmented reality and gaming controlled by myoelectric pattern recognition},
  url        = {http://journal.frontiersin.org/article/10.3389/fnins.2014.00024/abstract},
  urldate    = {2019-09-14},
}

@Article{Berlier2018,
  author = {Berlier, Adam J and Brown, Bradford and Christovich, Timothy and Hester, Taylor and Koury, Brandon J and Monk, Cameron T and Woolford, Chadwick A},
  title  = {Integration of {Augmented} {Reality} and {Neuromuscular} {Control} {Systems} for {Remote} {Vehicle} {Operations}},
  year   = {2018},
}

@InProceedings{Woodward2017,
  author    = {Woodward, Richard B. and Cancio, Jill M. and Fisher, Robert and Hargrove, Levi J. and Rabago, Christopher A. and Siewiorek, Dan and Smailagic, Asim},
  title     = {A virtual coach for upper-extremity myoelectric prosthetic rehabilitation},
  booktitle = {2017 {International} {Conference} on {Virtual} {Rehabilitation} ({ICVR})},
  year      = {2017},
  pages     = {1--2},
  address   = {Montreal, QC, Canada},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/ICVR.2017.8007495},
  isbn      = {9781509030538},
  url       = {http://ieeexplore.ieee.org/document/8007495/},
  urldate   = {2019-09-14},
}

@Article{Roche2014,
  author     = {Roche, Aidan D. and Rehbaum, Hubertus and Farina, Dario and Aszmann, Oskar C.},
  title      = {Prosthetic {Myoelectric} {Control} {Strategies}: {A} {Clinical} {Perspective}},
  journal    = {Current Surgery Reports},
  year       = {2014},
  volume     = {2},
  number     = {3},
  pages      = {44},
  month      = mar,
  issn       = {2167-4817},
  doi        = {10.1007/s40137-013-0044-8},
  language   = {en},
  shorttitle = {Prosthetic {Myoelectric} {Control} {Strategies}},
  url        = {http://link.springer.com/10.1007/s40137-013-0044-8},
  urldate    = {2019-09-14},
}

@Article{Markovic2014,
  author  = {Markovic, Marko and Dosen, Strahinja and Cipriani, Christian and Popovic, Dejan and Farina, Dario},
  title   = {Stereovision and augmented reality for closed-loop control of grasping in hand prostheses},
  journal = {Journal of Neural Engineering},
  year    = {2014},
  volume  = {11},
  number  = {4},
  pages   = {046001},
  month   = aug,
  issn    = {1741-2560, 1741-2552},
  doi     = {10.1088/1741-2560/11/4/046001},
  url     = {http://stacks.iop.org/1741-2552/11/i=4/a=046001?key=crossref.920cc30034714dfe1da6df3291ab5200},
  urldate = {2019-09-14},
}

@Article{Soares2012,
  author     = {Soares, Alcimar Barbosa and Júnior, Edgard Afonso Lamounier and Andrade, Adriano de Oliveira and Cardoso, Alexandre},
  title      = {Virtual and {Augmented} {Reality}: {A} {New} {Approach} to {Aid} {Users} of {Myoelectric} {Prostheses}},
  journal    = {Computational Intelligence in Electromyography Analysis - A Perspective on Current Applications and Future Challenges},
  year       = {2012},
  month      = oct,
  abstract   = {Open access peer-reviewed chapter},
  doi        = {10.5772/50600},
  language   = {en},
  shorttitle = {Virtual and {Augmented} {Reality}},
  url        = {https://www.intechopen.com/books/computational-intelligence-in-electromyography-analysis-a-perspective-on-current-applications-and-future-challenges/virtual-and-augmented-reality-a-new-approach-to-aid-users-of-myoelectric-prostheses},
  urldate    = {2019-09-14},
}

@Article{Kenedy2013,
  author  = {Kenedy Lopes, Edgard Afonso Lamounier},
  title   = {Using {Augmented} {Reality} {Techniques} to {Simulate} {Myoelectric} {Upper} {Limb} {Prostheses}},
  journal = {Journal of Bioengineering and Biomedical Sciences},
  year    = {2013},
  issn    = {21559538},
  doi     = {10.4172/2155-9538.S1-010},
  url     = {https://www.omicsonline.org/using-augmented-reality-techniques-to-simulate-myoelectric-upper-limb-prostheses-2155-9538.S1-010.php?aid=4717},
  urldate = {2019-09-14},
}

@Article{Ninu2014,
  author     = {Ninu, Andrei and Dosen, Strahinja and Muceli, Silvia and Rattay, Frank and Dietl, Hans and Farina, Dario},
  title      = {Closed-{Loop} {Control} of {Grasping} {With} a {Myoelectric} {Hand} {Prosthesis}: {Which} {Are} the {Relevant} {Feedback} {Variables} for {Force} {Control}?},
  journal    = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year       = {2014},
  volume     = {22},
  number     = {5},
  pages      = {1041--1052},
  month      = sep,
  issn       = {1534-4320, 1558-0210},
  doi        = {10.1109/TNSRE.2014.2318431},
  shorttitle = {Closed-{Loop} {Control} of {Grasping} {With} a {Myoelectric} {Hand} {Prosthesis}},
  url        = {http://ieeexplore.ieee.org/document/6807741/},
  urldate    = {2019-09-14},
}

@InProceedings{Tabor2016,
  author    = {Tabor, Aaron and Bateman, Scott and Scheme, Erik},
  title     = {Game-{Based} {Myoelectric} {Training}},
  booktitle = {Proceedings of the 2016 {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play} {Companion} {Extended} {Abstracts} - {CHI} {PLAY} {Companion} '16},
  year      = {2016},
  pages     = {299--306},
  address   = {Austin, Texas, USA},
  publisher = {ACM Press},
  doi       = {10.1145/2968120.2987731},
  isbn      = {9781450344586},
  language  = {en},
  url       = {http://dl.acm.org/citation.cfm?doid=2968120.2987731},
  urldate   = {2019-09-14},
}

@Article{Clemente2017,
  author  = {Clemente, Francesco and Dosen, Strahinja and Lonini, Luca and Markovic, Marko and Farina, Dario and Cipriani, Christian},
  title   = {Humans {Can} {Integrate} {Augmented} {Reality} {Feedback} in {Their} {Sensorimotor} {Control} of a {Robotic} {Hand}},
  journal = {IEEE Transactions on Human-Machine Systems},
  year    = {2017},
  volume  = {47},
  number  = {4},
  pages   = {583--589},
  month   = aug,
  issn    = {2168-2291, 2168-2305},
  doi     = {10.1109/THMS.2016.2611998},
  url     = {http://ieeexplore.ieee.org/document/7588033/},
  urldate = {2019-09-14},
}

@Article{Markovic2017,
  author     = {Markovic, Marko and Karnal, Hemanth and Graimann, Bernhard and Farina, Dario and Dosen, Strahinja},
  title      = {{GLIMPSE}: {Google} {Glass} interface for sensory feedback in myoelectric hand prostheses},
  journal    = {Journal of Neural Engineering},
  year       = {2017},
  volume     = {14},
  number     = {3},
  pages      = {036007},
  month      = jun,
  issn       = {1741-2560, 1741-2552},
  doi        = {10.1088/1741-2552/aa620a},
  shorttitle = {{GLIMPSE}},
  url        = {http://stacks.iop.org/1741-2552/14/i=3/a=036007?key=crossref.5da5d68d8ce7f07868eef5b4347fcba5},
  urldate    = {2019-09-14},
}

@InProceedings{Boschmann2016,
  author    = {Boschmann, Alexander and Dosen, Strahinja and Werner, Andreas and Raies, Ali and Farina, Dario},
  title     = {A novel immersive augmented reality system for prosthesis training and assessment},
  booktitle = {2016 {IEEE}-{EMBS} {International} {Conference} on {Biomedical} and {Health} {Informatics} ({BHI})},
  year      = {2016},
  pages     = {280--283},
  address   = {Las Vegas, NV},
  month     = feb,
  publisher = {IEEE},
  doi       = {10.1109/BHI.2016.7455889},
  isbn      = {9781509024551},
  url       = {http://ieeexplore.ieee.org/document/7455889/},
  urldate   = {2019-09-14},
}

@InProceedings{Ban2013,
  author     = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
  title      = {Augmented endurance: controlling fatigue while handling objects by affecting weight perception using augmented reality},
  booktitle  = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
  year       = {2013},
  pages      = {69},
  address    = {Paris, France},
  publisher  = {ACM Press},
  doi        = {10.1145/2470654.2470665},
  isbn       = {9781450318990},
  language   = {en},
  shorttitle = {Augmented endurance},
  url        = {http://dl.acm.org/citation.cfm?doid=2470654.2470665},
  urldate    = {2019-09-14},
}

@InProceedings{Mohammed2017,
  author = {Si-Mohammed, Hakim and Argelaguet, Ferran and Casiez, Géry and Roussel, Nicolas and Lécuyer, Anatole},
  title  = {Brain-Computer Interfaces and Augmented Reality: A State of the Art},
  year   = {2017},
  month  = {09},
  doi    = {10.3217/978-3-85125-533-1-82},
}

@InProceedings{Higa2007,
  author    = {K. {Higa} and T. {Nishiura} and A. {Kimura} and F. {Shibata} and H. {Tamura}},
  title     = {A Two-by-Two Mixed Reality System That Merges Real and Virtual Worlds in Both Audio and Visual Senses},
  booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
  year      = {2007},
  pages     = {203-206},
  month     = {Nov},
  doi       = {10.1109/ISMAR.2007.4538847},
  keywords  = {virtual reality;two-by-two mixed reality system;virtual reality;geometric consistency;audio sense;closed-air headphones;Virtual reality;Headphones;Auditory displays;Real time systems;Optical sensors;Computer displays;Merging;Layout;Humans;Chromium;Mixed Reality;Audio and Visual Senses;Geometric Consistency;Open-Air Headphones;Closed-Air Headphones},
}

@Article{Zhou2008,
  author  = {Zhou, Feng and Duh, Henry and Billinghurst, Mark},
  title   = {Trends in Augmented Reality Tracking, Interaction and Display: A Review of Ten Years of ISMAR},
  journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
  year    = {2008},
  volume  = {2},
  pages   = {193-202},
  month   = {09},
  doi     = {10.1109/ISMAR.2008.4637362},
}

@InProceedings{Abbasi2019,
  author    = {R. {Abbasi-Asl} and M. {Keshavarzi} and D. Y. {Chan}},
  title     = {Brain-Computer Interface in Virtual Reality},
  booktitle = {2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)},
  year      = {2019},
  pages     = {1220-1224},
  month     = {March},
  doi       = {10.1109/NER.2019.8717158},
  keywords  = {biomedical electrodes;brain-computer interfaces;electroencephalography;handicapped aids;medical computing;medical signal processing;virtual reality;brain computer interface systems;virtual reality environments;2D regular displays;wearable electroencephalography device;VR headset;virtual interface;human subjects;object rotation;mental commands;smile;eyebrow movement;similar tasks;regular 2D monitor screens;VR settings;future BCI systems;virtual reality settings;time 1.0 min;Electroencephalography;Two dimensional displays;Virtual reality;Task analysis;Headphones;Eyebrows;Three-dimensional displays},
}

@InProceedings{Ranasinghe2012,
  author    = {N. {Ranasinghe} and R. {Nakatsu} and H. {Nii} and P. {Gopalakrishnakone}},
  title     = {Tongue Mounted Interface for Digitally Actuating the Sense of Taste},
  booktitle = {2012 16th International Symposium on Wearable Computers},
  year      = {2012},
  pages     = {80-87},
  month     = {June},
  doi       = {10.1109/ISWC.2012.16},
  keywords  = {biocontrol;chemioception;digital control;tongue mounted interface;sense of taste;taste sensations;electrical stimulation;thermal stimulation;digital control systems;tongue mounted digital taste interface;digital sour lollipop;human tongue;Tongue;Humans;Electrical stimulation;Computers;Chemicals;Electrodes;Control systems;Taste;Digital Taste;Gustation;User interfaces;Control systems;Virtual reality;Ubiquitous computing},
}

@Article{Kessler1995,
  author  = {Kessler, Gregory and Walker, Neff and Hodges, Larry},
  title   = {Evaluation of the CyberGlove(TM) as a Whole Hand Input Device},
  journal = {ACM Transactions on Computer-Human Interaction},
  year    = {1995},
  volume  = {2},
  month   = {12},
  doi     = {10.1145/212430.212431},
}

@InProceedings{Choi2017,
  author = {Choi, Inrak and Culbertson, Heather and Miller, Mark and Olwal, Alex and Follmer, Sean},
  title  = {Grabity: A Wearable Haptic Interface for Simulating Weight and Grasping in Virtual Reality},
  year   = {2017},
  pages  = {119-130},
  month  = {10},
  doi    = {10.1145/3126594.3126599},
}

@Article{Minamizawa2007,
  author = {Minamizawa, Kouta and Fukamachi, Souichiro and Kajimoto, Hiroyuki and Kawakami, Naoki and Tachi, Susumu},
  title  = {Gravity grabber: wearable haptic display to present virtual mass sensation},
  year   = {2007},
  pages  = {8},
  month  = {01},
  doi    = {10.1145/1278280.1278289},
  isbn   = {978-1-4503-1824-2},
}

@InProceedings{Moriyama2018,
  author = {Moriyama, Taha and Ayaka, Nishi and Nakamura, Takuto and Yem, Vibol and Kajimoto, Hiroyuk},
  title  = {Hap-link: wearable haptic device on the forearm that presents haptics sensations corresponding to the fingers},
  year   = {2018},
  pages  = {1-2},
  month  = {12},
  doi    = {10.1145/3275476.3275488},
}

@InProceedings{Hamza2019,
  author = {Hamza Lup, Felix and Bergeron, Kyle and Newton, Daniel},
  title  = {Haptic Systems in User Interfaces - State of the Art Survey},
  year   = {2019},
  month  = {03},
  doi    = {10.1145/3299815.3314445},
}

@InProceedings{Perret2018,
  author = {Perret, Jérôme and Vander Poorten, Emmanuel},
  title  = {Touching Virtual Reality: a Review of Haptic Gloves},
  year   = {2018},
  month  = {06},
}

@InProceedings{Gu2016,
  author = {Gu, Xiaochi and Zhang, Yifei and Sun, Weize and Bian, Yuanzhe and Zhou, Dao and Kristensson, Per},
  title  = {Dexmo: An Inexpensive and Lightweight Mechanical Exoskeleton for Motion Capture and Force Feedback in VR},
  year   = {2016},
  pages  = {1991-1995},
  month  = {05},
  doi    = {10.1145/2858036.2858487},
}

@InProceedings{Ahmed2015,
  author    = {L. {Ahmed} and S. {Hamdy} and D. {Hegazy} and T. {El-Arif}},
  title     = {Interaction techniques in mobile Augmented Reality: State-of-the-art},
  booktitle = {2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)},
  year      = {2015},
  pages     = {424-433},
  month     = {Dec},
  doi       = {10.1109/IntelCIS.2015.7397255},
  keywords  = {augmented reality;human computer interaction;mobile computing;interaction techniques;mobile augmented reality;intangible techniques;tangible techniques;Visualization;Rendering (computer graphics);Merging;Cameras;Tracking;Image segmentation;Mobile Augmented Reality;Tangible Interaction;Intagible Interaction},
}

@InProceedings{Gabardi2016,
  author    = {M. {Gabardi} and M. {Solazzi} and D. {Leonardis} and A. {Frisoli}},
  title     = {A new wearable fingertip haptic interface for the rendering of virtual shapes and surface features},
  booktitle = {2016 IEEE Haptics Symposium (HAPTICS)},
  year      = {2016},
  pages     = {140-146},
  month     = {April},
  doi       = {10.1109/HAPTICS.2016.7463168},
  keywords  = {haptic interfaces;rendering (computer graphics);wearable fingertip haptic interface;rendering;virtual shape;surface feature;Haptic Thimble;wearable haptic device;surface exploration;tactile feedback;reactive contact;surface asperities;serial kinematics;compact servo motor;voice coil;kinesthetic feedback;Haptic interfaces;Force;Actuators;Rendering (computer graphics);Kinematics;Surface texture;Performance evaluation},
}

@Article{Meli2018,
  author   = {L. {Meli} and I. {Hussain} and M. {Aurilio} and M. {Malvezzi} and M. K. {O’Malley} and D. {Prattichizzo}},
  title    = {The hBracelet: A Wearable Haptic Device for the Distributed Mechanotactile Stimulation of the Upper Limb},
  journal  = {IEEE Robotics and Automation Letters},
  year     = {2018},
  volume   = {3},
  number   = {3},
  pages    = {2198-2205},
  month    = {July},
  doi      = {10.1109/LRA.2018.2810958},
  keywords = {haptic interfaces;medical computing;virtual reality;robotic manipulators;human body;virtual environment interactions;remote environment interactions;upper limb;distributed mechanotactile stimulation;belt presses;control strategies;wearable haptic display;haptic interface;body area;hBracelet;wearable haptic device;mechatronic devices;tactile sensations;haptic stimuli;linear actuator;servoactuators;wearable skin;wearable solutions;Actuators;Belts;Haptic interfaces;Force;Robots;Skin;Pulleys;Haptics and haptic interfaces;wearable robots;human-centered robotics;telerobotics and teleoperation},
}

@Article{Rizzo2017,
  author  = {Rizzo, Rocco and Musolino, Antonino and Jones, Lynette},
  title   = {Shape Localization and Recognition Using a Magnetorheological-Fluid Haptic Display},
  journal = {IEEE Transactions on Haptics},
  year    = {2017},
  volume  = {PP},
  pages   = {1-1},
  month   = {11},
  doi     = {10.1109/TOH.2017.2771420},
}

@InProceedings{Nojima2002,
  author    = {T. {Nojima} and D. {Sekiguchi} and M. {Inami} and S. {Tachi}},
  title     = {The SmartTool: a system for augmented reality of haptics},
  booktitle = {Proceedings IEEE Virtual Reality 2002},
  year      = {2002},
  pages     = {67-72},
  month     = {March},
  doi       = {10.1109/VR.2002.996506},
  keywords  = {augmented reality;haptic interfaces;augmented reality;haptics;haptic sensation;SmartTool;real environment;time sensor;haptic display;prototype system;Augmented reality;Haptic interfaces;Humans;Displays;Surgery;Navigation;Cameras;Acoustics;Real time systems;Machine vision},
}

@Article{Pacchierotti2017,
  author   = {C. {Pacchierotti} and S. {Sinclair} and M. {Solazzi} and A. {Frisoli} and V. {Hayward} and D. {Prattichizzo}},
  title    = {Wearable Haptic Systems for the Fingertip and the Hand: Taxonomy, Review, and Perspectives},
  journal  = {IEEE Transactions on Haptics},
  year     = {2017},
  volume   = {10},
  number   = {4},
  pages    = {580-600},
  month    = {Oct},
  doi      = {10.1109/TOH.2017.2689006},
  keywords = {haptic interfaces;representative wearable haptic systems;fingertip;taxonomy;wearable haptic interfaces;wearability challenges;technological design;hand haptic system;Haptic interfaces;Robots;Exoskeletons;Wearable computing;Vibrations;Force feedback;Taxonomy;Haptic interfaces;Wearable haptics;fingertip haptics;hand exoskeletons;wearable devices;wearable interfaces;cutaneous force feedback;tactile force feedback;taxonomy;review;Feedback;Hand;Humans;Physical Stimulation;Touch;Wearable Electronic Devices},
}

@InProceedings{Ranasinghe2013,
  author = {Ranasinghe, Nimesha and Cheok, Adrian and Nakatsu, Ryohei and Do, Ellen},
  title  = {Simulating the sensation of taste for immersive experiences},
  year   = {2013},
  pages  = {29-34},
  month  = {10},
  doi    = {10.1145/2512142.2512148},
}

@Article{Jacks2003,
  author  = {Jacks, A and Miller, N},
  title   = {Spontaneous retinal venous pulsation: Aetiology and significance},
  journal = {Journal of neurology, neurosurgery, and psychiatry},
  year    = {2003},
  volume  = {74},
  pages   = {7-9},
  month   = {02},
  doi     = {10.1136/jnnp.74.1.7},
}

@Article{Zander2011,
  author  = {Zander, Thorsten and Kothe, Christian},
  title   = {Towards passive Brain–Computer interfaces: applying Brain–Computer interface technology to human-machine systems in general},
  journal = {Journal of neural engineering},
  year    = {2011},
  volume  = {8},
  pages   = {025005},
  month   = {03},
  doi     = {10.1088/1741-2560/8/2/025005},
}

@Article{Jeon2009,
  author  = {S. {Jeon} and S. {Choi}},
  title   = {Haptic Augmented Reality: Taxonomy and an Example of Stiffness Modulation},
  journal = {Presence},
  year    = {2009},
  volume  = {18},
  number  = {5},
  pages   = {387-408},
  month   = {Oct},
  doi     = {10.1162/pres.18.5.387},
}

@InProceedings{Milgram1993,
  author  = {Milgram, Paul and Zhai, Shumin and Drascic, David and Grodski, J.},
  title   = {Applications of augmented reality for human-robot communication},
  year    = {1993},
  pages   = {1467 - 1472 vol.3},
  month   = {08},
  doi     = {10.1109/IROS.1993.583833},
  isbn    = {0-7803-0823-9},
  journal = {Journal of Intelligent and Robotic Systems - JIRS},
}

@InProceedings{Billinghurst2009,
  author  = {Billinghurst, Mark and Kato, Hirokazu and Myojin, Seiko},
  title   = {Advanced Interaction Techniques for Augmented Reality Applications},
  year    = {2009},
  volume  = {5622},
  pages   = {13-22},
  month   = {07},
  doi     = {10.1007/978-3-642-02771-0_2},
  journal = {Lecture Notes in Computer Science},
}

@InBook{Margallo2010,
  pages   = {121-128},
  title   = {Ergonomic Assessment of Hand Movements in Laparoscopic Surgery Using the CyberGlove®},
  year    = {2010},
  author  = {Sánchez Margallo, Francisco and Sánchez-Margallo, Juan A. and Pagador, J Blas and Moyano, José and Moreno_del_Pozo, José and Usón, Jesús},
  month   = {01},
  doi     = {10.1007/978-1-4419-5874-7_13},
  journal = {Computational Biomechanics for Medicine},
}

@Article{Wang2019,
  author  = {Wang, Dangxiao and Guo, Yuan and Liu, Shiyi and Zhang, Yuru and Xu, Weiliang and Xiao, Jing},
  title   = {Haptic display for virtual reality: progress and challenges},
  journal = {Virtual Reality \& Intelligent Hardware},
  year    = {2019},
  volume  = {1},
  month   = {04},
  doi     = {10.3724/SP.J.2096-5796.2019.0008},
}

@InProceedings{Marwecki2018,
  author = {Marwecki, Sebastian and Brehm, Maximilian and Wagner, Lukas and Cheng, Lung-Pan and Mueller, Florian and Baudisch, Patrick},
  title  = {VirtualSpace - Overloading Physical Space with Multiple Virtual Reality Users},
  year   = {2018},
  pages  = {1-10},
  month  = {04},
  doi    = {10.1145/3173574.3173815},
}

@InProceedings{Lopes2018,
  author    = {Lopes, Pedro and You, Sijing and Ion, Alexandra and Baudisch, Patrick},
  title     = {Adding Force Feedback to Mixed Reality Experiences and Games Using Electrical Muscle Stimulation},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {446:1--446:13},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3174020},
  articleno = {446},
  doi       = {10.1145/3173574.3174020},
  isbn      = {978-1-4503-5620-6},
  keywords  = {ar, augmented reality, body i/o, electrical muscle stimulation, haptics, hololens, mixed reality, mr, wearable},
  location  = {Montreal QC, Canada},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/3173574.3174020},
}

@InProceedings{Rietzler2018,
  author    = {Rietzler, Michael and Geiselhart, Florian and Frommel, Julian and Rukzio, Enrico},
  title     = {Conveying the Perception of Kinesthetic Feedback in Virtual Reality Using State-of-the-Art Hardware},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {460:1--460:13},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3174034},
  articleno = {460},
  doi       = {10.1145/3173574.3174034},
  isbn      = {978-1-4503-5620-6},
  keywords  = {kinesthetic feedback, pseudo haptics, virtual reality},
  location  = {Montreal QC, Canada},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/3173574.3174034},
}

@InProceedings{Zhao2018,
  author    = {Zhao, Yuhang and Bennett, Cynthia L. and Benko, Hrvoje and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Sinclair, Mike},
  title     = {Enabling People with Visual Impairments to Navigate Virtual Reality with a Haptic and Auditory Cane Simulation},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {116:1--116:14},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173690},
  articleno = {116},
  doi       = {10.1145/3173574.3173690},
  isbn      = {978-1-4503-5620-6},
  keywords  = {auditory feedback, blindness, haptic feedback, mobility, virtual reality, visual impairments, white cane},
  location  = {Montreal QC, Canada},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/3173574.3173690},
}

@InProceedings{Yan2018,
  author    = {Yan, Yukang and Yu, Chun and Ma, Xiaojuan and Huang, Shuai and Iqbal, Hasan and Shi, Yuanchun},
  title     = {Eyes-Free Target Acquisition in Interaction Space Around the Body for Virtual Reality},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {42:1--42:13},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173616},
  articleno = {42},
  doi       = {10.1145/3173574.3173616},
  isbn      = {978-1-4503-5620-6},
  keywords  = {eyes-free, proprioception, target acquisition, virtual reality},
  location  = {Montreal QC, Canada},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/3173574.3173616},
}

@InProceedings{Vovk2018,
  author    = {Vovk, Alla and Wild, Fridolin and Guest, Will and Kuula, Timo},
  title     = {Simulator Sickness in Augmented Reality Training Using the Microsoft HoloLens},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {209:1--209:9},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173783},
  articleno = {209},
  doi       = {10.1145/3173574.3173783},
  isbn      = {978-1-4503-5620-6},
  keywords  = {augmented reality, microsoft hololens, motion sickness, simulator sickness},
  location  = {Montreal QC, Canada},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/3173574.3173783},
}

@InProceedings{Albouys2018,
  author    = {Albouys-Perrois, J{\'e}r{\'e}my and Laviole, J{\'e}r{\'e}my and Briant, Carine and Brock, Anke M.},
  title     = {Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: A Participatory Design Approach},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {629:1--629:14},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3174203},
  articleno = {629},
  doi       = {10.1145/3173574.3174203},
  isbn      = {978-1-4503-5620-6},
  keywords  = {accessibility, augmented reality, geographic maps, participatory design, visual impairment},
  location  = {Montreal QC, Canada},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/3173574.3174203},
}

@InProceedings{Dillman2018,
  author    = {Dillman, Kody R. and Mok, Terrance Tin Hoi and Tang, Anthony and Oehlberg, Lora and Mitchell, Alex},
  title     = {A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {140:1--140:12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173714},
  articleno = {140},
  doi       = {10.1145/3173574.3173714},
  isbn      = {978-1-4503-5620-6},
  keywords  = {augmented reality, game design, guidance, interaction cues},
  location  = {Montreal QC, Canada},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3173574.3173714},
}

@InProceedings{Sra2018,
  author    = {Sra, Misha and Xu, Xuhai and Maes, Pattie},
  title     = {BreathVR: Leveraging Breathing As a Directly Controlled Interface for Virtual Reality Games},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {340:1--340:12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173914},
  articleno = {340},
  doi       = {10.1145/3173574.3173914},
  isbn      = {978-1-4503-5620-6},
  keywords  = {breathing actions, game design, physiological control, virtual reality},
  location  = {Montreal QC, Canada},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3173574.3173914},
}

@InProceedings{Huang2018,
  author = {Huang, Yu-Hsuan and Chang, Hao-Yu and Yang, Wan-ling and Chiu, Yu-Kai and Yu, Tzu-Chieh and Tsai, Pei-Hsuan and Ouhyoung, Ming},
  title  = {CatAR: A Novel Stereoscopic Augmented Reality Cataract Surgery Training System with Dexterous Instruments Tracking Technology},
  year   = {2018},
  pages  = {1-12},
  month  = {04},
  doi    = {10.1145/3173574.3174039},
}

@InProceedings{Gugenheimer2018,
  author = {Gugenheimer, Jan and Stemasov, Evgeny and Sareen, Harpreet and Rukzio, Enrico},
  title  = {FaceDisplay: Towards Asymmetric Multi-User Interaction for Nomadic Virtual Reality},
  year   = {2018},
  pages  = {1-13},
  month  = {04},
  doi    = {10.1145/3173574.3173628},
}

@InProceedings{Strasnick2018,
  author = {Strasnick, Evan and Holz, Christian and Ofek, Eyal and Sinclair, Michael and Benko, Hrvoje},
  title  = {Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation},
  year   = {2018},
  pages  = {1-12},
  month  = {04},
  doi    = {10.1145/3173574.3174218},
}

@InProceedings{Whitmire2018,
  author = {Whitmire, Eric and Benko, Hrvoje and Holz, Christian and Ofek, Eyal and Sinclair, Michael},
  title  = {Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfigurable Virtual Reality Controller},
  year   = {2018},
  pages  = {1-12},
  month  = {04},
  doi    = {10.1145/3173574.3173660},
}

@InProceedings{Cheng2018,
  author = {Cheng, Lung-Pan and Chang, Li and Marwecki, Sebastian and Baudisch, Patrick},
  title  = {iTurk: Turning Passive Haptics into Active Haptics by Making Users Reconfigure Props in Virtual Reality},
  year   = {2018},
  pages  = {1-10},
  month  = {04},
  doi    = {10.1145/3173574.3173663},
}

@InProceedings{Gweon2018,
  author    = {Gweon, Gahgene and Kim, Bugeun and Kim, Jinyoung and Lee, Kung Jin and Rhim, Jungwook and Choi, Jueun},
  title     = {MABLE: Mediating Young Children's Smart Media Usage with Augmented Reality},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {13:1--13:9},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173587},
  articleno = {13},
  doi       = {10.1145/3173574.3173587},
  isbn      = {978-1-4503-5620-6},
  keywords  = {augmented reality (ar), engagement, parental medi-ation, preschoolers, rule compliance, smart media usage},
  location  = {Montreal QC, Canada},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/3173574.3173587},
}

@InProceedings{Nebeling2018,
  author    = {Nebeling, Michael and Nebeling, Janet and Yu, Ao and Rumble, Rob},
  title     = {ProtoAR: Rapid Physical-Digital Prototyping of Mobile Augmented Reality Applications},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  year      = {2018},
  series    = {CHI '18},
  pages     = {353:1--353:12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3173927},
  articleno = {353},
  doi       = {10.1145/3173574.3173927},
  isbn      = {978-1-4503-5620-6},
  keywords  = {mobile augmented reality, physical-digital prototyping, quasi-3d 360-degree captures},
  location  = {Montreal QC, Canada},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3173574.3173927},
}

@InProceedings{Lindlbauer2018,
  author = {Lindlbauer, David and Wilson, Andy},
  title  = {Remixed Reality: Manipulating Space and Time in Augmented Reality},
  year   = {2018},
  pages  = {1-13},
  month  = {04},
  doi    = {10.1145/3173574.3173703},
}

@InProceedings{Poyade2017,
  author = {Poyade, Matthieu and Morris, Glyn and Taylor, Ian and Portela, Victor},
  title  = {Using mobile virtual reality to empower people with hidden disabilities to overcome their barriers},
  year   = {2017},
  pages  = {504-505},
  month  = {11},
  doi    = {10.1145/3136755.3143025},
}

@InProceedings{Tiefenbacher2014,
  author = {Tiefenbacher, Philipp and Wichert, Steven and Merget, Daniel and Rigoll, Gerhard},
  title  = {Impact of Coordinate Systems on 3D Manipulations in Mobile Augmented Reality},
  year   = {2014},
  pages  = {435-438},
  month  = {11},
  doi    = {10.1145/2663204.2663234},
}

@InProceedings{Hurst2016,
  author    = {H\"{u}rst, Wolfgang and Iwai, Daisuke and Balakrishnan, Prabhakaran},
  title     = {International Workshop on Multimodal Virtual and Augmented Reality (Workshop Summary)},
  booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year      = {2016},
  series    = {ICMI '16},
  pages     = {596--597},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3007631},
  doi       = {10.1145/2993148.3007631},
  isbn      = {978-1-4503-4556-9},
  keywords  = {Multimodal virtual reality, multimodal augmented reality, multimodal mixed reality},
  location  = {Tokyo, Japan},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2993148.3007631},
}

@InProceedings{Joachimczak2017,
  author = {Joachimczak, Michał and Liu, Juan and Ando, Hiroshi},
  title  = {Real-time mixed-reality telepresence via 3D reconstruction with HoloLens and commodity depth sensors},
  year   = {2017},
  pages  = {514-515},
  month  = {11},
  doi    = {10.1145/3136755.3143031},
}

@InProceedings{Mavridou2018,
  author = {Mavridou, Ifigeneia and Seiss, Ellen and Kostoulas, Theodoros and Nduka, Charles and Balaguer-Ballester, Emili},
  title  = {Towards an effective arousal detection system for virtual reality},
  year   = {2018},
  pages  = {1-6},
  month  = {10},
  doi    = {10.1145/3279963.3279969},
}

@InProceedings{Hirshfield2018,
  author    = {Hirshfield, Leanne and Williams, Tom and Sommer, Natalie and Grant, Trevor and Gursoy, Senem Velipasalar},
  title     = {Workload-driven Modulation of Mixed-reality Robot-human Communication},
  booktitle = {Proceedings of the Workshop on Modeling Cognitive Processes from Multimodal Data},
  year      = {2016},
  series    = {MCPMD '18},
  pages     = {3:1--3:8},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3279848},
  articleno = {3},
  doi       = {10.1145/3279810.3279848},
  isbn      = {978-1-4503-6072-2},
  location  = {Boulder, Colorado},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/3279810.3279848},
}

@Article{Wen2014,
  author   = {Wen, Rong and Tay, Wei-Liang and Nguyen, Binh P. and Chng, Chin-Boon and Chui, Chee-Kong},
  title    = {Hand gesture guided robot-assisted surgery based on a direct augmented reality interface},
  journal  = {Computer Methods and Programs in Biomedicine},
  year     = {2014},
  volume   = {116},
  number   = {2},
  pages    = {68--80},
  month    = sep,
  issn     = {01692607},
  doi      = {10.1016/j.cmpb.2013.12.018},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0169260713004082},
  urldate  = {2019-09-20},
}

@InProceedings{White2007,
  author    = {White, Sean and Lister, Levi and Feiner, Steven},
  title     = {Visual {Hints} for {Tangible} {Gestures} in {Augmented} {Reality}},
  booktitle = {Proceedings of the 2007 6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
  year      = {2007},
  series    = {{ISMAR} '07},
  pages     = {1--4},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract  = {Tangible Augmented Reality (AR) systems imbue physical objects with the ability to act and respond in new ways. In particular, physical objects and gestures made with them gain meaning that does not exist outside the tangible AR environment. The existence of this new set of possible actions and outcomes is not always apparent, making it necessary to learn new movements or gestures. Addressing this opportunity, we present visual hints, which are graphical representations in AR of potential actions and their consequences in the augmented physical world. Visual hints enable discovery, learning, and completion of gestures and manipulation in tangible AR. Here, we discuss our investigation of a variety of representations of visual hints and methods for activating them. We then describe a specific implementation that supports gestures developed for a tangible AR user interface to an electronic field guide for botanists, and present results from a pilot study.},
  doi       = {10.1109/ISMAR.2007.4538824},
  isbn      = {9781424417490},
  url       = {https://doi.org/10.1109/ISMAR.2007.4538824},
  urldate   = {2019-09-20},
}

@Article{Lee2010,
  author   = {Lee, Jae Yeol and Rhee, Gue Won and Seo, Dong Woo},
  title    = {Hand gesture-based tangible interactions for manipulating virtual objects in a mixed reality environment},
  journal  = {The International Journal of Advanced Manufacturing Technology},
  year     = {2010},
  volume   = {51},
  number   = {9-12},
  pages    = {1069--1082},
  month    = dec,
  issn     = {0268-3768, 1433-3015},
  doi      = {10.1007/s00170-010-2671-x},
  language = {en},
  url      = {http://link.springer.com/10.1007/s00170-010-2671-x},
  urldate  = {2019-09-20},
}

@Article{Hossein2013,
  author    = {Hossein, Mousavi Hondori and Maryam, Khademi and Lucy, Dodakian and C, Cramer Steven and Videira, Lopes Cristina},
  title     = {A {Spatial} {Augmented} {Reality} {Rehab} {System} for {Post}-{Stroke} {Hand} {Rehabilitation}},
  journal   = {Studies in Health Technology and Informatics},
  year      = {2013},
  pages     = {279--285},
  issn      = {0926-9630},
  abstract  = {This paper features a Spatial Augmented Reality system for rehabilitation of hand and arm movement. The table-top home-based system tracks a subject's hand and creates a virtual audio-visual interface for performing rehabilitation-related tasks that involve wrist, elbow, and shoulder movements. It measures range, speed, and smoothness of movements locally and can send the real-time photos and data to the clinic for further assessment. To evaluate the system, it was tested on two normal subjects and proved functional.},
  copyright = {©2013 \&copy; The authors and IOS Press. All rights reserved.},
  doi       = {10.3233/978-1-61499-209-7-279},
  url       = {http://www.medra.org/servlet/aliasResolver?alias=iospressISSNISBN&issn=0926-9630&volume=184&spage=279},
  urldate   = {2019-09-20},
}

@Article{Escolano2012,
  author  = {Escolano, C. and Antelis, J. M. and Minguez, J.},
  title   = {A {Telepresence} {Mobile} {Robot} {Controlled} {With} a {Noninvasive} {Brain}–{Computer} {Interface}},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  year    = {2012},
  volume  = {42},
  number  = {3},
  pages   = {793--804},
  month   = jun,
  issn    = {1083-4419, 1941-0492},
  doi     = {10.1109/TSMCB.2011.2177968},
  url     = {http://ieeexplore.ieee.org/document/6104414/},
  urldate = {2019-09-20},
}

@Article{Kerruish2019,
  author     = {Kerruish, Erika},
  title      = {Arranging sensations: smell and taste in augmented and virtual reality},
  journal    = {The Senses and Society},
  year       = {2019},
  volume     = {14},
  number     = {1},
  pages      = {31--45},
  month      = jan,
  issn       = {1745-8927},
  abstract   = {The development of digital taste and smell underscores the importance of cultural dimensions of bodily perception in augmented reality (AR) and virtual reality (VR) devices. This can be seen in Vocktail and Season Traveller, two digital devices incorporating taste and smell. Vocktail is an AR technology that augments the experience of drinking water, or even air, through the electrical stimulation of tastebuds and the manipulation of color and smell. Season Traveller is a VR game in which the user moves through four seasonal landscapes. It uses wind, odor, and temperature in addition to the more standard audio-visual displays. The cultural dimensions of these devices can be examined using phenomenological terms. They instigate perceptual circuits, and call on and create sedimented habits. Although VR and AR are often thought of in terms of their similitude to reality, understanding Vocktail and Season Traveller this way illustrates the world-creating dimension of multisensory devices. These technologies structure and shift thresholds of taste and smell, reworking past perceptual styles and habits to develop new perceptual experiences. In so doing, Season Traveller and Vocktail throw to the fore questions about the conditions according to which people exercise their senses in digitally dominated environments.},
  doi        = {10.1080/17458927.2018.1556952},
  keywords   = {Taste, smell, postphenomenology, augmented reality, virtual reality, multisensory computing},
  shorttitle = {Arranging sensations},
  url        = {https://doi.org/10.1080/17458927.2018.1556952},
  urldate    = {2019-09-20},
}

@InProceedings{Barresi2015,
  author    = {Barresi, Giacinto and Olivieri, Emidio and Caldwell, Darwin G. and Mattos, Leonardo S.},
  title     = {Brain-{Controlled} {AR} {Feedback} {Design} for {User}'s {Training} in {Surgical} {HRI}},
  booktitle = {2015 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
  year      = {2015},
  pages     = {1116--1121},
  address   = {Kowloon Tong, Hong Kong},
  month     = oct,
  publisher = {IEEE},
  doi       = {10.1109/SMC.2015.200},
  isbn      = {9781479986972},
  url       = {http://ieeexplore.ieee.org/document/7379332/},
  urldate   = {2019-09-20},
}

@InProceedings{Hasan2012,
  author     = {Hasan, H. S. and Kareem, S. A.},
  title      = {Human {Computer} {Interaction} for {Vision} {Based} {Hand} {Gesture} {Recognition}: {A} {Survey}},
  booktitle  = {2012 {International} {Conference} on {Advanced} {Computer} {Science} {Applications} and {Technologies} ({ACSAT})},
  year       = {2012},
  pages      = {55--60},
  month      = nov,
  abstract   = {The ultimate aim is to bring Human Computer Interaction to a regime where interactions with computers will be as natural as an interaction between humans, and to this end, incorporating gestures in HCI is an important research area. Gestures have long been considered as an interaction technique that can potentially deliver more natural, creative and intuitive methods for communicating with our computers. This paper provides a summary of previous surveys done in this area and focuses on the different application domain which employs hand gestures for efficient interaction. The use of hand gestures as a natural interface serves as a motivating force for research in gesture taxonomies, its representations and recognition techniques. Also provides an analysis of existing literature related to gesture recognition systems for human computer interaction by categorizing it based on different parameters. The main goal of this survey is to provide researchers in the field with a summary of progress achieved to date and to help identify areas where further research is needed.},
  doi        = {10.1109/ACSAT.2012.37},
  keywords   = {computer vision, gesture recognition, human computer interaction, human computer interaction, vision based hand gesture recognition, HCI, intuitive method, natural interface, gesture taxonomy, Human-Computer Interaction, Gesture recognition, human computer interaction, representations, recognition, natural interfaces},
  shorttitle = {Human {Computer} {Interaction} for {Vision} {Based} {Hand} {Gesture} {Recognition}},
}

@Article{Kolsch2006,
  author   = {Kolsch, M. and Bane, R. and Hollerer, T. and Turk, M.},
  title    = {Multimodal interaction with a wearable augmented reality system},
  journal  = {IEEE Computer Graphics and Applications},
  year     = {2006},
  volume   = {26},
  number   = {3},
  pages    = {62--71},
  month    = may,
  abstract = {An augmented reality system enhances a mobile user's situational awareness and provides new visualization functionality. The custom-built multimodal interface provides access to information encountered in urban environments. In this article, we detail our experiences with various input devices and modalities and discuss their advantages and drawbacks in the context of interaction tasks in mobile computing. We show how we integrated the input channels to use the modalities beneficially and how this enhances the interface's overall usability},
  doi      = {10.1109/MCG.2006.66},
  keywords = {augmented reality, data visualisation, mobile computing, user interfaces, multimodal interaction, wearable augmented reality system, situational awareness, visualization functionality, custom-built multimodal interface, urban environment, mobile computing, Augmented reality, Buildings, Filters, Visualization, Temperature, Clouds, Fingers, Computer displays, Cities and towns, Information filtering, augmented reality, wearable computing, multimodal interface, hand-gesture recognition, information visualization, Clothing, Computer Peripherals, Data Display, Equipment Design, Equipment Failure Analysis, Multimedia, Signal Processing, Computer-Assisted, Systems Integration, User-Computer Interface},
}

@InProceedings{Kaiser2003,
  author    = {Kaiser, Ed and Olwal, Alex and McGee, David and Benko, Hrvoje and Corradini, Andrea and Li, Xiaoguang and Cohen, Phil and Feiner, Steven},
  title     = {Mutual {Disambiguation} of 3D {Multimodal} {Interaction} in {Augmented} and {Virtual} {Reality}},
  booktitle = {Proceedings of the 5th {International} {Conference} on {Multimodal} {Interfaces}},
  year      = {2003},
  series    = {{ICMI} '03},
  pages     = {12--19},
  address   = {New York, NY, USA},
  publisher = {ACM},
  note      = {event-place: Vancouver, British Columbia, Canada},
  abstract  = {We describe an approach to 3D multimodal interaction in immersive augmented and virtual reality environments that accounts for the uncertain nature of the information sources. The resulting multimodal system fuses symbolic and statistical information from a set of 3D gesture, spoken language, and referential agents. The referential agents employ visible or invisible volumes that can be attached to 3D trackers in the environment, and which use a time-stamped history of the objects that intersect them to derive statistics for ranking potential referents. We discuss the means by which the system supports mutual disambiguation of these modalities and information sources, and show through a user study how mutual disambiguation accounts for over 45\% of the successful 3D multimodal interpretations. An accompanying video demonstrates the system in action.},
  doi       = {10.1145/958432.958438},
  isbn      = {9781581136210},
  keywords  = {augmented/virtual reality, evaluation, multimodal interaction},
  url       = {http://doi.acm.org/10.1145/958432.958438},
  urldate   = {2019-09-20},
}

@InProceedings{Petit2014,
  author    = {Petit, D. and Gergondet, P. and Cherubini, A. and Meilland, M. and Comport, A. I. and Kheddar, A.},
  title     = {Navigation assistance for a {BCI}-controlled humanoid robot},
  booktitle = {The 4th {Annual} {IEEE} {International} {Conference} on {Cyber} {Technology} in {Automation}, {Control} and {Intelligent}},
  year      = {2014},
  pages     = {246--251},
  month     = jun,
  abstract  = {We present an assisted navigation scheme designed to control a humanoid robot via a brain computer interface in order to let it interact with the environment and with humans. The interface is based on the well-known steady-state visually evoked potentials (SSVEP) and the stimuli are integrated into the live feedback from the robot embedded camera displayed on a Head Mounted Display (HMD). One user controlled the HRP-2 humanoid robot in an experiment designed to measure the performance of the new navigation scheme based on visual SLAM feedback. The new navigation scheme performance is tested in an experience where the user is asked to navigate to a certain location in order to perform a task. It results that without the navigation assistance it is much more difficult to reach the appropriate pose for performing the task. The detailed results of the experiments are reported in this paper, and we discuss the possible improvements of our novel scheme.},
  doi       = {10.1109/CYBER.2014.6917469},
  keywords  = {brain-computer interfaces, cameras, control engineering computing, feedback, helmet mounted displays, humanoid robots, human-robot interaction, mobile robots, path planning, robot vision, SLAM (robots), visual evoked potentials, BCI-controlled humanoid robot, assisted navigation scheme, brain computer interface, environment interaction, human interaction, steady-state visually evoked potentials, SSVEP, stimuli, live feedback, robot embedded camera, head mounted display, HMD, HRP-2 humanoid robot, navigation scheme performance, visual SLAM feedback, navigation assistance, Navigation, Collision avoidance, Humanoid robots, Cameras, Robot vision systems, Manuals},
}

@InCollection{Sardo2018,
  author    = {Sardo, J. D. P. and Semião, J. and Monteiro, J. M. and Pereira, João A. R. and de Freitas, Marco A. G. and Esteves, E. and Rodrigues, João M. F.},
  title     = {Portable {Device} for {Touch}, {Taste} and {Smell} {Sensations} in {Augmented} {Reality} {Experiences}},
  booktitle = {{INCREaSE}},
  publisher = {Springer International Publishing},
  year      = {2018},
  editor    = {Mortal, António and Aníbal, Jaime and Monteiro, Jânio and Sequeira, Cláudia and Semião, Jorge and Moreira da Silva, Manuela and Oliveira, Miguel},
  pages     = {305--320},
  address   = {Cham},
  isbn      = {9783319702711 9783319702728},
  doi       = {10.1007/978-3-319-70272-8_26},
  language  = {en},
  url       = {http://link.springer.com/10.1007/978-3-319-70272-8_26},
  urldate   = {2019-09-20},
}

@InProceedings{Olwal2003,
  author     = {Olwal, A. and Benko, H. and Feiner, S.},
  title      = {{SenseShapes}: using statistical geometry for object selection in a multimodal augmented reality},
  booktitle  = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
  year       = {2003},
  pages      = {300--301},
  address    = {Tokyo, Japan},
  publisher  = {IEEE Comput. Soc},
  doi        = {10.1109/ISMAR.2003.1240730},
  isbn       = {9780769520063},
  shorttitle = {{SenseShapes}},
  url        = {http://ieeexplore.ieee.org/document/1240730/},
  urldate    = {2019-09-20},
}

@InProceedings{Tuceryan2000,
  author    = {Tuceryan, M. and Navab, N.},
  title     = {Single point active alignment method ({SPAAM}) for optical see-through {HMD} calibration for {AR}},
  booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality} ({ISAR} 2000)},
  year      = {2000},
  pages     = {149--158},
  month     = oct,
  abstract  = {Augmented reality (AR) is a technology in which a user's view of the real world is enhanced or augmented with additional information generated from a computer model. In order to have a working AR system, the see-through display system must be calibrated so that the graphics is properly rendered. The optical see-through systems present an additional challenge because we do not have access to the image data directly as in video see-through systems. This paper reports on a method we developed for optical see-through head-mounted displays. The method integrates the measurements for the camera and the magnetic tracker which is attached to the camera in order to do the calibration. The calibration is based on the alignment of image points with a single 3D point in the world coordinate system from various viewpoints. The user interaction to do the calibration is extremely easy compared to prior methods, and there is no requirement for keeping the head static while doing the calibration.},
  doi       = {10.1109/ISAR.2000.880938},
  keywords  = {calibration, augmented reality, computer displays, user interfaces, cameras, rendering (computer graphics), image processing, single point active alignment method, calibration, augmented reality, computer model, camera, rendering, optical see-through head-mounted displays, magnetic tracker, user interaction, Calibration, Cameras, Computer graphics, Augmented reality, Displays, Optical computing, Biomedical optical imaging, Application software, Layout, Information science},
}

@InProceedings{Coomans1997,
  author    = {Coomans, M. K. D. and Timmermans, H. J. P.},
  title     = {Towards a taxonomy of virtual reality user interfaces},
  booktitle = {Proceedings. 1997 {IEEE} {Conference} on {Information} {Visualization} ({Cat}. {No}.97TB100165)},
  year      = {1997},
  pages     = {279--284},
  month     = aug,
  abstract  = {Virtual reality based user interfaces (VRUIs) are expected to bring about a revolution in computing. VR can potentially communicate large amounts of data in an easily understandable format. VR looks very promising, but it is still a very new interface technology for which very little application oriented knowledge is available. As a basis for such a future VRUI design theory, a taxonomy of VRUIs is required. A general model of human computer communication is formulated. This model constitutes a frame for the integration of partial taxonomies of human computer interaction that are found in the literature. The whole model constitutes a general user interface taxonomy. The field of VRUIs is described and delimited with respect to this taxonomy.},
  doi       = {10.1109/IV.1997.626531},
  keywords  = {graphical user interfaces, virtual reality, interactive systems, human factors, virtual reality user interfaces, VRUIs, VR, understandable format, interface technology, application oriented knowledge, future VRUI design theory, human computer communication, partial taxonomies, human computer interaction, general user interface taxonomy, Taxonomy, Virtual reality, User interfaces, Computer interfaces, Visualization, Computer architecture, Buildings, Technology planning, Postal services, Humans},
}

@InProceedings{Lin2018,
  author     = {Lin, Ying-Li and Chou, Tsai-Yi and Lieo, Yu-Cheng and Huang, Yu-Cheng and Han, Ping-Hsuan},
  title      = {{TransFork}: {Using} {Olfactory} {Device} for {Augmented} {Tasting} {Experience} with {Video} {See}-through {Head}-mounted {Display}},
  booktitle  = {Proceedings of the 24th {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
  year       = {2018},
  series     = {{VRST} '18},
  pages      = {58:1--58:2},
  address    = {New York, NY, USA},
  publisher  = {ACM},
  note       = {event-place: Tokyo, Japan},
  abstract   = {When people eat, the taste is very complex and be influenced easily by other senses. Such as visual, olfactory, and haptic, even past experiences, can affect the human perception, which in turn creates more taste possibilities. We present TransFork, an eating tool with olfactory feedback, which augments the tasting experience with video see-through head-mounted display. Additionally, we design a recipe via preliminary experiments to find out the taste conversion formula, which could enhance the flavor of foods and change the user perception to recognize the food. In this demonstration, we prepare a mini feast with bite-sized fruit, the participants use the TransFork to eat food A and smell the scent of food B stored at the aromatic box via airflow guiding. Before they deliver the food to their mouth, the head-mounted display augmented the color of food B on food A by the QR code on the aromatic box. With this augmented reality techniques and the recipe, the tasting experience could be augmented or enhanced, which is a potential approach and could be a playful used for eating.},
  doi        = {10.1145/3281505.3281560},
  isbn       = {9781450360869},
  keywords   = {augmented reality, augmented tasting experience, olfactory, video see-through head-mounted display},
  shorttitle = {{TransFork}},
  url        = {http://doi.acm.org/10.1145/3281505.3281560},
  urldate    = {2019-09-20},
}

@InProceedings{Sales2009,
  author    = {Sales Dias, Miguel and Bastos, Rafael and Fernandes, João and Tavares, João and Santos, Pedro},
  title     = {Using {Hand} {Gesture} and {Speech} in a {Multimodal} {Augmented} {Reality} {Environment}},
  booktitle = {Gesture-{Based} {Human}-{Computer} {Interaction} and {Simulation}},
  year      = {2009},
  editor    = {Sales Dias, Miguel and Gibet, Sylvie and Wanderley, Marcelo M. and Bastos, Rafael},
  series    = {Lecture {Notes} in {Computer} {Science}},
  pages     = {175--180},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this work we describe a 3D authoring tool which takes advantage of multimodal interfaces such as gestures and speech. This tool allows real-time Augmented Reality aimed to aid the tasks of interior architects and designers. This approach intends to be an alternative to traditional techniques. The main benefit of using a multimodal based augmented reality system is the provision of a more transparent, flexible, efficient and expressive means of human-computer interaction.},
  isbn      = {9783540928652},
  keywords  = {Gesture Tracking , Augmented Reality , 3D Authoring Tool , Speech , Multimodal interfaces },
  language  = {en},
}

@InProceedings{Ranasinghe2017,
  author     = {Ranasinghe, Nimesha and Nguyen, Thi Ngoc Tram and Liangkun, Yan and Lin, Lien-Ya and Tolley, David and Do, Ellen Yi-Luen},
  title      = {Vocktail: {A} {Virtual} {Cocktail} for {Pairing} {Digital} {Taste}, {Smell}, and {Color} {Sensations}},
  booktitle  = {Proceedings of the 25th {ACM} {International} {Conference} on {Multimedia}},
  year       = {2017},
  series     = {{MM} '17},
  pages      = {1139--1147},
  address    = {New York, NY, USA},
  publisher  = {ACM},
  note       = {event-place: Mountain View, California, USA},
  abstract   = {Similar to the concept of a cocktail or mocktail, we present Vocktail (a.k.a. Virtual Cocktail) - an interactive drinking utensil that digitally simulates multisensory flavor experiences. The Vocktail system utilizes three common sensory modalities, taste, smell, and visual (color), to create virtual flavors and augment the existing flavors of a beverage. The system is coupled with a mobile application that enables users to create customized virtual flavor sensations by configuring each of the stimuli via Bluetooth. The system consists of a cocktail glass that is seamlessly fused into a 3D printed structure, which holds the electronic control module, three scent cartridges, and three micro air-pumps. When a user drinks from the system, the visual (RGB light projected on the beverage), taste (electrical stimulation at the tip of the tongue), and smell stimuli (emitted by micro air-pumps) are combined to create a virtual flavor sensation, thus altering the flavor of the beverage. In summary, this paper discusses 1) technical details of the Vocktail system and 2) user experiments that investigate the influences of these multimodal stimuli on the perception of virtual flavors in terms of five primary tastes (i.e. salty, sweet, bitter, sour, and umami). Our results suggest that the combination of these stimuli delivers richer flavor experiences, as compared to separately simulating individual modalities, and indicates that the types of pairings that can be formed between smell and electric taste stimuli.},
  doi        = {10.1145/3123266.3123440},
  isbn       = {9781450349062},
  keywords   = {digital taste, electric taste, virtual cocktail, virtual flavor, virtual taste, vocktail},
  shorttitle = {Vocktail},
  url        = {http://doi.acm.org/10.1145/3123266.3123440},
  urldate    = {2019-09-20},
}

@Article{Wang2016,
  author   = {Wang, X. and Ong, S. K. and Nee, A. Y. C.},
  title    = {A comprehensive survey of augmented reality assembly research},
  journal  = {Advances in Manufacturing},
  year     = {2016},
  volume   = {4},
  number   = {1},
  pages    = {1--22},
  month    = mar,
  issn     = {2095-3127, 2195-3597},
  doi      = {10.1007/s40436-015-0131-4},
  language = {en},
  url      = {http://link.springer.com/10.1007/s40436-015-0131-4},
  urldate  = {2019-09-20},
}

@Article{Muhammad2018,
  author  = {Muhammad Nizam, Siti Soleha and Zainal Abidin, Rimaniza and Che Hashim, Nurhazarifah and Lam, Meng Chun and Arshad, Haslina and Abd Majid, Nazatul Aini},
  title   = {A {Review} of {Multimodal} {Interaction} {Technique} in {Augmented} {Reality} {Environment}},
  journal = {International Journal on Advanced Science, Engineering and Information Technology},
  year    = {2018},
  volume  = {8},
  number  = {4-2},
  pages   = {1460},
  month   = sep,
  issn    = {2460-6952, 2088-5334},
  doi     = {10.18517/ijaseit.8.4-2.6824},
  url     = {http://ijaseit.insightsociety.org/index.php?option=com_content&view=article&id=9&Itemid=1&article_id=6824},
  urldate = {2019-09-20},
}

@Article{Thomas2012,
  author   = {Thomas, Bruce H.},
  title    = {A survey of visual, mixed, and augmented reality gaming},
  journal  = {Computers in Entertainment},
  year     = {2012},
  volume   = {10},
  number   = {3},
  pages    = {1--33},
  month    = nov,
  issn     = {15443574},
  doi      = {10.1145/2381876.2381879},
  language = {en},
  url      = {http://dl.acm.org/citation.cfm?doid=2381876.2381879},
  urldate  = {2019-09-20},
}

@Article{Ong2008,
  author     = {Ong, S. K. and Yuan, M. L. and Nee, A. Y. C.},
  title      = {Augmented reality applications in manufacturing: a survey},
  journal    = {International Journal of Production Research},
  year       = {2008},
  volume     = {46},
  number     = {10},
  pages      = {2707--2742},
  month      = may,
  issn       = {0020-7543, 1366-588X},
  doi        = {10.1080/00207540601064773},
  language   = {en},
  shorttitle = {Augmented reality applications in manufacturing},
  url        = {http://www.tandfonline.com/doi/abs/10.1080/00207540601064773},
  urldate    = {2019-09-20},
}

@Article{Huang2013,
  author     = {Huang, Zhanpeng and Hui, Pan and Peylo, Christoph and Chatzopoulos, Dimitris},
  title      = {Mobile augmented reality survey: a bottom-up approach},
  journal    = {arXiv:1309.4413 [cs]},
  year       = {2013},
  month      = sep,
  note       = {arXiv: 1309.4413},
  abstract   = {Augmented Reality (AR) is becoming mobile. Mobile devices have many constraints but also rich new features that traditional desktop computers do not have. There are several survey papers on AR, but none is dedicated to Mobile Augmented Reality (MAR). Our work serves the purpose of closing this gap. The contents are organized with a bottom-up approach. We first present the state-of-the-art in system components including hardware platforms, software frameworks and display devices, follows with enabling technologies such as tracking and data management. We then survey the latest technologies and methods to improve run-time performance and energy efficiency for practical implementation. On top of these, we further introduce the application fields and several typical MAR applications. Finally we conclude the survey with several challenge problems, which are under exploration and require great research efforts in the future.},
  keywords   = {Computer Science - Graphics, Computer Science - Human-Computer Interaction, H.5.1},
  shorttitle = {Mobile augmented reality survey},
  url        = {http://arxiv.org/abs/1309.4413},
  urldate    = {2019-09-20},
}

@InProceedings{Rekimoto2000,
  author    = {Rekimoto, Jun and Ayatsuka, Yuji},
  title     = {CyberCode: Designing Augmented Reality Environments with Visual Tags},
  booktitle = {Proceedings of DARE 2000 on Designing Augmented Reality Environments},
  year      = {2000},
  series    = {DARE '00},
  pages     = {1--10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {354667},
  doi       = {10.1145/354666.354667},
  keywords  = {CyberCode, ID-aware interface, augmented reality, merging virtual and real},
  location  = {Elsinore, Denmark},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/354666.354667},
}

@Article{Kennedy2000,
  author   = {P. R. {Kennedy} and R. A. E. {Bakay} and M. M. {Moore} and K. {Adams} and J. {Goldwaithe}},
  title    = {Direct control of a computer from the human central nervous system},
  journal  = {IEEE Transactions on Rehabilitation Engineering},
  year     = {2000},
  volume   = {8},
  number   = {2},
  pages    = {198-202},
  month    = {June},
  doi      = {10.1109/86.847815},
  keywords = {electroencephalography;biomedical electrodes;handicapped aids;prosthetics;human central nervous system;direct computer control;invasive alternative;externally applied brain-computer interface devices;special electrode implantation;human neocortex outer layers;recorded signals transmission;computer monitor cursor driving;cursor control;synthetic speech production;typing;Centralized control;Control systems;Humans;Central nervous system;Brain computer interfaces;Electrodes;Signal processing;Drives;Computer displays;Speech},
}

@Article{Hayward2000,
  author = {Hayward, Vincent},
  title  = {Haptics: A Key to Fast Paced Interactivity},
  year   = {2000},
  month  = {01},
  doi    = {10.1016/B978-044450649-8/50004-8},
}

@InProceedings{Billinghurst2000,
  author = {Billinghurst, Mark and Poupyrev, Ivan and Kato, Hirokazu and May, Richard},
  title  = {Mixing Realities in Shared Space: An Augmented Reality Interface for Collaborative Computing.},
  year   = {2000},
  volume = {3},
  pages  = {1641-1644},
  month  = {01},
  doi    = {10.1109/ICME.2000.871085},
}

@Article{Liarokapis2002,
  author    = {Liarokapis, Fotis and Petridis, Panos and Lister, Paul F and White, Martin and others},
  title     = {Multimedia augmented reality interface for e-learning (MARIE)},
  journal   = {World Transactions on Engineering and Technology Education},
  year      = {2002},
  volume    = {1},
  number    = {2},
  pages     = {173--176},
  publisher = {UNESCO International Centre for Engineering Education},
}

@InProceedings{Djajadiningrat2002,
  author    = {Djajadiningrat, Tom and Overbeeke, Kees and Wensveen, Stephan},
  title     = {But How, Donald, Tell Us How?: On the Creation of Meaning in Interaction Design Through Feedforward and Inherent Feedback},
  booktitle = {Proceedings of the 4th Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques},
  year      = {2002},
  series    = {DIS '02},
  pages     = {285--291},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {778752},
  doi       = {10.1145/778712.778752},
  isbn      = {1-58113-515-7},
  keywords  = {expressiveness, feedback, feedforward, meaning, usability},
  location  = {London, England},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/778712.778752},
}

@Article{Piekarski2002,
  author  = {Piekarski, Wayne and Thomas, Bruce},
  title   = {ARQuake: The Outdoor Augmented Reality Gaming System},
  journal = {Commun. ACM},
  year    = {2002},
  volume  = {45},
  pages   = {36-38},
  month   = {01},
  doi     = {10.1145/502269.502291},
}

@Book{Alan2003,
  title     = {Human Computer Interaction},
  publisher = {Pearson Prentice Hall},
  year      = {2003},
  author    = {Dix, Alan and Finlay, Janet and Abowd, Gregory D. and Beale, Russell},
  address   = {Harlow, England},
  edition   = {3},
  isbn      = {978-0-13-046109-4},
  abstract  = {The second edition of Human-Computer Interaction established itself as one of the classic textbooks in the area, with its broad coverage and rigorous approach, this new edition builds on the existing strengths of the book, but giving the text a more student-friendly slant and improving the coverage in certain areas. The revised structure, separating out the introductory and more advanced material will make it easier to use the book on a variety of courses. This new edition now includes chapters on Interaction Design, Universal Access and Rich Interaction, as well as covering the latest developments in ubiquitous computing and Web technologies, making it the ideal text to provide a grounding in HCI theory and practice.},
  added-at  = {2017-07-09T13:56:37.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/2372ebd7aa5ae8d991a46314c89024052/flint63},
  file      = {eBook:2000-04/DixFinlayEtAl03.pdf:PDF;Amazon Search inside:http\://www.amazon.de/gp/reader/0130461091/:URL},
  groups    = {public},
  interhash = {82af498e4224a245f1219c8dd5554e58},
  intrahash = {372ebd7aa5ae8d991a46314c89024052},
  keywords  = {01841 105 book shelf user interface interaction design zzz.hci},
  timestamp = {2018-04-16T11:59:30.000+0200},
  username  = {flint63},
}

@Article{Birch2003,
  author  = {G. E. Birch and S Mason and J. F. Borisoff},
  title   = {Current trends in brain-computer interface research at the Neil Squire foundation},
  journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year    = {2003},
  volume  = {11},
  pages   = {123-126},
}

@Article{Mason2003,
  author   = {S. G. {Mason} and G. E. {Birch}},
  title    = {A general framework for brain-computer interface design},
  journal  = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  year     = {2003},
  volume   = {11},
  number   = {1},
  pages    = {70-85},
  month    = {March},
  doi      = {10.1109/TNSRE.2003.810426},
  keywords = {handicapped aids;medical computing;electroencephalography;user interfaces;brain-computer interface design;general framework;common vocabulary;assistive technology;direct-brain interface;poor intergroup communication;taxonomy;objective methods;Brain computer interfaces;Vocabulary;Power system modeling;Taxonomy;Standards development;Brain modeling;User interfaces;System testing;Electroencephalography;Algorithms;Brain;Communication Aids for Disabled;Decision Support Techniques;Equipment Failure Analysis;Humans;Prosthesis Design;Technology Assessment, Biomedical;User-Computer Interface},
}

@InProceedings{Duenser2007,
  author = {Duenser, Andreas and , Rapha and Seichter, Hartmut and Billinghurst, Mark},
  title  = {Applying HCI principles to AR systems design},
  year   = {2007},
  month  = {01},
}

@Article{autism-in-adults,
  author   = {Billstedt, Eva and Carina Gillberg, I. and Gillberg, Christopher},
  title    = {Autism in adults: symptom patterns and early childhood predictors. Use of the DISCO in a community sample followed from childhood},
  journal  = {Journal of Child Psychology and Psychiatry},
  year     = {2007},
  volume   = {48},
  number   = {11},
  pages    = {1102-1110},
  doi      = {10.1111/j.1469-7610.2007.01774.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-7610.2007.01774.x},
  keywords = {Autism, the DISCO, community sample, adult outcome.},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-7610.2007.01774.x},
}

@Book{Haller2007,
  title     = {Emerging Technologies of Augmented Reality: Interfaces and Design},
  publisher = {Idea Group Pub.},
  year      = {2007},
  author    = {Michael Haller and Mark Billinghurst and Bruce H. Thomas},
  isbn      = {9781599040660},
  lccn      = {2006027724},
  url       = {https://books.google.lk/books?id=ItLhfvNGTssC},
}

@Article{Mitra2007,
  author   = {S. {Mitra} and T. {Acharya}},
  title    = {Gesture Recognition: A Survey},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  year     = {2007},
  volume   = {37},
  number   = {3},
  pages    = {311-324},
  month    = {May},
  issn     = {1094-6977},
  doi      = {10.1109/TSMCC.2007.893280},
  keywords = {face recognition;finite state machines;gesture recognition;hidden Markov models;human computer interaction;image colour analysis;image sequences;gesture recognition;intelligent human-computer interface;hand gestures;facial expressions;hidden Markov models;particle filtering;condensation;finite-state machines;optical flow;skin color;connectionist models;Face recognition;Hidden Markov models;Optical filters;Humans;Arm;Magnetic heads;Manifolds;Handicapped aids;Virtual reality;Filtering;Face recognition;facial expressions;hand gestures;hidden Markov models (HMMs);soft computing;optical flow},
}

@Article{Edmans2007,
  author     = {Edmans, Judi and Gladman, John and Walker, Marion and Sunderland, Alan and Porter, Amanda and Fraser, Danae Stanton},
  title      = {Mixed reality environments in stroke rehabilitation: {Development} as rehabilitation tools},
  journal    = {International Journal on Disability and Human Development},
  year       = {2007},
  volume     = {6},
  number     = {1},
  month      = jan,
  issn       = {2191-0367, 2191-1231},
  doi        = {10.1515/IJDHD.2007.6.1.39},
  shorttitle = {Mixed reality environments in stroke rehabilitation},
  url        = {https://www.degruyter.com/view/j/ijdhd.2007.6.1/ijdhd.2007.6.1.39/ijdhd.2007.6.1.39.xml},
  urldate    = {2019-09-18},
}

@Article{Friedman2007,
  author   = {Friedman, Doron and Leeb, Robert and Guger, Christoph and Steed, Anthony and Pfurtscheller, Gert and Slater, Mel},
  title    = {Navigating Virtual Reality by Thought: What Is It Like?},
  journal  = {Presence: Teleoperators and Virtual Environments},
  year     = {2007},
  volume   = {16},
  number   = {1},
  pages    = {100-110},
  abstract = { Abstract We have set up a brain-computer interface (BCI) to be used as an input device to a highly immersive virtual reality CAVE-like system. We have carried out two navigation experiments: three subjects were required to rotate in a virtual bar room by imagining left or right hand movement, and to walk along a single axis in a virtual street by imagining foot or hand movement. In this paper we focus on the subjective experience of navigating virtual reality “by thought,” and on the interrelations between BCI and presence. },
  doi      = {10.1162/pres.16.1.100},
  eprint   = {https://doi.org/10.1162/pres.16.1.100},
  url      = { 
        https://doi.org/10.1162/pres.16.1.100
    
},
}

@InProceedings{Oconnor2005,
  author = {M. O’connor},
  title  = {Authoring and Delivering Mixed Reality Experiences},
  year   = {2005},
}

@InProceedings{Papagiannakis2005,
  author = {George Papagiannakis and Hyungseok Kim and Nadia Magnenat-Thalmann},
  title  = {Believability and Presence in Mobile Mixed Reality Environments},
  year   = {2005},
}

@InProceedings{Maynes2005,
  author    = {Dan Maynes-aminzade},
  title     = {Edible Bits: Seamless Interfaces between People, Data and Food},
  booktitle = {Proceedings of the 2005 ACM Conference on Human Factors in Computing Systems (CHI'2005},
  year      = {2005},
}

@Article{Naimark2006,
  author  = {Michael Naimark},
  title   = {Aspen the Verb: Musings on Heritage and Virtuality},
  journal = {PRESENCE: Teleoperators and Virtual Environments},
  year    = {2006},
  volume  = {15},
  pages   = {330-335},
}

@Book{Saffer2006,
  title     = {Designing for Interaction: Creating Smart Applications and Clever Devices},
  publisher = {Peachpit Press},
  year      = {2006},
  author    = {Saffer, Dan},
  address   = {Berkeley, CA, USA},
  edition   = {First},
  isbn      = {0321447123},
}

@Article{Khosravi2019,
  author  = {Bijan Khosravi},
  title   = {Put Down The Smart Phone - The Future Of Communications Is Mixed Reality Glasses},
  journal = {Forbes},
  year    = {2019},
  url     = {https://www.forbes.com/sites/bijankhosravi/2019/09/08/put-down-the-smart-phone-the-future-of-communications-is-mixed-reality-glasses/#2fe1b9046aef},
}

@Book{Todd2015,
  title     = {Nolte’s The Human Brain: An Introduction to its Functional Anatomy},
  publisher = {Elsevier},
  year      = {2015},
  author    = {Todd Vanderah, Douglas Gould},
  edition   = {7},
  isbn      = {1455728594,9781455728596},
  url       = {http://gen.lib.rus.ec/book/index.php?md5=866e8d84135d6c9150a75381cd42d16a},
}
